// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework-validators/float64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/int64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/mapvalidator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64default"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/objectdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringdefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	tfTypes "github.com/kong/terraform-provider-konnect/v2/internal/provider/types"
	"github.com/kong/terraform-provider-konnect/v2/internal/sdk"
	"github.com/kong/terraform-provider-konnect/v2/internal/validators"
	speakeasy_int64validators "github.com/kong/terraform-provider-konnect/v2/internal/validators/int64validators"
	speakeasy_objectvalidators "github.com/kong/terraform-provider-konnect/v2/internal/validators/objectvalidators"
	speakeasy_stringvalidators "github.com/kong/terraform-provider-konnect/v2/internal/validators/stringvalidators"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ resource.Resource = &GatewayPluginKafkaLogResource{}
var _ resource.ResourceWithImportState = &GatewayPluginKafkaLogResource{}

func NewGatewayPluginKafkaLogResource() resource.Resource {
	return &GatewayPluginKafkaLogResource{}
}

// GatewayPluginKafkaLogResource defines the resource implementation.
type GatewayPluginKafkaLogResource struct {
	// Provider configured SDK client.
	client *sdk.Konnect
}

// GatewayPluginKafkaLogResourceModel describes the resource data model.
type GatewayPluginKafkaLogResourceModel struct {
	Config         tfTypes.KafkaLogPluginConfig `tfsdk:"config"`
	Consumer       *tfTypes.Set                 `tfsdk:"consumer"`
	ControlPlaneID types.String                 `tfsdk:"control_plane_id"`
	CreatedAt      types.Int64                  `tfsdk:"created_at"`
	Enabled        types.Bool                   `tfsdk:"enabled"`
	ID             types.String                 `tfsdk:"id"`
	InstanceName   types.String                 `tfsdk:"instance_name"`
	Ordering       *tfTypes.ACLPluginOrdering   `tfsdk:"ordering"`
	Partials       []tfTypes.Partials           `tfsdk:"partials"`
	Protocols      []types.String               `tfsdk:"protocols"`
	Route          *tfTypes.Set                 `tfsdk:"route"`
	Service        *tfTypes.Set                 `tfsdk:"service"`
	Tags           []types.String               `tfsdk:"tags"`
	UpdatedAt      types.Int64                  `tfsdk:"updated_at"`
}

func (r *GatewayPluginKafkaLogResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_gateway_plugin_kafka_log"
}

func (r *GatewayPluginKafkaLogResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "GatewayPluginKafkaLog Resource",
		Attributes: map[string]schema.Attribute{
			"config": schema.SingleNestedAttribute{
				Required: true,
				Attributes: map[string]schema.Attribute{
					"authentication": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
							"mechanism": types.StringType,
							"password":  types.StringType,
							"strategy":  types.StringType,
							"tokenauth": types.BoolType,
							"user":      types.StringType,
						})),
						Attributes: map[string]schema.Attribute{
							"mechanism": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `The SASL authentication mechanism.  Supported options: ` + "`" + `PLAIN` + "`" + `, ` + "`" + `SCRAM-SHA-256` + "`" + ` or ` + "`" + `SCRAM-SHA-512` + "`" + `. must be one of ["PLAIN", "SCRAM-SHA-256", "SCRAM-SHA-512"]`,
								Validators: []validator.String{
									stringvalidator.OneOf(
										"PLAIN",
										"SCRAM-SHA-256",
										"SCRAM-SHA-512",
									),
								},
							},
							"password": schema.StringAttribute{
								Optional:    true,
								Description: `Password for SASL authentication.`,
							},
							"strategy": schema.StringAttribute{
								Computed:    true,
								Optional:    true,
								Description: `The authentication strategy for the plugin, the only option for the value is ` + "`" + `sasl` + "`" + `. must be "sasl"`,
								Validators: []validator.String{
									stringvalidator.OneOf("sasl"),
								},
							},
							"tokenauth": schema.BoolAttribute{
								Optional:    true,
								Description: `Enable this to indicate ` + "`" + `DelegationToken` + "`" + ` authentication`,
							},
							"user": schema.StringAttribute{
								Optional:    true,
								Description: `Username for SASL authentication.`,
							},
						},
					},
					"bootstrap_servers": schema.ListNestedAttribute{
						Optional: true,
						NestedObject: schema.NestedAttributeObject{
							Validators: []validator.Object{
								speakeasy_objectvalidators.NotNull(),
							},
							Attributes: map[string]schema.Attribute{
								"host": schema.StringAttribute{
									Computed:    true,
									Optional:    true,
									Description: `A string representing a host name, such as example.com. Not Null`,
									Validators: []validator.String{
										speakeasy_stringvalidators.NotNull(),
									},
								},
								"port": schema.Int64Attribute{
									Computed:    true,
									Optional:    true,
									Description: `An integer representing a port number between 0 and 65535, inclusive. Not Null`,
									Validators: []validator.Int64{
										speakeasy_int64validators.NotNull(),
										int64validator.AtMost(65535),
									},
								},
							},
						},
						Description: `Set of bootstrap brokers in a ` + "`" + `{host: host, port: port}` + "`" + ` list format.`,
					},
					"cluster_name": schema.StringAttribute{
						Optional:    true,
						Description: `An identifier for the Kafka cluster. By default, this field generates a random string. You can also set your own custom cluster identifier.  If more than one Kafka plugin is configured without a ` + "`" + `cluster_name` + "`" + ` (that is, if the default autogenerated value is removed), these plugins will use the same producer, and by extension, the same cluster. Logs will be sent to the leader of the cluster.`,
					},
					"custom_fields_by_lua": schema.MapAttribute{
						Optional:    true,
						ElementType: types.StringType,
						Description: `Lua code as a key-value map`,
						Validators: []validator.Map{
							mapvalidator.ValueStringsAre(validators.IsValidJSON()),
						},
					},
					"keepalive": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(60000),
						Description: `Default: 60000`,
					},
					"keepalive_enabled": schema.BoolAttribute{
						Computed:    true,
						Optional:    true,
						Default:     booldefault.StaticBool(false),
						Description: `Default: false`,
					},
					"key_query_arg": schema.StringAttribute{
						Optional:    true,
						Description: `The request query parameter name that contains the Kafka message key. If specified, messages with the same key will be sent to the same Kafka partition, ensuring consistent ordering.`,
					},
					"producer_async": schema.BoolAttribute{
						Computed:    true,
						Optional:    true,
						Default:     booldefault.StaticBool(true),
						Description: `Flag to enable asynchronous mode. Default: true`,
					},
					"producer_async_buffering_limits_messages_in_memory": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(50000),
						Description: `Maximum number of messages that can be buffered in memory in asynchronous mode. Default: 50000`,
					},
					"producer_async_flush_timeout": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(1000),
						Description: `Maximum time interval in milliseconds between buffer flushes in asynchronous mode. Default: 1000`,
					},
					"producer_request_acks": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(1),
						Description: `The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set). Default: 1; must be one of ["-1", "0", "1"]`,
						Validators: []validator.Int64{
							int64validator.OneOf(-1, 0, 1),
						},
					},
					"producer_request_limits_bytes_per_request": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(1048576),
						Description: `Maximum size of a Produce request in bytes. Default: 1048576`,
					},
					"producer_request_limits_messages_per_request": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(200),
						Description: `Maximum number of messages to include into a single Produce request. Default: 200`,
					},
					"producer_request_retries_backoff_timeout": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(100),
						Description: `Backoff interval between retry attempts in milliseconds. Default: 100`,
					},
					"producer_request_retries_max_attempts": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(10),
						Description: `Maximum number of retry attempts per single Produce request. Default: 10`,
					},
					"producer_request_timeout": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(2000),
						Description: `Time to wait for a Produce response in milliseconds. Default: 2000`,
					},
					"schema_registry": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
							"confluent": types.ObjectType{
								AttrTypes: map[string]attr.Type{
									`authentication`: types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`basic`: types.ObjectType{
												AttrTypes: map[string]attr.Type{
													`password`: types.StringType,
													`username`: types.StringType,
												},
											},
											`mode`: types.StringType,
										},
									},
									`key_schema`: types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`schema_version`: types.StringType,
											`subject_name`:   types.StringType,
										},
									},
									`ssl_verify`: types.BoolType,
									`ttl`:        types.Float64Type,
									`url`:        types.StringType,
									`value_schema`: types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`schema_version`: types.StringType,
											`subject_name`:   types.StringType,
										},
									},
								},
							},
						})),
						Attributes: map[string]schema.Attribute{
							"confluent": schema.SingleNestedAttribute{
								Computed: true,
								Optional: true,
								Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
									"authentication": types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`basic`: types.ObjectType{
												AttrTypes: map[string]attr.Type{
													`password`: types.StringType,
													`username`: types.StringType,
												},
											},
											`mode`: types.StringType,
										},
									},
									"key_schema": types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`schema_version`: types.StringType,
											`subject_name`:   types.StringType,
										},
									},
									"ssl_verify": types.BoolType,
									"ttl":        types.Float64Type,
									"url":        types.StringType,
									"value_schema": types.ObjectType{
										AttrTypes: map[string]attr.Type{
											`schema_version`: types.StringType,
											`subject_name`:   types.StringType,
										},
									},
								})),
								Attributes: map[string]schema.Attribute{
									"authentication": schema.SingleNestedAttribute{
										Required: true,
										Attributes: map[string]schema.Attribute{
											"basic": schema.SingleNestedAttribute{
												Computed: true,
												Optional: true,
												Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
													"password": types.StringType,
													"username": types.StringType,
												})),
												Attributes: map[string]schema.Attribute{
													"password": schema.StringAttribute{
														Required: true,
													},
													"username": schema.StringAttribute{
														Required: true,
													},
												},
											},
											"mode": schema.StringAttribute{
												Computed:    true,
												Optional:    true,
												Default:     stringdefault.StaticString(`none`),
												Description: `Authentication mode to use with the schema registry. Default: "none"; must be one of ["basic", "none"]`,
												Validators: []validator.String{
													stringvalidator.OneOf(
														"basic",
														"none",
													),
												},
											},
										},
									},
									"key_schema": schema.SingleNestedAttribute{
										Computed: true,
										Optional: true,
										Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
											"schema_version": types.StringType,
											"subject_name":   types.StringType,
										})),
										Attributes: map[string]schema.Attribute{
											"schema_version": schema.StringAttribute{
												Optional:    true,
												Description: `The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.`,
											},
											"subject_name": schema.StringAttribute{
												Optional:    true,
												Description: `The name of the subject`,
											},
										},
									},
									"ssl_verify": schema.BoolAttribute{
										Computed:    true,
										Optional:    true,
										Default:     booldefault.StaticBool(true),
										Description: `Set to false to disable SSL certificate verification when connecting to the schema registry. Default: true`,
									},
									"ttl": schema.Float64Attribute{
										Optional:    true,
										Description: `The TTL in seconds for the schema registry cache.`,
										Validators: []validator.Float64{
											float64validator.AtMost(3600),
										},
									},
									"url": schema.StringAttribute{
										Optional:    true,
										Description: `The URL of the schema registry.`,
									},
									"value_schema": schema.SingleNestedAttribute{
										Computed: true,
										Optional: true,
										Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
											"schema_version": types.StringType,
											"subject_name":   types.StringType,
										})),
										Attributes: map[string]schema.Attribute{
											"schema_version": schema.StringAttribute{
												Optional:    true,
												Description: `The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.`,
											},
											"subject_name": schema.StringAttribute{
												Optional:    true,
												Description: `The name of the subject`,
											},
										},
									},
								},
							},
						},
						Description: `The plugin-global schema registry configuration. This can be overwritten by the topic configuration.`,
					},
					"security": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
							"certificate_id": types.StringType,
							"ssl":            types.BoolType,
						})),
						Attributes: map[string]schema.Attribute{
							"certificate_id": schema.StringAttribute{
								Optional:    true,
								Description: `UUID of certificate entity for mTLS authentication.`,
							},
							"ssl": schema.BoolAttribute{
								Optional:    true,
								Description: `Enables TLS.`,
							},
						},
					},
					"timeout": schema.Int64Attribute{
						Computed:    true,
						Optional:    true,
						Default:     int64default.StaticInt64(10000),
						Description: `Socket timeout in milliseconds. Default: 10000`,
					},
					"topic": schema.StringAttribute{
						Required:    true,
						Description: `The Kafka topic to publish to.`,
					},
				},
			},
			"consumer": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
					"id": types.StringType,
				})),
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
						Optional: true,
					},
				},
				Description: `If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.`,
			},
			"control_plane_id": schema.StringAttribute{
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplaceIfConfigured(),
				},
				Description: `The UUID of your control plane. This variable is available in the Konnect manager. Requires replacement if changed.`,
			},
			"created_at": schema.Int64Attribute{
				Computed:    true,
				Optional:    true,
				Description: `Unix epoch when the resource was created.`,
			},
			"enabled": schema.BoolAttribute{
				Computed:    true,
				Optional:    true,
				Default:     booldefault.StaticBool(true),
				Description: `Whether the plugin is applied. Default: true`,
			},
			"id": schema.StringAttribute{
				Computed:    true,
				Optional:    true,
				Description: `A string representing a UUID (universally unique identifier).`,
			},
			"instance_name": schema.StringAttribute{
				Optional:    true,
				Description: `A unique string representing a UTF-8 encoded name.`,
			},
			"ordering": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
					"after": types.ObjectType{
						AttrTypes: map[string]attr.Type{
							`access`: types.ListType{
								ElemType: types.StringType,
							},
						},
					},
					"before": types.ObjectType{
						AttrTypes: map[string]attr.Type{
							`access`: types.ListType{
								ElemType: types.StringType,
							},
						},
					},
				})),
				Attributes: map[string]schema.Attribute{
					"after": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
							"access": types.ListType{
								ElemType: types.StringType,
							},
						})),
						Attributes: map[string]schema.Attribute{
							"access": schema.ListAttribute{
								Optional:    true,
								ElementType: types.StringType,
							},
						},
					},
					"before": schema.SingleNestedAttribute{
						Computed: true,
						Optional: true,
						Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
							"access": types.ListType{
								ElemType: types.StringType,
							},
						})),
						Attributes: map[string]schema.Attribute{
							"access": schema.ListAttribute{
								Optional:    true,
								ElementType: types.StringType,
							},
						},
					},
				},
			},
			"partials": schema.ListNestedAttribute{
				Optional: true,
				NestedObject: schema.NestedAttributeObject{
					Validators: []validator.Object{
						speakeasy_objectvalidators.NotNull(),
					},
					Attributes: map[string]schema.Attribute{
						"id": schema.StringAttribute{
							Computed:    true,
							Optional:    true,
							Description: `A string representing a UUID (universally unique identifier).`,
						},
						"name": schema.StringAttribute{
							Optional:    true,
							Description: `A unique string representing a UTF-8 encoded name.`,
						},
						"path": schema.StringAttribute{
							Optional: true,
						},
					},
				},
				Description: `A list of partials to be used by the plugin.`,
			},
			"protocols": schema.SetAttribute{
				Computed:    true,
				Optional:    true,
				ElementType: types.StringType,
				Description: `A list of the request protocols that will trigger this plugin. The default value, as well as the possible values allowed on this field, may change depending on the plugin type. For example, plugins that only work in stream mode will only support tcp and tls.`,
			},
			"route": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
					"id": types.StringType,
				})),
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
						Optional: true,
					},
				},
				Description: `If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.`,
			},
			"service": schema.SingleNestedAttribute{
				Computed: true,
				Optional: true,
				Default: objectdefault.StaticValue(types.ObjectNull(map[string]attr.Type{
					"id": types.StringType,
				})),
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
						Optional: true,
					},
				},
				Description: `If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.`,
			},
			"tags": schema.ListAttribute{
				Optional:    true,
				ElementType: types.StringType,
				Description: `An optional set of strings associated with the Plugin for grouping and filtering.`,
			},
			"updated_at": schema.Int64Attribute{
				Computed:    true,
				Optional:    true,
				Description: `Unix epoch when the resource was last updated.`,
			},
		},
	}
}

func (r *GatewayPluginKafkaLogResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.Konnect)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *sdk.Konnect, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *GatewayPluginKafkaLogResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data *GatewayPluginKafkaLogResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(plan.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsCreateKafkalogPluginRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Plugins.CreateKafkalogPlugin(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 201 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.KafkaLogPlugin != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedKafkaLogPlugin(ctx, res.KafkaLogPlugin)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *GatewayPluginKafkaLogResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data *GatewayPluginKafkaLogResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsGetKafkalogPluginRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Plugins.GetKafkalogPlugin(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode == 404 {
		resp.State.RemoveResource(ctx)
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.KafkaLogPlugin != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedKafkaLogPlugin(ctx, res.KafkaLogPlugin)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *GatewayPluginKafkaLogResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data *GatewayPluginKafkaLogResourceModel
	var plan types.Object

	resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
	if resp.Diagnostics.HasError() {
		return
	}

	merge(ctx, req, resp, &data)
	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsUpdateKafkalogPluginRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Plugins.UpdateKafkalogPlugin(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.KafkaLogPlugin != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedKafkaLogPlugin(ctx, res.KafkaLogPlugin)...)

	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(refreshPlan(ctx, plan, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *GatewayPluginKafkaLogResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data *GatewayPluginKafkaLogResourceModel
	var item types.Object

	resp.Diagnostics.Append(req.State.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	request, requestDiags := data.ToOperationsDeleteKafkalogPluginRequest(ctx)
	resp.Diagnostics.Append(requestDiags...)

	if resp.Diagnostics.HasError() {
		return
	}
	res, err := r.client.Plugins.DeleteKafkalogPlugin(ctx, *request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode != 204 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}

}

func (r *GatewayPluginKafkaLogResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	dec := json.NewDecoder(bytes.NewReader([]byte(req.ID)))
	dec.DisallowUnknownFields()
	var data struct {
		ControlPlaneID string `json:"control_plane_id"`
		ID             string `json:"id"`
	}

	if err := dec.Decode(&data); err != nil {
		resp.Diagnostics.AddError("Invalid ID", `The import ID is not valid. It is expected to be a JSON object string with the format: '{"control_plane_id": "9524ec7d-36d9-465d-a8c5-83a3c9390458", "id": "3473c251-5b6c-4f45-b1ff-7ede735a366d"}': `+err.Error())
		return
	}

	if len(data.ControlPlaneID) == 0 {
		resp.Diagnostics.AddError("Missing required field", `The field control_plane_id is required but was not found in the json encoded ID. It's expected to be a value alike '"9524ec7d-36d9-465d-a8c5-83a3c9390458"`)
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("control_plane_id"), data.ControlPlaneID)...)
	if len(data.ID) == 0 {
		resp.Diagnostics.AddError("Missing required field", `The field id is required but was not found in the json encoded ID. It's expected to be a value alike '"3473c251-5b6c-4f45-b1ff-7ede735a366d"`)
		return
	}
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), data.ID)...)
}
