// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package provider

import (
	"context"
	"fmt"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-framework/types/basetypes"
	tfTypes "github.com/kong/terraform-provider-konnect/v2/internal/provider/types"
	"github.com/kong/terraform-provider-konnect/v2/internal/sdk"
	"github.com/kong/terraform-provider-konnect/v2/internal/sdk/models/operations"
)

// Ensure provider defined types fully satisfy framework interfaces.
var _ datasource.DataSource = &GatewayPluginConfluentConsumeDataSource{}
var _ datasource.DataSourceWithConfigure = &GatewayPluginConfluentConsumeDataSource{}

func NewGatewayPluginConfluentConsumeDataSource() datasource.DataSource {
	return &GatewayPluginConfluentConsumeDataSource{}
}

// GatewayPluginConfluentConsumeDataSource is the data source implementation.
type GatewayPluginConfluentConsumeDataSource struct {
	client *sdk.Konnect
}

// GatewayPluginConfluentConsumeDataSourceModel describes the data model.
type GatewayPluginConfluentConsumeDataSourceModel struct {
	Config         *tfTypes.ConfluentConsumePluginConfig `tfsdk:"config"`
	Consumer       *tfTypes.ACLWithoutParentsConsumer    `tfsdk:"consumer"`
	ControlPlaneID types.String                          `tfsdk:"control_plane_id"`
	CreatedAt      types.Int64                           `tfsdk:"created_at"`
	Enabled        types.Bool                            `tfsdk:"enabled"`
	ID             types.String                          `tfsdk:"id"`
	InstanceName   types.String                          `tfsdk:"instance_name"`
	Ordering       *tfTypes.ACLPluginOrdering            `tfsdk:"ordering"`
	Protocols      []types.String                        `tfsdk:"protocols"`
	Route          *tfTypes.ACLWithoutParentsConsumer    `tfsdk:"route"`
	Service        *tfTypes.ACLWithoutParentsConsumer    `tfsdk:"service"`
	Tags           []types.String                        `tfsdk:"tags"`
	UpdatedAt      types.Int64                           `tfsdk:"updated_at"`
}

// Metadata returns the data source type name.
func (r *GatewayPluginConfluentConsumeDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_gateway_plugin_confluent_consume"
}

// Schema defines the schema for the data source.
func (r *GatewayPluginConfluentConsumeDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "GatewayPluginConfluentConsume DataSource",

		Attributes: map[string]schema.Attribute{
			"config": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"auto_offset_reset": schema.StringAttribute{
						Computed:    true,
						Description: `The offset to start from when there is no initial offset in the consumer group.`,
					},
					"bootstrap_servers": schema.ListNestedAttribute{
						Computed: true,
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"host": schema.StringAttribute{
									Computed:    true,
									Description: `A string representing a host name, such as example.com.`,
								},
								"port": schema.Int64Attribute{
									Computed:    true,
									Description: `An integer representing a port number between 0 and 65535, inclusive.`,
								},
							},
						},
						Description: `Set of bootstrap brokers in a ` + "`" + `{host: host, port: port}` + "`" + ` list format.`,
					},
					"cluster_api_key": schema.StringAttribute{
						Computed:    true,
						Description: `Username/Apikey for SASL authentication.`,
					},
					"cluster_api_secret": schema.StringAttribute{
						Computed:    true,
						Description: `Password/ApiSecret for SASL authentication.`,
					},
					"cluster_name": schema.StringAttribute{
						Computed:    true,
						Description: `An identifier for the Kafka cluster. By default, this field generates a random string. You can also set your own custom cluster identifier.  If more than one Kafka plugin is configured without a ` + "`" + `cluster_name` + "`" + ` (that is, if the default autogenerated value is removed), these plugins will use the same producer, and by extension, the same cluster. Logs will be sent to the leader of the cluster.`,
					},
					"commit_strategy": schema.StringAttribute{
						Computed:    true,
						Description: `The strategy to use for committing offsets.`,
					},
					"confluent_cloud_api_key": schema.StringAttribute{
						Computed:    true,
						Description: `Apikey for authentication with Confluent Cloud. This allows for management tasks such as creating topics, ACLs, etc.`,
					},
					"confluent_cloud_api_secret": schema.StringAttribute{
						Computed:    true,
						Description: `The corresponding secret for the Confluent Cloud API key.`,
					},
					"keepalive": schema.Int64Attribute{
						Computed:    true,
						Description: `Keepalive timeout in milliseconds.`,
					},
					"keepalive_enabled": schema.BoolAttribute{
						Computed: true,
					},
					"message_deserializer": schema.StringAttribute{
						Computed:    true,
						Description: `The deserializer to use for the consumed messages.`,
					},
					"mode": schema.StringAttribute{
						Computed:    true,
						Description: `The mode of operation for the plugin.`,
					},
					"timeout": schema.Int64Attribute{
						Computed:    true,
						Description: `Socket timeout in milliseconds.`,
					},
					"topics": schema.ListNestedAttribute{
						Computed: true,
						NestedObject: schema.NestedAttributeObject{
							Attributes: map[string]schema.Attribute{
								"name": schema.StringAttribute{
									Computed: true,
								},
							},
						},
						Description: `The Kafka topics and their configuration you want to consume from.`,
					},
				},
			},
			"consumer": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
					},
				},
				Description: `If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.`,
			},
			"control_plane_id": schema.StringAttribute{
				Required:    true,
				Description: `The UUID of your control plane. This variable is available in the Konnect manager.`,
			},
			"created_at": schema.Int64Attribute{
				Computed:    true,
				Description: `Unix epoch when the resource was created.`,
			},
			"enabled": schema.BoolAttribute{
				Computed:    true,
				Description: `Whether the plugin is applied.`,
			},
			"id": schema.StringAttribute{
				Computed: true,
			},
			"instance_name": schema.StringAttribute{
				Computed: true,
			},
			"ordering": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"after": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"access": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
							},
						},
					},
					"before": schema.SingleNestedAttribute{
						Computed: true,
						Attributes: map[string]schema.Attribute{
							"access": schema.ListAttribute{
								Computed:    true,
								ElementType: types.StringType,
							},
						},
					},
				},
			},
			"protocols": schema.ListAttribute{
				Computed:    true,
				ElementType: types.StringType,
				Description: `A set of strings representing HTTP protocols.`,
			},
			"route": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
					},
				},
				Description: `If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.`,
			},
			"service": schema.SingleNestedAttribute{
				Computed: true,
				Attributes: map[string]schema.Attribute{
					"id": schema.StringAttribute{
						Computed: true,
					},
				},
				Description: `If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.`,
			},
			"tags": schema.ListAttribute{
				Computed:    true,
				ElementType: types.StringType,
				Description: `An optional set of strings associated with the Plugin for grouping and filtering.`,
			},
			"updated_at": schema.Int64Attribute{
				Computed:    true,
				Description: `Unix epoch when the resource was last updated.`,
			},
		},
	}
}

func (r *GatewayPluginConfluentConsumeDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
	// Prevent panic if the provider has not been configured.
	if req.ProviderData == nil {
		return
	}

	client, ok := req.ProviderData.(*sdk.Konnect)

	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected DataSource Configure Type",
			fmt.Sprintf("Expected *sdk.Konnect, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)

		return
	}

	r.client = client
}

func (r *GatewayPluginConfluentConsumeDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data *GatewayPluginConfluentConsumeDataSourceModel
	var item types.Object

	resp.Diagnostics.Append(req.Config.Get(ctx, &item)...)
	if resp.Diagnostics.HasError() {
		return
	}

	resp.Diagnostics.Append(item.As(ctx, &data, basetypes.ObjectAsOptions{
		UnhandledNullAsEmpty:    true,
		UnhandledUnknownAsEmpty: true,
	})...)

	if resp.Diagnostics.HasError() {
		return
	}

	var pluginID string
	pluginID = data.ID.ValueString()

	var controlPlaneID string
	controlPlaneID = data.ControlPlaneID.ValueString()

	request := operations.GetConfluentconsumePluginRequest{
		PluginID:       pluginID,
		ControlPlaneID: controlPlaneID,
	}
	res, err := r.client.Plugins.GetConfluentconsumePlugin(ctx, request)
	if err != nil {
		resp.Diagnostics.AddError("failure to invoke API", err.Error())
		if res != nil && res.RawResponse != nil {
			resp.Diagnostics.AddError("unexpected http request/response", debugResponse(res.RawResponse))
		}
		return
	}
	if res == nil {
		resp.Diagnostics.AddError("unexpected response from API", fmt.Sprintf("%v", res))
		return
	}
	if res.StatusCode == 404 {
		resp.State.RemoveResource(ctx)
		return
	}
	if res.StatusCode != 200 {
		resp.Diagnostics.AddError(fmt.Sprintf("unexpected response from API. Got an unexpected response code %v", res.StatusCode), debugResponse(res.RawResponse))
		return
	}
	if !(res.ConfluentConsumePlugin != nil) {
		resp.Diagnostics.AddError("unexpected response from API. Got an unexpected response body", debugResponse(res.RawResponse))
		return
	}
	resp.Diagnostics.Append(data.RefreshFromSharedConfluentConsumePlugin(ctx, res.ConfluentConsumePlugin)...)

	if resp.Diagnostics.HasError() {
		return
	}

	// Save updated data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
