// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/kong/terraform-provider-konnect/v3/internal/sdk/internal/utils"
)

type KafkaUpstreamPluginAfter struct {
	Access []string `json:"access,omitempty"`
}

func (k *KafkaUpstreamPluginAfter) GetAccess() []string {
	if k == nil {
		return nil
	}
	return k.Access
}

type KafkaUpstreamPluginBefore struct {
	Access []string `json:"access,omitempty"`
}

func (k *KafkaUpstreamPluginBefore) GetAccess() []string {
	if k == nil {
		return nil
	}
	return k.Access
}

type KafkaUpstreamPluginOrdering struct {
	After  *KafkaUpstreamPluginAfter  `json:"after,omitempty"`
	Before *KafkaUpstreamPluginBefore `json:"before,omitempty"`
}

func (k *KafkaUpstreamPluginOrdering) GetAfter() *KafkaUpstreamPluginAfter {
	if k == nil {
		return nil
	}
	return k.After
}

func (k *KafkaUpstreamPluginOrdering) GetBefore() *KafkaUpstreamPluginBefore {
	if k == nil {
		return nil
	}
	return k.Before
}

type KafkaUpstreamPluginPartials struct {
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	Name *string `json:"name,omitempty"`
	Path *string `json:"path,omitempty"`
}

func (k *KafkaUpstreamPluginPartials) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

func (k *KafkaUpstreamPluginPartials) GetName() *string {
	if k == nil {
		return nil
	}
	return k.Name
}

func (k *KafkaUpstreamPluginPartials) GetPath() *string {
	if k == nil {
		return nil
	}
	return k.Path
}

// KafkaUpstreamPluginMechanism - The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256`, or `SCRAM-SHA-512`.
type KafkaUpstreamPluginMechanism string

const (
	KafkaUpstreamPluginMechanismPlain       KafkaUpstreamPluginMechanism = "PLAIN"
	KafkaUpstreamPluginMechanismScramSha256 KafkaUpstreamPluginMechanism = "SCRAM-SHA-256"
	KafkaUpstreamPluginMechanismScramSha512 KafkaUpstreamPluginMechanism = "SCRAM-SHA-512"
)

func (e KafkaUpstreamPluginMechanism) ToPointer() *KafkaUpstreamPluginMechanism {
	return &e
}
func (e *KafkaUpstreamPluginMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PLAIN":
		fallthrough
	case "SCRAM-SHA-256":
		fallthrough
	case "SCRAM-SHA-512":
		*e = KafkaUpstreamPluginMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaUpstreamPluginMechanism: %v", v)
	}
}

// KafkaUpstreamPluginStrategy - The authentication strategy for the plugin, the only option for the value is `sasl`.
type KafkaUpstreamPluginStrategy string

const (
	KafkaUpstreamPluginStrategySasl KafkaUpstreamPluginStrategy = "sasl"
)

func (e KafkaUpstreamPluginStrategy) ToPointer() *KafkaUpstreamPluginStrategy {
	return &e
}
func (e *KafkaUpstreamPluginStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sasl":
		*e = KafkaUpstreamPluginStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaUpstreamPluginStrategy: %v", v)
	}
}

type KafkaUpstreamPluginAuthentication struct {
	// The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256`, or `SCRAM-SHA-512`.
	Mechanism *KafkaUpstreamPluginMechanism `json:"mechanism,omitempty"`
	// Password for SASL authentication.
	Password *string `default:"null" json:"password"`
	// The authentication strategy for the plugin, the only option for the value is `sasl`.
	Strategy *KafkaUpstreamPluginStrategy `json:"strategy,omitempty"`
	// Enable this to indicate `DelegationToken` authentication.
	Tokenauth *bool `default:"null" json:"tokenauth"`
	// Username for SASL authentication.
	User *string `default:"null" json:"user"`
}

func (k KafkaUpstreamPluginAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginAuthentication) GetMechanism() *KafkaUpstreamPluginMechanism {
	if k == nil {
		return nil
	}
	return k.Mechanism
}

func (k *KafkaUpstreamPluginAuthentication) GetPassword() *string {
	if k == nil {
		return nil
	}
	return k.Password
}

func (k *KafkaUpstreamPluginAuthentication) GetStrategy() *KafkaUpstreamPluginStrategy {
	if k == nil {
		return nil
	}
	return k.Strategy
}

func (k *KafkaUpstreamPluginAuthentication) GetTokenauth() *bool {
	if k == nil {
		return nil
	}
	return k.Tokenauth
}

func (k *KafkaUpstreamPluginAuthentication) GetUser() *string {
	if k == nil {
		return nil
	}
	return k.User
}

type KafkaUpstreamPluginBootstrapServers struct {
	// A string representing a host name, such as example.com.
	Host string `json:"host"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port int64 `json:"port"`
}

func (k *KafkaUpstreamPluginBootstrapServers) GetHost() string {
	if k == nil {
		return ""
	}
	return k.Host
}

func (k *KafkaUpstreamPluginBootstrapServers) GetPort() int64 {
	if k == nil {
		return 0
	}
	return k.Port
}

// KafkaUpstreamPluginProducerRequestAcks - The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
type KafkaUpstreamPluginProducerRequestAcks int64

const (
	KafkaUpstreamPluginProducerRequestAcksMinus1 KafkaUpstreamPluginProducerRequestAcks = -1
	KafkaUpstreamPluginProducerRequestAcksZero   KafkaUpstreamPluginProducerRequestAcks = 0
	KafkaUpstreamPluginProducerRequestAcksOne    KafkaUpstreamPluginProducerRequestAcks = 1
)

func (e KafkaUpstreamPluginProducerRequestAcks) ToPointer() *KafkaUpstreamPluginProducerRequestAcks {
	return &e
}
func (e *KafkaUpstreamPluginProducerRequestAcks) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case -1:
		fallthrough
	case 0:
		fallthrough
	case 1:
		*e = KafkaUpstreamPluginProducerRequestAcks(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaUpstreamPluginProducerRequestAcks: %v", v)
	}
}

type KafkaUpstreamPluginBasic struct {
	Password string `json:"password"`
	Username string `json:"username"`
}

func (k *KafkaUpstreamPluginBasic) GetPassword() string {
	if k == nil {
		return ""
	}
	return k.Password
}

func (k *KafkaUpstreamPluginBasic) GetUsername() string {
	if k == nil {
		return ""
	}
	return k.Username
}

// KafkaUpstreamPluginMode - Authentication mode to use with the schema registry.
type KafkaUpstreamPluginMode string

const (
	KafkaUpstreamPluginModeBasic KafkaUpstreamPluginMode = "basic"
	KafkaUpstreamPluginModeNone  KafkaUpstreamPluginMode = "none"
)

func (e KafkaUpstreamPluginMode) ToPointer() *KafkaUpstreamPluginMode {
	return &e
}
func (e *KafkaUpstreamPluginMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "none":
		*e = KafkaUpstreamPluginMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaUpstreamPluginMode: %v", v)
	}
}

type KafkaUpstreamPluginConfigAuthentication struct {
	Basic *KafkaUpstreamPluginBasic `json:"basic"`
	// Authentication mode to use with the schema registry.
	Mode *KafkaUpstreamPluginMode `default:"none" json:"mode"`
}

func (k KafkaUpstreamPluginConfigAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginConfigAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginConfigAuthentication) GetBasic() *KafkaUpstreamPluginBasic {
	if k == nil {
		return nil
	}
	return k.Basic
}

func (k *KafkaUpstreamPluginConfigAuthentication) GetMode() *KafkaUpstreamPluginMode {
	if k == nil {
		return nil
	}
	return k.Mode
}

type KafkaUpstreamPluginKeySchema struct {
	// The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.
	SchemaVersion *string `default:"null" json:"schema_version"`
	// The name of the subject
	SubjectName *string `default:"null" json:"subject_name"`
}

func (k KafkaUpstreamPluginKeySchema) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginKeySchema) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginKeySchema) GetSchemaVersion() *string {
	if k == nil {
		return nil
	}
	return k.SchemaVersion
}

func (k *KafkaUpstreamPluginKeySchema) GetSubjectName() *string {
	if k == nil {
		return nil
	}
	return k.SubjectName
}

type KafkaUpstreamPluginValueSchema struct {
	// The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.
	SchemaVersion *string `default:"null" json:"schema_version"`
	// The name of the subject
	SubjectName *string `default:"null" json:"subject_name"`
}

func (k KafkaUpstreamPluginValueSchema) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginValueSchema) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginValueSchema) GetSchemaVersion() *string {
	if k == nil {
		return nil
	}
	return k.SchemaVersion
}

func (k *KafkaUpstreamPluginValueSchema) GetSubjectName() *string {
	if k == nil {
		return nil
	}
	return k.SubjectName
}

type KafkaUpstreamPluginConfluent struct {
	Authentication *KafkaUpstreamPluginConfigAuthentication `json:"authentication"`
	KeySchema      *KafkaUpstreamPluginKeySchema            `json:"key_schema"`
	// Set to false to disable SSL certificate verification when connecting to the schema registry.
	SslVerify *bool `default:"true" json:"ssl_verify"`
	// The TTL in seconds for the schema registry cache.
	TTL *float64 `default:"null" json:"ttl"`
	// The URL of the schema registry.
	URL         *string                         `default:"null" json:"url"`
	ValueSchema *KafkaUpstreamPluginValueSchema `json:"value_schema"`
}

func (k KafkaUpstreamPluginConfluent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginConfluent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginConfluent) GetAuthentication() *KafkaUpstreamPluginConfigAuthentication {
	if k == nil {
		return nil
	}
	return k.Authentication
}

func (k *KafkaUpstreamPluginConfluent) GetKeySchema() *KafkaUpstreamPluginKeySchema {
	if k == nil {
		return nil
	}
	return k.KeySchema
}

func (k *KafkaUpstreamPluginConfluent) GetSslVerify() *bool {
	if k == nil {
		return nil
	}
	return k.SslVerify
}

func (k *KafkaUpstreamPluginConfluent) GetTTL() *float64 {
	if k == nil {
		return nil
	}
	return k.TTL
}

func (k *KafkaUpstreamPluginConfluent) GetURL() *string {
	if k == nil {
		return nil
	}
	return k.URL
}

func (k *KafkaUpstreamPluginConfluent) GetValueSchema() *KafkaUpstreamPluginValueSchema {
	if k == nil {
		return nil
	}
	return k.ValueSchema
}

// KafkaUpstreamPluginSchemaRegistry - The plugin-global schema registry configuration. This can be overwritten by the topic configuration.
type KafkaUpstreamPluginSchemaRegistry struct {
	Confluent *KafkaUpstreamPluginConfluent `json:"confluent"`
}

func (k *KafkaUpstreamPluginSchemaRegistry) GetConfluent() *KafkaUpstreamPluginConfluent {
	if k == nil {
		return nil
	}
	return k.Confluent
}

type KafkaUpstreamPluginSecurity struct {
	// UUID of certificate entity for mTLS authentication.
	CertificateID *string `default:"null" json:"certificate_id"`
	// Enables TLS.
	Ssl *bool `default:"null" json:"ssl"`
}

func (k KafkaUpstreamPluginSecurity) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginSecurity) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginSecurity) GetCertificateID() *string {
	if k == nil {
		return nil
	}
	return k.CertificateID
}

func (k *KafkaUpstreamPluginSecurity) GetSsl() *bool {
	if k == nil {
		return nil
	}
	return k.Ssl
}

type KafkaUpstreamPluginConfig struct {
	// The list of allowed topic names to which messages can be sent. The default topic configured in the `topic` field is always allowed, regardless of its inclusion in `allowed_topics`.
	AllowedTopics  []string                           `json:"allowed_topics"`
	Authentication *KafkaUpstreamPluginAuthentication `json:"authentication"`
	// Set of bootstrap brokers in a `{host: host, port: port}` list format.
	BootstrapServers []KafkaUpstreamPluginBootstrapServers `json:"bootstrap_servers"`
	// An identifier for the Kafka cluster. By default, this field generates a random string. You can also set your own custom cluster identifier.  If more than one Kafka plugin is configured without a `cluster_name` (that is, if the default autogenerated value is removed), these plugins will use the same producer, and by extension, the same cluster. Logs will be sent to the leader of the cluster.
	ClusterName *string `default:"null" json:"cluster_name"`
	// Include the request body in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardBody *bool `default:"true" json:"forward_body"`
	// Include the request headers in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardHeaders *bool `default:"false" json:"forward_headers"`
	// Include the request method in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardMethod *bool `default:"false" json:"forward_method"`
	// Include the request URI and URI arguments (as in, query arguments) in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardURI *bool `default:"false" json:"forward_uri"`
	// Keepalive timeout in milliseconds.
	Keepalive        *int64 `default:"60000" json:"keepalive"`
	KeepaliveEnabled *bool  `default:"false" json:"keepalive_enabled"`
	// The request query parameter name that contains the Kafka message key. If specified, messages with the same key will be sent to the same Kafka partition, ensuring consistent ordering.
	KeyQueryArg *string `default:"null" json:"key_query_arg"`
	// The Lua functions that manipulates the message being sent to the Kafka topic.
	MessageByLuaFunctions []string `json:"message_by_lua_functions"`
	// Flag to enable asynchronous mode.
	ProducerAsync *bool `default:"true" json:"producer_async"`
	// Maximum number of messages that can be buffered in memory in asynchronous mode.
	ProducerAsyncBufferingLimitsMessagesInMemory *int64 `default:"50000" json:"producer_async_buffering_limits_messages_in_memory"`
	// Maximum time interval in milliseconds between buffer flushes in asynchronous mode.
	ProducerAsyncFlushTimeout *int64 `default:"1000" json:"producer_async_flush_timeout"`
	// The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
	ProducerRequestAcks *KafkaUpstreamPluginProducerRequestAcks `default:"1" json:"producer_request_acks"`
	// Maximum size of a Produce request in bytes.
	ProducerRequestLimitsBytesPerRequest *int64 `default:"1048576" json:"producer_request_limits_bytes_per_request"`
	// Maximum number of messages to include into a single producer request.
	ProducerRequestLimitsMessagesPerRequest *int64 `default:"200" json:"producer_request_limits_messages_per_request"`
	// Backoff interval between retry attempts in milliseconds.
	ProducerRequestRetriesBackoffTimeout *int64 `default:"100" json:"producer_request_retries_backoff_timeout"`
	// Maximum number of retry attempts per single Produce request.
	ProducerRequestRetriesMaxAttempts *int64 `default:"10" json:"producer_request_retries_max_attempts"`
	// Time to wait for a Produce response in milliseconds.
	ProducerRequestTimeout *int64 `default:"2000" json:"producer_request_timeout"`
	// The plugin-global schema registry configuration. This can be overwritten by the topic configuration.
	SchemaRegistry *KafkaUpstreamPluginSchemaRegistry `json:"schema_registry"`
	Security       *KafkaUpstreamPluginSecurity       `json:"security"`
	// Socket timeout in milliseconds.
	Timeout *int64 `default:"10000" json:"timeout"`
	// The default Kafka topic to publish to if the query parameter defined in the `topics_query_arg` does not exist in the request
	Topic string `json:"topic"`
	// The request query parameter name that contains the topics to publish to
	TopicsQueryArg *string `default:"null" json:"topics_query_arg"`
}

func (k KafkaUpstreamPluginConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPluginConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, []string{"topic"}); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPluginConfig) GetAllowedTopics() []string {
	if k == nil {
		return nil
	}
	return k.AllowedTopics
}

func (k *KafkaUpstreamPluginConfig) GetAuthentication() *KafkaUpstreamPluginAuthentication {
	if k == nil {
		return nil
	}
	return k.Authentication
}

func (k *KafkaUpstreamPluginConfig) GetBootstrapServers() []KafkaUpstreamPluginBootstrapServers {
	if k == nil {
		return nil
	}
	return k.BootstrapServers
}

func (k *KafkaUpstreamPluginConfig) GetClusterName() *string {
	if k == nil {
		return nil
	}
	return k.ClusterName
}

func (k *KafkaUpstreamPluginConfig) GetForwardBody() *bool {
	if k == nil {
		return nil
	}
	return k.ForwardBody
}

func (k *KafkaUpstreamPluginConfig) GetForwardHeaders() *bool {
	if k == nil {
		return nil
	}
	return k.ForwardHeaders
}

func (k *KafkaUpstreamPluginConfig) GetForwardMethod() *bool {
	if k == nil {
		return nil
	}
	return k.ForwardMethod
}

func (k *KafkaUpstreamPluginConfig) GetForwardURI() *bool {
	if k == nil {
		return nil
	}
	return k.ForwardURI
}

func (k *KafkaUpstreamPluginConfig) GetKeepalive() *int64 {
	if k == nil {
		return nil
	}
	return k.Keepalive
}

func (k *KafkaUpstreamPluginConfig) GetKeepaliveEnabled() *bool {
	if k == nil {
		return nil
	}
	return k.KeepaliveEnabled
}

func (k *KafkaUpstreamPluginConfig) GetKeyQueryArg() *string {
	if k == nil {
		return nil
	}
	return k.KeyQueryArg
}

func (k *KafkaUpstreamPluginConfig) GetMessageByLuaFunctions() []string {
	if k == nil {
		return nil
	}
	return k.MessageByLuaFunctions
}

func (k *KafkaUpstreamPluginConfig) GetProducerAsync() *bool {
	if k == nil {
		return nil
	}
	return k.ProducerAsync
}

func (k *KafkaUpstreamPluginConfig) GetProducerAsyncBufferingLimitsMessagesInMemory() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerAsyncBufferingLimitsMessagesInMemory
}

func (k *KafkaUpstreamPluginConfig) GetProducerAsyncFlushTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerAsyncFlushTimeout
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestAcks() *KafkaUpstreamPluginProducerRequestAcks {
	if k == nil {
		return nil
	}
	return k.ProducerRequestAcks
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestLimitsBytesPerRequest() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestLimitsBytesPerRequest
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestLimitsMessagesPerRequest() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestLimitsMessagesPerRequest
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestRetriesBackoffTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestRetriesBackoffTimeout
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestRetriesMaxAttempts() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestRetriesMaxAttempts
}

func (k *KafkaUpstreamPluginConfig) GetProducerRequestTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestTimeout
}

func (k *KafkaUpstreamPluginConfig) GetSchemaRegistry() *KafkaUpstreamPluginSchemaRegistry {
	if k == nil {
		return nil
	}
	return k.SchemaRegistry
}

func (k *KafkaUpstreamPluginConfig) GetSecurity() *KafkaUpstreamPluginSecurity {
	if k == nil {
		return nil
	}
	return k.Security
}

func (k *KafkaUpstreamPluginConfig) GetTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.Timeout
}

func (k *KafkaUpstreamPluginConfig) GetTopic() string {
	if k == nil {
		return ""
	}
	return k.Topic
}

func (k *KafkaUpstreamPluginConfig) GetTopicsQueryArg() *string {
	if k == nil {
		return nil
	}
	return k.TopicsQueryArg
}

// KafkaUpstreamPluginConsumer - If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
type KafkaUpstreamPluginConsumer struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaUpstreamPluginConsumer) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

type KafkaUpstreamPluginProtocols string

const (
	KafkaUpstreamPluginProtocolsGrpc  KafkaUpstreamPluginProtocols = "grpc"
	KafkaUpstreamPluginProtocolsGrpcs KafkaUpstreamPluginProtocols = "grpcs"
	KafkaUpstreamPluginProtocolsHTTP  KafkaUpstreamPluginProtocols = "http"
	KafkaUpstreamPluginProtocolsHTTPS KafkaUpstreamPluginProtocols = "https"
)

func (e KafkaUpstreamPluginProtocols) ToPointer() *KafkaUpstreamPluginProtocols {
	return &e
}
func (e *KafkaUpstreamPluginProtocols) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "grpcs":
		fallthrough
	case "http":
		fallthrough
	case "https":
		*e = KafkaUpstreamPluginProtocols(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaUpstreamPluginProtocols: %v", v)
	}
}

// KafkaUpstreamPluginRoute - If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
type KafkaUpstreamPluginRoute struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaUpstreamPluginRoute) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

// KafkaUpstreamPluginService - If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
type KafkaUpstreamPluginService struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaUpstreamPluginService) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

// KafkaUpstreamPlugin - A Plugin entity represents a plugin configuration that will be executed during the HTTP request/response lifecycle. It is how you can add functionalities to Services that run behind Kong, like Authentication or Rate Limiting for example. You can find more information about how to install and what values each plugin takes by visiting the [Kong Hub](https://docs.konghq.com/hub/). When adding a Plugin Configuration to a Service, every request made by a client to that Service will run said Plugin. If a Plugin needs to be tuned to different values for some specific Consumers, you can do so by creating a separate plugin instance that specifies both the Service and the Consumer, through the `service` and `consumer` fields.
type KafkaUpstreamPlugin struct {
	// Unix epoch when the resource was created.
	CreatedAt *int64 `json:"created_at,omitempty"`
	// Whether the plugin is applied.
	Enabled *bool `default:"true" json:"enabled"`
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	InstanceName *string                      `default:"null" json:"instance_name"`
	name         string                       `const:"kafka-upstream" json:"name"`
	Ordering     *KafkaUpstreamPluginOrdering `json:"ordering"`
	// A list of partials to be used by the plugin.
	Partials []KafkaUpstreamPluginPartials `json:"partials"`
	// An optional set of strings associated with the Plugin for grouping and filtering.
	Tags []string `json:"tags"`
	// Unix epoch when the resource was last updated.
	UpdatedAt *int64                    `json:"updated_at,omitempty"`
	Config    KafkaUpstreamPluginConfig `json:"config"`
	// If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
	Consumer *KafkaUpstreamPluginConsumer `json:"consumer"`
	// A set of strings representing HTTP protocols.
	Protocols []KafkaUpstreamPluginProtocols `json:"protocols"`
	// If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
	Route *KafkaUpstreamPluginRoute `json:"route"`
	// If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
	Service *KafkaUpstreamPluginService `json:"service"`
}

func (k KafkaUpstreamPlugin) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaUpstreamPlugin) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, []string{"name", "config"}); err != nil {
		return err
	}
	return nil
}

func (k *KafkaUpstreamPlugin) GetCreatedAt() *int64 {
	if k == nil {
		return nil
	}
	return k.CreatedAt
}

func (k *KafkaUpstreamPlugin) GetEnabled() *bool {
	if k == nil {
		return nil
	}
	return k.Enabled
}

func (k *KafkaUpstreamPlugin) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

func (k *KafkaUpstreamPlugin) GetInstanceName() *string {
	if k == nil {
		return nil
	}
	return k.InstanceName
}

func (k *KafkaUpstreamPlugin) GetName() string {
	return "kafka-upstream"
}

func (k *KafkaUpstreamPlugin) GetOrdering() *KafkaUpstreamPluginOrdering {
	if k == nil {
		return nil
	}
	return k.Ordering
}

func (k *KafkaUpstreamPlugin) GetPartials() []KafkaUpstreamPluginPartials {
	if k == nil {
		return nil
	}
	return k.Partials
}

func (k *KafkaUpstreamPlugin) GetTags() []string {
	if k == nil {
		return nil
	}
	return k.Tags
}

func (k *KafkaUpstreamPlugin) GetUpdatedAt() *int64 {
	if k == nil {
		return nil
	}
	return k.UpdatedAt
}

func (k *KafkaUpstreamPlugin) GetConfig() KafkaUpstreamPluginConfig {
	if k == nil {
		return KafkaUpstreamPluginConfig{}
	}
	return k.Config
}

func (k *KafkaUpstreamPlugin) GetConsumer() *KafkaUpstreamPluginConsumer {
	if k == nil {
		return nil
	}
	return k.Consumer
}

func (k *KafkaUpstreamPlugin) GetProtocols() []KafkaUpstreamPluginProtocols {
	if k == nil {
		return nil
	}
	return k.Protocols
}

func (k *KafkaUpstreamPlugin) GetRoute() *KafkaUpstreamPluginRoute {
	if k == nil {
		return nil
	}
	return k.Route
}

func (k *KafkaUpstreamPlugin) GetService() *KafkaUpstreamPluginService {
	if k == nil {
		return nil
	}
	return k.Service
}
