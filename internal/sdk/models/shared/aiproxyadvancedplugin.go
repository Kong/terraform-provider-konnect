// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/kong/terraform-provider-konnect/v3/internal/sdk/internal/utils"
)

type AiProxyAdvancedPluginAfter struct {
	Access []string `json:"access,omitempty"`
}

func (a *AiProxyAdvancedPluginAfter) GetAccess() []string {
	if a == nil {
		return nil
	}
	return a.Access
}

type AiProxyAdvancedPluginBefore struct {
	Access []string `json:"access,omitempty"`
}

func (a *AiProxyAdvancedPluginBefore) GetAccess() []string {
	if a == nil {
		return nil
	}
	return a.Access
}

type AiProxyAdvancedPluginOrdering struct {
	After  *AiProxyAdvancedPluginAfter  `json:"after,omitempty"`
	Before *AiProxyAdvancedPluginBefore `json:"before,omitempty"`
}

func (a *AiProxyAdvancedPluginOrdering) GetAfter() *AiProxyAdvancedPluginAfter {
	if a == nil {
		return nil
	}
	return a.After
}

func (a *AiProxyAdvancedPluginOrdering) GetBefore() *AiProxyAdvancedPluginBefore {
	if a == nil {
		return nil
	}
	return a.Before
}

type AiProxyAdvancedPluginPartials struct {
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	Name *string `json:"name,omitempty"`
	Path *string `json:"path,omitempty"`
}

func (a *AiProxyAdvancedPluginPartials) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

func (a *AiProxyAdvancedPluginPartials) GetName() *string {
	if a == nil {
		return nil
	}
	return a.Name
}

func (a *AiProxyAdvancedPluginPartials) GetPath() *string {
	if a == nil {
		return nil
	}
	return a.Path
}

// AiProxyAdvancedPluginAlgorithm - Which load balancing algorithm to use.
type AiProxyAdvancedPluginAlgorithm string

const (
	AiProxyAdvancedPluginAlgorithmConsistentHashing AiProxyAdvancedPluginAlgorithm = "consistent-hashing"
	AiProxyAdvancedPluginAlgorithmLowestLatency     AiProxyAdvancedPluginAlgorithm = "lowest-latency"
	AiProxyAdvancedPluginAlgorithmLowestUsage       AiProxyAdvancedPluginAlgorithm = "lowest-usage"
	AiProxyAdvancedPluginAlgorithmPriority          AiProxyAdvancedPluginAlgorithm = "priority"
	AiProxyAdvancedPluginAlgorithmRoundRobin        AiProxyAdvancedPluginAlgorithm = "round-robin"
	AiProxyAdvancedPluginAlgorithmSemantic          AiProxyAdvancedPluginAlgorithm = "semantic"
)

func (e AiProxyAdvancedPluginAlgorithm) ToPointer() *AiProxyAdvancedPluginAlgorithm {
	return &e
}
func (e *AiProxyAdvancedPluginAlgorithm) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "consistent-hashing":
		fallthrough
	case "lowest-latency":
		fallthrough
	case "lowest-usage":
		fallthrough
	case "priority":
		fallthrough
	case "round-robin":
		fallthrough
	case "semantic":
		*e = AiProxyAdvancedPluginAlgorithm(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginAlgorithm: %v", v)
	}
}

type FailoverCriteria string

const (
	FailoverCriteriaError         FailoverCriteria = "error"
	FailoverCriteriaHttp403       FailoverCriteria = "http_403"
	FailoverCriteriaHttp404       FailoverCriteria = "http_404"
	FailoverCriteriaHttp429       FailoverCriteria = "http_429"
	FailoverCriteriaHttp500       FailoverCriteria = "http_500"
	FailoverCriteriaHttp502       FailoverCriteria = "http_502"
	FailoverCriteriaHttp503       FailoverCriteria = "http_503"
	FailoverCriteriaHttp504       FailoverCriteria = "http_504"
	FailoverCriteriaInvalidHeader FailoverCriteria = "invalid_header"
	FailoverCriteriaNonIdempotent FailoverCriteria = "non_idempotent"
	FailoverCriteriaTimeout       FailoverCriteria = "timeout"
)

func (e FailoverCriteria) ToPointer() *FailoverCriteria {
	return &e
}
func (e *FailoverCriteria) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "error":
		fallthrough
	case "http_403":
		fallthrough
	case "http_404":
		fallthrough
	case "http_429":
		fallthrough
	case "http_500":
		fallthrough
	case "http_502":
		fallthrough
	case "http_503":
		fallthrough
	case "http_504":
		fallthrough
	case "invalid_header":
		fallthrough
	case "non_idempotent":
		fallthrough
	case "timeout":
		*e = FailoverCriteria(v)
		return nil
	default:
		return fmt.Errorf("invalid value for FailoverCriteria: %v", v)
	}
}

// LatencyStrategy - What metrics to use for latency. Available values are: `tpot` (time-per-output-token) and `e2e`.
type LatencyStrategy string

const (
	LatencyStrategyE2e  LatencyStrategy = "e2e"
	LatencyStrategyTpot LatencyStrategy = "tpot"
)

func (e LatencyStrategy) ToPointer() *LatencyStrategy {
	return &e
}
func (e *LatencyStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "e2e":
		fallthrough
	case "tpot":
		*e = LatencyStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for LatencyStrategy: %v", v)
	}
}

// AiProxyAdvancedPluginTokensCountStrategy - What tokens to use for usage calculation. Available values are: `total_tokens` `prompt_tokens`, `completion_tokens` and `cost`.
type AiProxyAdvancedPluginTokensCountStrategy string

const (
	AiProxyAdvancedPluginTokensCountStrategyCompletionTokens AiProxyAdvancedPluginTokensCountStrategy = "completion-tokens"
	AiProxyAdvancedPluginTokensCountStrategyCost             AiProxyAdvancedPluginTokensCountStrategy = "cost"
	AiProxyAdvancedPluginTokensCountStrategyLlmAccuracy      AiProxyAdvancedPluginTokensCountStrategy = "llm-accuracy"
	AiProxyAdvancedPluginTokensCountStrategyPromptTokens     AiProxyAdvancedPluginTokensCountStrategy = "prompt-tokens"
	AiProxyAdvancedPluginTokensCountStrategyTotalTokens      AiProxyAdvancedPluginTokensCountStrategy = "total-tokens"
)

func (e AiProxyAdvancedPluginTokensCountStrategy) ToPointer() *AiProxyAdvancedPluginTokensCountStrategy {
	return &e
}
func (e *AiProxyAdvancedPluginTokensCountStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "completion-tokens":
		fallthrough
	case "cost":
		fallthrough
	case "llm-accuracy":
		fallthrough
	case "prompt-tokens":
		fallthrough
	case "total-tokens":
		*e = AiProxyAdvancedPluginTokensCountStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginTokensCountStrategy: %v", v)
	}
}

type Balancer struct {
	// Which load balancing algorithm to use.
	Algorithm      *AiProxyAdvancedPluginAlgorithm `default:"round-robin" json:"algorithm"`
	ConnectTimeout *int64                          `default:"60000" json:"connect_timeout"`
	// Specifies in which cases an upstream response should be failover to the next target. Each option in the array is equivalent to the function of http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream
	FailoverCriteria []FailoverCriteria `json:"failover_criteria,omitempty"`
	// The header to use for consistent-hashing.
	HashOnHeader *string `default:"X-Kong-LLM-Request-ID" json:"hash_on_header"`
	// What metrics to use for latency. Available values are: `tpot` (time-per-output-token) and `e2e`.
	LatencyStrategy *LatencyStrategy `default:"tpot" json:"latency_strategy"`
	ReadTimeout     *int64           `default:"60000" json:"read_timeout"`
	// The number of retries to execute upon failure to proxy.
	Retries *int64 `default:"5" json:"retries"`
	// The number of slots in the load balancer algorithm.
	Slots *int64 `default:"10000" json:"slots"`
	// What tokens to use for usage calculation. Available values are: `total_tokens` `prompt_tokens`, `completion_tokens` and `cost`.
	TokensCountStrategy *AiProxyAdvancedPluginTokensCountStrategy `default:"total-tokens" json:"tokens_count_strategy"`
	WriteTimeout        *int64                                    `default:"60000" json:"write_timeout"`
}

func (b Balancer) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(b, "", false)
}

func (b *Balancer) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &b, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (b *Balancer) GetAlgorithm() *AiProxyAdvancedPluginAlgorithm {
	if b == nil {
		return nil
	}
	return b.Algorithm
}

func (b *Balancer) GetConnectTimeout() *int64 {
	if b == nil {
		return nil
	}
	return b.ConnectTimeout
}

func (b *Balancer) GetFailoverCriteria() []FailoverCriteria {
	if b == nil {
		return nil
	}
	return b.FailoverCriteria
}

func (b *Balancer) GetHashOnHeader() *string {
	if b == nil {
		return nil
	}
	return b.HashOnHeader
}

func (b *Balancer) GetLatencyStrategy() *LatencyStrategy {
	if b == nil {
		return nil
	}
	return b.LatencyStrategy
}

func (b *Balancer) GetReadTimeout() *int64 {
	if b == nil {
		return nil
	}
	return b.ReadTimeout
}

func (b *Balancer) GetRetries() *int64 {
	if b == nil {
		return nil
	}
	return b.Retries
}

func (b *Balancer) GetSlots() *int64 {
	if b == nil {
		return nil
	}
	return b.Slots
}

func (b *Balancer) GetTokensCountStrategy() *AiProxyAdvancedPluginTokensCountStrategy {
	if b == nil {
		return nil
	}
	return b.TokensCountStrategy
}

func (b *Balancer) GetWriteTimeout() *int64 {
	if b == nil {
		return nil
	}
	return b.WriteTimeout
}

// AiProxyAdvancedPluginParamLocation - Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.
type AiProxyAdvancedPluginParamLocation string

const (
	AiProxyAdvancedPluginParamLocationBody  AiProxyAdvancedPluginParamLocation = "body"
	AiProxyAdvancedPluginParamLocationQuery AiProxyAdvancedPluginParamLocation = "query"
)

func (e AiProxyAdvancedPluginParamLocation) ToPointer() *AiProxyAdvancedPluginParamLocation {
	return &e
}
func (e *AiProxyAdvancedPluginParamLocation) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "body":
		fallthrough
	case "query":
		*e = AiProxyAdvancedPluginParamLocation(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginParamLocation: %v", v)
	}
}

type AiProxyAdvancedPluginAuth struct {
	// If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin.
	AllowOverride *bool `default:"false" json:"allow_override"`
	// Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.
	AwsAccessKeyID *string `default:"null" json:"aws_access_key_id"`
	// Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.
	AwsSecretAccessKey *string `default:"null" json:"aws_secret_access_key"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.
	AzureClientID *string `default:"null" json:"azure_client_id"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.
	AzureClientSecret *string `default:"null" json:"azure_client_secret"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.
	AzureTenantID *string `default:"null" json:"azure_tenant_id"`
	// Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models.
	AzureUseManagedIdentity *bool `default:"false" json:"azure_use_managed_identity"`
	// Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.
	GcpServiceAccountJSON *string `default:"null" json:"gcp_service_account_json"`
	// Use service account auth for GCP-based providers and models.
	GcpUseServiceAccount *bool `default:"false" json:"gcp_use_service_account"`
	// If AI model requires authentication via Authorization or API key header, specify its name here.
	HeaderName *string `default:"null" json:"header_name"`
	// Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.
	HeaderValue *string `default:"null" json:"header_value"`
	// Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.
	ParamLocation *AiProxyAdvancedPluginParamLocation `json:"param_location,omitempty"`
	// If AI model requires authentication via query parameter, specify its name here.
	ParamName *string `default:"null" json:"param_name"`
	// Specify the full parameter value for 'param_name'.
	ParamValue *string `default:"null" json:"param_value"`
}

func (a AiProxyAdvancedPluginAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginAuth) GetAllowOverride() *bool {
	if a == nil {
		return nil
	}
	return a.AllowOverride
}

func (a *AiProxyAdvancedPluginAuth) GetAwsAccessKeyID() *string {
	if a == nil {
		return nil
	}
	return a.AwsAccessKeyID
}

func (a *AiProxyAdvancedPluginAuth) GetAwsSecretAccessKey() *string {
	if a == nil {
		return nil
	}
	return a.AwsSecretAccessKey
}

func (a *AiProxyAdvancedPluginAuth) GetAzureClientID() *string {
	if a == nil {
		return nil
	}
	return a.AzureClientID
}

func (a *AiProxyAdvancedPluginAuth) GetAzureClientSecret() *string {
	if a == nil {
		return nil
	}
	return a.AzureClientSecret
}

func (a *AiProxyAdvancedPluginAuth) GetAzureTenantID() *string {
	if a == nil {
		return nil
	}
	return a.AzureTenantID
}

func (a *AiProxyAdvancedPluginAuth) GetAzureUseManagedIdentity() *bool {
	if a == nil {
		return nil
	}
	return a.AzureUseManagedIdentity
}

func (a *AiProxyAdvancedPluginAuth) GetGcpServiceAccountJSON() *string {
	if a == nil {
		return nil
	}
	return a.GcpServiceAccountJSON
}

func (a *AiProxyAdvancedPluginAuth) GetGcpUseServiceAccount() *bool {
	if a == nil {
		return nil
	}
	return a.GcpUseServiceAccount
}

func (a *AiProxyAdvancedPluginAuth) GetHeaderName() *string {
	if a == nil {
		return nil
	}
	return a.HeaderName
}

func (a *AiProxyAdvancedPluginAuth) GetHeaderValue() *string {
	if a == nil {
		return nil
	}
	return a.HeaderValue
}

func (a *AiProxyAdvancedPluginAuth) GetParamLocation() *AiProxyAdvancedPluginParamLocation {
	if a == nil {
		return nil
	}
	return a.ParamLocation
}

func (a *AiProxyAdvancedPluginAuth) GetParamName() *string {
	if a == nil {
		return nil
	}
	return a.ParamName
}

func (a *AiProxyAdvancedPluginAuth) GetParamValue() *string {
	if a == nil {
		return nil
	}
	return a.ParamValue
}

type Azure struct {
	// 'api-version' for Azure OpenAI instances.
	APIVersion *string `default:"2023-05-15" json:"api_version"`
	// Deployment ID for Azure OpenAI instances.
	DeploymentID *string `default:"null" json:"deployment_id"`
	// Instance name for Azure OpenAI hosted models.
	Instance *string `default:"null" json:"instance"`
}

func (a Azure) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *Azure) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *Azure) GetAPIVersion() *string {
	if a == nil {
		return nil
	}
	return a.APIVersion
}

func (a *Azure) GetDeploymentID() *string {
	if a == nil {
		return nil
	}
	return a.DeploymentID
}

func (a *Azure) GetInstance() *string {
	if a == nil {
		return nil
	}
	return a.Instance
}

type AiProxyAdvancedPluginBedrock struct {
	// If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.
	AwsAssumeRoleArn *string `default:"null" json:"aws_assume_role_arn"`
	// If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.
	AwsRegion *string `default:"null" json:"aws_region"`
	// If using AWS providers (Bedrock), set the identifier of the assumed role session.
	AwsRoleSessionName *string `default:"null" json:"aws_role_session_name"`
	// If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.
	AwsStsEndpointURL *string `default:"null" json:"aws_sts_endpoint_url"`
	// If using AWS providers (Bedrock), set to true to normalize the embeddings.
	EmbeddingsNormalize *bool `default:"false" json:"embeddings_normalize"`
	// Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.
	PerformanceConfigLatency *string `default:"null" json:"performance_config_latency"`
}

func (a AiProxyAdvancedPluginBedrock) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginBedrock) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginBedrock) GetAwsAssumeRoleArn() *string {
	if a == nil {
		return nil
	}
	return a.AwsAssumeRoleArn
}

func (a *AiProxyAdvancedPluginBedrock) GetAwsRegion() *string {
	if a == nil {
		return nil
	}
	return a.AwsRegion
}

func (a *AiProxyAdvancedPluginBedrock) GetAwsRoleSessionName() *string {
	if a == nil {
		return nil
	}
	return a.AwsRoleSessionName
}

func (a *AiProxyAdvancedPluginBedrock) GetAwsStsEndpointURL() *string {
	if a == nil {
		return nil
	}
	return a.AwsStsEndpointURL
}

func (a *AiProxyAdvancedPluginBedrock) GetEmbeddingsNormalize() *bool {
	if a == nil {
		return nil
	}
	return a.EmbeddingsNormalize
}

func (a *AiProxyAdvancedPluginBedrock) GetPerformanceConfigLatency() *string {
	if a == nil {
		return nil
	}
	return a.PerformanceConfigLatency
}

type AiProxyAdvancedPluginGemini struct {
	// If running Gemini on Vertex, specify the regional API endpoint (hostname only).
	APIEndpoint *string `default:"null" json:"api_endpoint"`
	// If running Gemini on Vertex, specify the location ID.
	LocationID *string `default:"null" json:"location_id"`
	// If running Gemini on Vertex, specify the project ID.
	ProjectID *string `default:"null" json:"project_id"`
}

func (a AiProxyAdvancedPluginGemini) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginGemini) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginGemini) GetAPIEndpoint() *string {
	if a == nil {
		return nil
	}
	return a.APIEndpoint
}

func (a *AiProxyAdvancedPluginGemini) GetLocationID() *string {
	if a == nil {
		return nil
	}
	return a.LocationID
}

func (a *AiProxyAdvancedPluginGemini) GetProjectID() *string {
	if a == nil {
		return nil
	}
	return a.ProjectID
}

type AiProxyAdvancedPluginHuggingface struct {
	// Use the cache layer on the inference API
	UseCache *bool `default:"null" json:"use_cache"`
	// Wait for the model if it is not ready
	WaitForModel *bool `default:"null" json:"wait_for_model"`
}

func (a AiProxyAdvancedPluginHuggingface) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginHuggingface) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginHuggingface) GetUseCache() *bool {
	if a == nil {
		return nil
	}
	return a.UseCache
}

func (a *AiProxyAdvancedPluginHuggingface) GetWaitForModel() *bool {
	if a == nil {
		return nil
	}
	return a.WaitForModel
}

// AiProxyAdvancedPluginOptions - Key/value settings for the model
type AiProxyAdvancedPluginOptions struct {
	Azure       *Azure                            `json:"azure"`
	Bedrock     *AiProxyAdvancedPluginBedrock     `json:"bedrock"`
	Gemini      *AiProxyAdvancedPluginGemini      `json:"gemini"`
	Huggingface *AiProxyAdvancedPluginHuggingface `json:"huggingface"`
	// upstream url for the embeddings
	UpstreamURL *string `default:"null" json:"upstream_url"`
}

func (a AiProxyAdvancedPluginOptions) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginOptions) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginOptions) GetAzure() *Azure {
	if a == nil {
		return nil
	}
	return a.Azure
}

func (a *AiProxyAdvancedPluginOptions) GetBedrock() *AiProxyAdvancedPluginBedrock {
	if a == nil {
		return nil
	}
	return a.Bedrock
}

func (a *AiProxyAdvancedPluginOptions) GetGemini() *AiProxyAdvancedPluginGemini {
	if a == nil {
		return nil
	}
	return a.Gemini
}

func (a *AiProxyAdvancedPluginOptions) GetHuggingface() *AiProxyAdvancedPluginHuggingface {
	if a == nil {
		return nil
	}
	return a.Huggingface
}

func (a *AiProxyAdvancedPluginOptions) GetUpstreamURL() *string {
	if a == nil {
		return nil
	}
	return a.UpstreamURL
}

// AiProxyAdvancedPluginProvider - AI provider format to use for embeddings API
type AiProxyAdvancedPluginProvider string

const (
	AiProxyAdvancedPluginProviderAzure       AiProxyAdvancedPluginProvider = "azure"
	AiProxyAdvancedPluginProviderBedrock     AiProxyAdvancedPluginProvider = "bedrock"
	AiProxyAdvancedPluginProviderGemini      AiProxyAdvancedPluginProvider = "gemini"
	AiProxyAdvancedPluginProviderHuggingface AiProxyAdvancedPluginProvider = "huggingface"
	AiProxyAdvancedPluginProviderMistral     AiProxyAdvancedPluginProvider = "mistral"
	AiProxyAdvancedPluginProviderOpenai      AiProxyAdvancedPluginProvider = "openai"
)

func (e AiProxyAdvancedPluginProvider) ToPointer() *AiProxyAdvancedPluginProvider {
	return &e
}
func (e *AiProxyAdvancedPluginProvider) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure":
		fallthrough
	case "bedrock":
		fallthrough
	case "gemini":
		fallthrough
	case "huggingface":
		fallthrough
	case "mistral":
		fallthrough
	case "openai":
		*e = AiProxyAdvancedPluginProvider(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginProvider: %v", v)
	}
}

type AiProxyAdvancedPluginModel struct {
	// Model name to execute.
	Name string `json:"name"`
	// Key/value settings for the model
	Options *AiProxyAdvancedPluginOptions `json:"options"`
	// AI provider format to use for embeddings API
	Provider AiProxyAdvancedPluginProvider `json:"provider"`
}

func (a *AiProxyAdvancedPluginModel) GetName() string {
	if a == nil {
		return ""
	}
	return a.Name
}

func (a *AiProxyAdvancedPluginModel) GetOptions() *AiProxyAdvancedPluginOptions {
	if a == nil {
		return nil
	}
	return a.Options
}

func (a *AiProxyAdvancedPluginModel) GetProvider() AiProxyAdvancedPluginProvider {
	if a == nil {
		return AiProxyAdvancedPluginProvider("")
	}
	return a.Provider
}

type Embeddings struct {
	Auth  *AiProxyAdvancedPluginAuth `json:"auth"`
	Model AiProxyAdvancedPluginModel `json:"model"`
}

func (e *Embeddings) GetAuth() *AiProxyAdvancedPluginAuth {
	if e == nil {
		return nil
	}
	return e.Auth
}

func (e *Embeddings) GetModel() AiProxyAdvancedPluginModel {
	if e == nil {
		return AiProxyAdvancedPluginModel{}
	}
	return e.Model
}

// AiProxyAdvancedPluginGenaiCategory - Generative AI category of the request
type AiProxyAdvancedPluginGenaiCategory string

const (
	AiProxyAdvancedPluginGenaiCategoryAudioSpeech        AiProxyAdvancedPluginGenaiCategory = "audio/speech"
	AiProxyAdvancedPluginGenaiCategoryAudioTranscription AiProxyAdvancedPluginGenaiCategory = "audio/transcription"
	AiProxyAdvancedPluginGenaiCategoryImageGeneration    AiProxyAdvancedPluginGenaiCategory = "image/generation"
	AiProxyAdvancedPluginGenaiCategoryRealtimeGeneration AiProxyAdvancedPluginGenaiCategory = "realtime/generation"
	AiProxyAdvancedPluginGenaiCategoryTextEmbeddings     AiProxyAdvancedPluginGenaiCategory = "text/embeddings"
	AiProxyAdvancedPluginGenaiCategoryTextGeneration     AiProxyAdvancedPluginGenaiCategory = "text/generation"
)

func (e AiProxyAdvancedPluginGenaiCategory) ToPointer() *AiProxyAdvancedPluginGenaiCategory {
	return &e
}
func (e *AiProxyAdvancedPluginGenaiCategory) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "audio/speech":
		fallthrough
	case "audio/transcription":
		fallthrough
	case "image/generation":
		fallthrough
	case "realtime/generation":
		fallthrough
	case "text/embeddings":
		fallthrough
	case "text/generation":
		*e = AiProxyAdvancedPluginGenaiCategory(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginGenaiCategory: %v", v)
	}
}

// AiProxyAdvancedPluginLlmFormat - LLM input and output format and schema to use
type AiProxyAdvancedPluginLlmFormat string

const (
	AiProxyAdvancedPluginLlmFormatBedrock     AiProxyAdvancedPluginLlmFormat = "bedrock"
	AiProxyAdvancedPluginLlmFormatCohere      AiProxyAdvancedPluginLlmFormat = "cohere"
	AiProxyAdvancedPluginLlmFormatGemini      AiProxyAdvancedPluginLlmFormat = "gemini"
	AiProxyAdvancedPluginLlmFormatHuggingface AiProxyAdvancedPluginLlmFormat = "huggingface"
	AiProxyAdvancedPluginLlmFormatOpenai      AiProxyAdvancedPluginLlmFormat = "openai"
)

func (e AiProxyAdvancedPluginLlmFormat) ToPointer() *AiProxyAdvancedPluginLlmFormat {
	return &e
}
func (e *AiProxyAdvancedPluginLlmFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "bedrock":
		fallthrough
	case "cohere":
		fallthrough
	case "gemini":
		fallthrough
	case "huggingface":
		fallthrough
	case "openai":
		*e = AiProxyAdvancedPluginLlmFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginLlmFormat: %v", v)
	}
}

// AiProxyAdvancedPluginResponseStreaming - Whether to 'optionally allow', 'deny', or 'always' (force) the streaming of answers via server sent events.
type AiProxyAdvancedPluginResponseStreaming string

const (
	AiProxyAdvancedPluginResponseStreamingAllow  AiProxyAdvancedPluginResponseStreaming = "allow"
	AiProxyAdvancedPluginResponseStreamingAlways AiProxyAdvancedPluginResponseStreaming = "always"
	AiProxyAdvancedPluginResponseStreamingDeny   AiProxyAdvancedPluginResponseStreaming = "deny"
)

func (e AiProxyAdvancedPluginResponseStreaming) ToPointer() *AiProxyAdvancedPluginResponseStreaming {
	return &e
}
func (e *AiProxyAdvancedPluginResponseStreaming) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "allow":
		fallthrough
	case "always":
		fallthrough
	case "deny":
		*e = AiProxyAdvancedPluginResponseStreaming(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginResponseStreaming: %v", v)
	}
}

// AiProxyAdvancedPluginConfigParamLocation - Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.
type AiProxyAdvancedPluginConfigParamLocation string

const (
	AiProxyAdvancedPluginConfigParamLocationBody  AiProxyAdvancedPluginConfigParamLocation = "body"
	AiProxyAdvancedPluginConfigParamLocationQuery AiProxyAdvancedPluginConfigParamLocation = "query"
)

func (e AiProxyAdvancedPluginConfigParamLocation) ToPointer() *AiProxyAdvancedPluginConfigParamLocation {
	return &e
}
func (e *AiProxyAdvancedPluginConfigParamLocation) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "body":
		fallthrough
	case "query":
		*e = AiProxyAdvancedPluginConfigParamLocation(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginConfigParamLocation: %v", v)
	}
}

type AiProxyAdvancedPluginConfigAuth struct {
	// If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin.
	AllowOverride *bool `default:"false" json:"allow_override"`
	// Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.
	AwsAccessKeyID *string `default:"null" json:"aws_access_key_id"`
	// Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.
	AwsSecretAccessKey *string `default:"null" json:"aws_secret_access_key"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.
	AzureClientID *string `default:"null" json:"azure_client_id"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.
	AzureClientSecret *string `default:"null" json:"azure_client_secret"`
	// If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.
	AzureTenantID *string `default:"null" json:"azure_tenant_id"`
	// Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models.
	AzureUseManagedIdentity *bool `default:"false" json:"azure_use_managed_identity"`
	// Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.
	GcpServiceAccountJSON *string `default:"null" json:"gcp_service_account_json"`
	// Use service account auth for GCP-based providers and models.
	GcpUseServiceAccount *bool `default:"false" json:"gcp_use_service_account"`
	// If AI model requires authentication via Authorization or API key header, specify its name here.
	HeaderName *string `default:"null" json:"header_name"`
	// Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.
	HeaderValue *string `default:"null" json:"header_value"`
	// Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body.
	ParamLocation *AiProxyAdvancedPluginConfigParamLocation `json:"param_location,omitempty"`
	// If AI model requires authentication via query parameter, specify its name here.
	ParamName *string `default:"null" json:"param_name"`
	// Specify the full parameter value for 'param_name'.
	ParamValue *string `default:"null" json:"param_value"`
}

func (a AiProxyAdvancedPluginConfigAuth) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigAuth) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAllowOverride() *bool {
	if a == nil {
		return nil
	}
	return a.AllowOverride
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAwsAccessKeyID() *string {
	if a == nil {
		return nil
	}
	return a.AwsAccessKeyID
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAwsSecretAccessKey() *string {
	if a == nil {
		return nil
	}
	return a.AwsSecretAccessKey
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAzureClientID() *string {
	if a == nil {
		return nil
	}
	return a.AzureClientID
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAzureClientSecret() *string {
	if a == nil {
		return nil
	}
	return a.AzureClientSecret
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAzureTenantID() *string {
	if a == nil {
		return nil
	}
	return a.AzureTenantID
}

func (a *AiProxyAdvancedPluginConfigAuth) GetAzureUseManagedIdentity() *bool {
	if a == nil {
		return nil
	}
	return a.AzureUseManagedIdentity
}

func (a *AiProxyAdvancedPluginConfigAuth) GetGcpServiceAccountJSON() *string {
	if a == nil {
		return nil
	}
	return a.GcpServiceAccountJSON
}

func (a *AiProxyAdvancedPluginConfigAuth) GetGcpUseServiceAccount() *bool {
	if a == nil {
		return nil
	}
	return a.GcpUseServiceAccount
}

func (a *AiProxyAdvancedPluginConfigAuth) GetHeaderName() *string {
	if a == nil {
		return nil
	}
	return a.HeaderName
}

func (a *AiProxyAdvancedPluginConfigAuth) GetHeaderValue() *string {
	if a == nil {
		return nil
	}
	return a.HeaderValue
}

func (a *AiProxyAdvancedPluginConfigAuth) GetParamLocation() *AiProxyAdvancedPluginConfigParamLocation {
	if a == nil {
		return nil
	}
	return a.ParamLocation
}

func (a *AiProxyAdvancedPluginConfigAuth) GetParamName() *string {
	if a == nil {
		return nil
	}
	return a.ParamName
}

func (a *AiProxyAdvancedPluginConfigAuth) GetParamValue() *string {
	if a == nil {
		return nil
	}
	return a.ParamValue
}

type AiProxyAdvancedPluginLogging struct {
	// If enabled, will log the request and response body into the Kong log plugin(s) output.
	LogPayloads *bool `default:"false" json:"log_payloads"`
	// If enabled and supported by the driver, will add model usage and token metrics into the Kong log plugin(s) output.
	LogStatistics *bool `default:"false" json:"log_statistics"`
}

func (a AiProxyAdvancedPluginLogging) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginLogging) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginLogging) GetLogPayloads() *bool {
	if a == nil {
		return nil
	}
	return a.LogPayloads
}

func (a *AiProxyAdvancedPluginLogging) GetLogStatistics() *bool {
	if a == nil {
		return nil
	}
	return a.LogStatistics
}

type AiProxyAdvancedPluginConfigBedrock struct {
	// If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.
	AwsAssumeRoleArn *string `default:"null" json:"aws_assume_role_arn"`
	// If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.
	AwsRegion *string `default:"null" json:"aws_region"`
	// If using AWS providers (Bedrock), set the identifier of the assumed role session.
	AwsRoleSessionName *string `default:"null" json:"aws_role_session_name"`
	// If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.
	AwsStsEndpointURL *string `default:"null" json:"aws_sts_endpoint_url"`
	// If using AWS providers (Bedrock), set to true to normalize the embeddings.
	EmbeddingsNormalize *bool `default:"false" json:"embeddings_normalize"`
	// Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.
	PerformanceConfigLatency *string `default:"null" json:"performance_config_latency"`
}

func (a AiProxyAdvancedPluginConfigBedrock) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigBedrock) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetAwsAssumeRoleArn() *string {
	if a == nil {
		return nil
	}
	return a.AwsAssumeRoleArn
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetAwsRegion() *string {
	if a == nil {
		return nil
	}
	return a.AwsRegion
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetAwsRoleSessionName() *string {
	if a == nil {
		return nil
	}
	return a.AwsRoleSessionName
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetAwsStsEndpointURL() *string {
	if a == nil {
		return nil
	}
	return a.AwsStsEndpointURL
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetEmbeddingsNormalize() *bool {
	if a == nil {
		return nil
	}
	return a.EmbeddingsNormalize
}

func (a *AiProxyAdvancedPluginConfigBedrock) GetPerformanceConfigLatency() *string {
	if a == nil {
		return nil
	}
	return a.PerformanceConfigLatency
}

// AiProxyAdvancedPluginEmbeddingInputType - The purpose of the input text to calculate embedding vectors.
type AiProxyAdvancedPluginEmbeddingInputType string

const (
	AiProxyAdvancedPluginEmbeddingInputTypeClassification AiProxyAdvancedPluginEmbeddingInputType = "classification"
	AiProxyAdvancedPluginEmbeddingInputTypeClustering     AiProxyAdvancedPluginEmbeddingInputType = "clustering"
	AiProxyAdvancedPluginEmbeddingInputTypeImage          AiProxyAdvancedPluginEmbeddingInputType = "image"
	AiProxyAdvancedPluginEmbeddingInputTypeSearchDocument AiProxyAdvancedPluginEmbeddingInputType = "search_document"
	AiProxyAdvancedPluginEmbeddingInputTypeSearchQuery    AiProxyAdvancedPluginEmbeddingInputType = "search_query"
)

func (e AiProxyAdvancedPluginEmbeddingInputType) ToPointer() *AiProxyAdvancedPluginEmbeddingInputType {
	return &e
}
func (e *AiProxyAdvancedPluginEmbeddingInputType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "classification":
		fallthrough
	case "clustering":
		fallthrough
	case "image":
		fallthrough
	case "search_document":
		fallthrough
	case "search_query":
		*e = AiProxyAdvancedPluginEmbeddingInputType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginEmbeddingInputType: %v", v)
	}
}

type AiProxyAdvancedPluginCohere struct {
	// The purpose of the input text to calculate embedding vectors.
	EmbeddingInputType *AiProxyAdvancedPluginEmbeddingInputType `default:"classification" json:"embedding_input_type"`
	// Wait for the model if it is not ready
	WaitForModel *bool `default:"null" json:"wait_for_model"`
}

func (a AiProxyAdvancedPluginCohere) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginCohere) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginCohere) GetEmbeddingInputType() *AiProxyAdvancedPluginEmbeddingInputType {
	if a == nil {
		return nil
	}
	return a.EmbeddingInputType
}

func (a *AiProxyAdvancedPluginCohere) GetWaitForModel() *bool {
	if a == nil {
		return nil
	}
	return a.WaitForModel
}

type AiProxyAdvancedPluginConfigGemini struct {
	// If running Gemini on Vertex, specify the regional API endpoint (hostname only).
	APIEndpoint *string `default:"null" json:"api_endpoint"`
	// If running Gemini on Vertex Model Garden, specify the endpoint ID.
	EndpointID *string `default:"null" json:"endpoint_id"`
	// If running Gemini on Vertex, specify the location ID.
	LocationID *string `default:"null" json:"location_id"`
	// If running Gemini on Vertex, specify the project ID.
	ProjectID *string `default:"null" json:"project_id"`
}

func (a AiProxyAdvancedPluginConfigGemini) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigGemini) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigGemini) GetAPIEndpoint() *string {
	if a == nil {
		return nil
	}
	return a.APIEndpoint
}

func (a *AiProxyAdvancedPluginConfigGemini) GetEndpointID() *string {
	if a == nil {
		return nil
	}
	return a.EndpointID
}

func (a *AiProxyAdvancedPluginConfigGemini) GetLocationID() *string {
	if a == nil {
		return nil
	}
	return a.LocationID
}

func (a *AiProxyAdvancedPluginConfigGemini) GetProjectID() *string {
	if a == nil {
		return nil
	}
	return a.ProjectID
}

type AiProxyAdvancedPluginConfigHuggingface struct {
	// Use the cache layer on the inference API
	UseCache *bool `default:"null" json:"use_cache"`
	// Wait for the model if it is not ready
	WaitForModel *bool `default:"null" json:"wait_for_model"`
}

func (a AiProxyAdvancedPluginConfigHuggingface) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigHuggingface) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigHuggingface) GetUseCache() *bool {
	if a == nil {
		return nil
	}
	return a.UseCache
}

func (a *AiProxyAdvancedPluginConfigHuggingface) GetWaitForModel() *bool {
	if a == nil {
		return nil
	}
	return a.WaitForModel
}

// AiProxyAdvancedPluginLlama2Format - If using llama2 provider, select the upstream message format.
type AiProxyAdvancedPluginLlama2Format string

const (
	AiProxyAdvancedPluginLlama2FormatOllama AiProxyAdvancedPluginLlama2Format = "ollama"
	AiProxyAdvancedPluginLlama2FormatOpenai AiProxyAdvancedPluginLlama2Format = "openai"
	AiProxyAdvancedPluginLlama2FormatRaw    AiProxyAdvancedPluginLlama2Format = "raw"
)

func (e AiProxyAdvancedPluginLlama2Format) ToPointer() *AiProxyAdvancedPluginLlama2Format {
	return &e
}
func (e *AiProxyAdvancedPluginLlama2Format) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ollama":
		fallthrough
	case "openai":
		fallthrough
	case "raw":
		*e = AiProxyAdvancedPluginLlama2Format(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginLlama2Format: %v", v)
	}
}

// AiProxyAdvancedPluginMistralFormat - If using mistral provider, select the upstream message format.
type AiProxyAdvancedPluginMistralFormat string

const (
	AiProxyAdvancedPluginMistralFormatOllama AiProxyAdvancedPluginMistralFormat = "ollama"
	AiProxyAdvancedPluginMistralFormatOpenai AiProxyAdvancedPluginMistralFormat = "openai"
)

func (e AiProxyAdvancedPluginMistralFormat) ToPointer() *AiProxyAdvancedPluginMistralFormat {
	return &e
}
func (e *AiProxyAdvancedPluginMistralFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "ollama":
		fallthrough
	case "openai":
		*e = AiProxyAdvancedPluginMistralFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginMistralFormat: %v", v)
	}
}

// AiProxyAdvancedPluginConfigOptions - Key/value settings for the model
type AiProxyAdvancedPluginConfigOptions struct {
	// Defines the schema/API version, if using Anthropic provider.
	AnthropicVersion *string `default:"null" json:"anthropic_version"`
	// 'api-version' for Azure OpenAI instances.
	AzureAPIVersion *string `default:"2023-05-15" json:"azure_api_version"`
	// Deployment ID for Azure OpenAI instances.
	AzureDeploymentID *string `default:"null" json:"azure_deployment_id"`
	// Instance name for Azure OpenAI hosted models.
	AzureInstance *string                             `default:"null" json:"azure_instance"`
	Bedrock       *AiProxyAdvancedPluginConfigBedrock `json:"bedrock"`
	Cohere        *AiProxyAdvancedPluginCohere        `json:"cohere"`
	// If using embeddings models, set the number of dimensions to generate.
	EmbeddingsDimensions *int64                                  `default:"null" json:"embeddings_dimensions"`
	Gemini               *AiProxyAdvancedPluginConfigGemini      `json:"gemini"`
	Huggingface          *AiProxyAdvancedPluginConfigHuggingface `json:"huggingface"`
	// Defines the cost per 1M tokens in your prompt.
	InputCost *float64 `default:"null" json:"input_cost"`
	// If using llama2 provider, select the upstream message format.
	Llama2Format *AiProxyAdvancedPluginLlama2Format `json:"llama2_format,omitempty"`
	// Defines the max_tokens, if using chat or completion models.
	MaxTokens *int64 `default:"null" json:"max_tokens"`
	// If using mistral provider, select the upstream message format.
	MistralFormat *AiProxyAdvancedPluginMistralFormat `json:"mistral_format,omitempty"`
	// Defines the cost per 1M tokens in the output of the AI.
	OutputCost *float64 `default:"null" json:"output_cost"`
	// Defines the matching temperature, if using chat or completion models.
	Temperature *float64 `default:"null" json:"temperature"`
	// Defines the top-k most likely tokens, if supported.
	TopK *int64 `default:"null" json:"top_k"`
	// Defines the top-p probability mass, if supported.
	TopP *float64 `default:"null" json:"top_p"`
	// Manually specify or override the AI operation path, used when e.g. using the 'preserve' route_type.
	UpstreamPath *string `default:"null" json:"upstream_path"`
	// Manually specify or override the full URL to the AI operation endpoints, when calling (self-)hosted models, or for running via a private endpoint.
	UpstreamURL *string `default:"null" json:"upstream_url"`
}

func (a AiProxyAdvancedPluginConfigOptions) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigOptions) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigOptions) GetAnthropicVersion() *string {
	if a == nil {
		return nil
	}
	return a.AnthropicVersion
}

func (a *AiProxyAdvancedPluginConfigOptions) GetAzureAPIVersion() *string {
	if a == nil {
		return nil
	}
	return a.AzureAPIVersion
}

func (a *AiProxyAdvancedPluginConfigOptions) GetAzureDeploymentID() *string {
	if a == nil {
		return nil
	}
	return a.AzureDeploymentID
}

func (a *AiProxyAdvancedPluginConfigOptions) GetAzureInstance() *string {
	if a == nil {
		return nil
	}
	return a.AzureInstance
}

func (a *AiProxyAdvancedPluginConfigOptions) GetBedrock() *AiProxyAdvancedPluginConfigBedrock {
	if a == nil {
		return nil
	}
	return a.Bedrock
}

func (a *AiProxyAdvancedPluginConfigOptions) GetCohere() *AiProxyAdvancedPluginCohere {
	if a == nil {
		return nil
	}
	return a.Cohere
}

func (a *AiProxyAdvancedPluginConfigOptions) GetEmbeddingsDimensions() *int64 {
	if a == nil {
		return nil
	}
	return a.EmbeddingsDimensions
}

func (a *AiProxyAdvancedPluginConfigOptions) GetGemini() *AiProxyAdvancedPluginConfigGemini {
	if a == nil {
		return nil
	}
	return a.Gemini
}

func (a *AiProxyAdvancedPluginConfigOptions) GetHuggingface() *AiProxyAdvancedPluginConfigHuggingface {
	if a == nil {
		return nil
	}
	return a.Huggingface
}

func (a *AiProxyAdvancedPluginConfigOptions) GetInputCost() *float64 {
	if a == nil {
		return nil
	}
	return a.InputCost
}

func (a *AiProxyAdvancedPluginConfigOptions) GetLlama2Format() *AiProxyAdvancedPluginLlama2Format {
	if a == nil {
		return nil
	}
	return a.Llama2Format
}

func (a *AiProxyAdvancedPluginConfigOptions) GetMaxTokens() *int64 {
	if a == nil {
		return nil
	}
	return a.MaxTokens
}

func (a *AiProxyAdvancedPluginConfigOptions) GetMistralFormat() *AiProxyAdvancedPluginMistralFormat {
	if a == nil {
		return nil
	}
	return a.MistralFormat
}

func (a *AiProxyAdvancedPluginConfigOptions) GetOutputCost() *float64 {
	if a == nil {
		return nil
	}
	return a.OutputCost
}

func (a *AiProxyAdvancedPluginConfigOptions) GetTemperature() *float64 {
	if a == nil {
		return nil
	}
	return a.Temperature
}

func (a *AiProxyAdvancedPluginConfigOptions) GetTopK() *int64 {
	if a == nil {
		return nil
	}
	return a.TopK
}

func (a *AiProxyAdvancedPluginConfigOptions) GetTopP() *float64 {
	if a == nil {
		return nil
	}
	return a.TopP
}

func (a *AiProxyAdvancedPluginConfigOptions) GetUpstreamPath() *string {
	if a == nil {
		return nil
	}
	return a.UpstreamPath
}

func (a *AiProxyAdvancedPluginConfigOptions) GetUpstreamURL() *string {
	if a == nil {
		return nil
	}
	return a.UpstreamURL
}

// AiProxyAdvancedPluginConfigProvider - AI provider request format - Kong translates requests to and from the specified backend compatible formats.
type AiProxyAdvancedPluginConfigProvider string

const (
	AiProxyAdvancedPluginConfigProviderAnthropic   AiProxyAdvancedPluginConfigProvider = "anthropic"
	AiProxyAdvancedPluginConfigProviderAzure       AiProxyAdvancedPluginConfigProvider = "azure"
	AiProxyAdvancedPluginConfigProviderBedrock     AiProxyAdvancedPluginConfigProvider = "bedrock"
	AiProxyAdvancedPluginConfigProviderCohere      AiProxyAdvancedPluginConfigProvider = "cohere"
	AiProxyAdvancedPluginConfigProviderGemini      AiProxyAdvancedPluginConfigProvider = "gemini"
	AiProxyAdvancedPluginConfigProviderHuggingface AiProxyAdvancedPluginConfigProvider = "huggingface"
	AiProxyAdvancedPluginConfigProviderLlama2      AiProxyAdvancedPluginConfigProvider = "llama2"
	AiProxyAdvancedPluginConfigProviderMistral     AiProxyAdvancedPluginConfigProvider = "mistral"
	AiProxyAdvancedPluginConfigProviderOpenai      AiProxyAdvancedPluginConfigProvider = "openai"
)

func (e AiProxyAdvancedPluginConfigProvider) ToPointer() *AiProxyAdvancedPluginConfigProvider {
	return &e
}
func (e *AiProxyAdvancedPluginConfigProvider) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "anthropic":
		fallthrough
	case "azure":
		fallthrough
	case "bedrock":
		fallthrough
	case "cohere":
		fallthrough
	case "gemini":
		fallthrough
	case "huggingface":
		fallthrough
	case "llama2":
		fallthrough
	case "mistral":
		fallthrough
	case "openai":
		*e = AiProxyAdvancedPluginConfigProvider(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginConfigProvider: %v", v)
	}
}

type AiProxyAdvancedPluginConfigModel struct {
	// Model name to execute.
	Name *string `default:"null" json:"name"`
	// Key/value settings for the model
	Options *AiProxyAdvancedPluginConfigOptions `json:"options"`
	// AI provider request format - Kong translates requests to and from the specified backend compatible formats.
	Provider AiProxyAdvancedPluginConfigProvider `json:"provider"`
}

func (a AiProxyAdvancedPluginConfigModel) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfigModel) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"provider"}); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfigModel) GetName() *string {
	if a == nil {
		return nil
	}
	return a.Name
}

func (a *AiProxyAdvancedPluginConfigModel) GetOptions() *AiProxyAdvancedPluginConfigOptions {
	if a == nil {
		return nil
	}
	return a.Options
}

func (a *AiProxyAdvancedPluginConfigModel) GetProvider() AiProxyAdvancedPluginConfigProvider {
	if a == nil {
		return AiProxyAdvancedPluginConfigProvider("")
	}
	return a.Provider
}

// AiProxyAdvancedPluginRouteType - The model's operation implementation, for this provider.
type AiProxyAdvancedPluginRouteType string

const (
	AiProxyAdvancedPluginRouteTypeAudioV1AudioSpeech         AiProxyAdvancedPluginRouteType = "audio/v1/audio/speech"
	AiProxyAdvancedPluginRouteTypeAudioV1AudioTranscriptions AiProxyAdvancedPluginRouteType = "audio/v1/audio/transcriptions"
	AiProxyAdvancedPluginRouteTypeAudioV1AudioTranslations   AiProxyAdvancedPluginRouteType = "audio/v1/audio/translations"
	AiProxyAdvancedPluginRouteTypeImageV1ImagesEdits         AiProxyAdvancedPluginRouteType = "image/v1/images/edits"
	AiProxyAdvancedPluginRouteTypeImageV1ImagesGenerations   AiProxyAdvancedPluginRouteType = "image/v1/images/generations"
	AiProxyAdvancedPluginRouteTypeLlmV1Assistants            AiProxyAdvancedPluginRouteType = "llm/v1/assistants"
	AiProxyAdvancedPluginRouteTypeLlmV1Batches               AiProxyAdvancedPluginRouteType = "llm/v1/batches"
	AiProxyAdvancedPluginRouteTypeLlmV1Chat                  AiProxyAdvancedPluginRouteType = "llm/v1/chat"
	AiProxyAdvancedPluginRouteTypeLlmV1Completions           AiProxyAdvancedPluginRouteType = "llm/v1/completions"
	AiProxyAdvancedPluginRouteTypeLlmV1Embeddings            AiProxyAdvancedPluginRouteType = "llm/v1/embeddings"
	AiProxyAdvancedPluginRouteTypeLlmV1Files                 AiProxyAdvancedPluginRouteType = "llm/v1/files"
	AiProxyAdvancedPluginRouteTypeLlmV1Responses             AiProxyAdvancedPluginRouteType = "llm/v1/responses"
	AiProxyAdvancedPluginRouteTypePreserve                   AiProxyAdvancedPluginRouteType = "preserve"
	AiProxyAdvancedPluginRouteTypeRealtimeV1Realtime         AiProxyAdvancedPluginRouteType = "realtime/v1/realtime"
)

func (e AiProxyAdvancedPluginRouteType) ToPointer() *AiProxyAdvancedPluginRouteType {
	return &e
}
func (e *AiProxyAdvancedPluginRouteType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "audio/v1/audio/speech":
		fallthrough
	case "audio/v1/audio/transcriptions":
		fallthrough
	case "audio/v1/audio/translations":
		fallthrough
	case "image/v1/images/edits":
		fallthrough
	case "image/v1/images/generations":
		fallthrough
	case "llm/v1/assistants":
		fallthrough
	case "llm/v1/batches":
		fallthrough
	case "llm/v1/chat":
		fallthrough
	case "llm/v1/completions":
		fallthrough
	case "llm/v1/embeddings":
		fallthrough
	case "llm/v1/files":
		fallthrough
	case "llm/v1/responses":
		fallthrough
	case "preserve":
		fallthrough
	case "realtime/v1/realtime":
		*e = AiProxyAdvancedPluginRouteType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginRouteType: %v", v)
	}
}

type Targets struct {
	Auth *AiProxyAdvancedPluginConfigAuth `json:"auth"`
	// The semantic description of the target, required if using semantic load balancing. Specially, setting this to 'CATCHALL' will indicate such target to be used when no other targets match the semantic threshold.
	Description *string                          `default:"null" json:"description"`
	Logging     *AiProxyAdvancedPluginLogging    `json:"logging"`
	Model       AiProxyAdvancedPluginConfigModel `json:"model"`
	// The model's operation implementation, for this provider.
	RouteType AiProxyAdvancedPluginRouteType `json:"route_type"`
	// The weight this target gets within the upstream loadbalancer (1-65535).
	Weight *int64 `default:"100" json:"weight"`
}

func (t Targets) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(t, "", false)
}

func (t *Targets) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &t, "", false, []string{"model", "route_type"}); err != nil {
		return err
	}
	return nil
}

func (t *Targets) GetAuth() *AiProxyAdvancedPluginConfigAuth {
	if t == nil {
		return nil
	}
	return t.Auth
}

func (t *Targets) GetDescription() *string {
	if t == nil {
		return nil
	}
	return t.Description
}

func (t *Targets) GetLogging() *AiProxyAdvancedPluginLogging {
	if t == nil {
		return nil
	}
	return t.Logging
}

func (t *Targets) GetModel() AiProxyAdvancedPluginConfigModel {
	if t == nil {
		return AiProxyAdvancedPluginConfigModel{}
	}
	return t.Model
}

func (t *Targets) GetRouteType() AiProxyAdvancedPluginRouteType {
	if t == nil {
		return AiProxyAdvancedPluginRouteType("")
	}
	return t.RouteType
}

func (t *Targets) GetWeight() *int64 {
	if t == nil {
		return nil
	}
	return t.Weight
}

// DistanceMetric - the distance metric to use for vector searches
type DistanceMetric string

const (
	DistanceMetricCosine    DistanceMetric = "cosine"
	DistanceMetricEuclidean DistanceMetric = "euclidean"
)

func (e DistanceMetric) ToPointer() *DistanceMetric {
	return &e
}
func (e *DistanceMetric) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cosine":
		fallthrough
	case "euclidean":
		*e = DistanceMetric(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DistanceMetric: %v", v)
	}
}

// SslVersion - the ssl version to use for the pgvector database
type SslVersion string

const (
	SslVersionAny    SslVersion = "any"
	SslVersionTlsv12 SslVersion = "tlsv1_2"
	SslVersionTlsv13 SslVersion = "tlsv1_3"
)

func (e SslVersion) ToPointer() *SslVersion {
	return &e
}
func (e *SslVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "any":
		fallthrough
	case "tlsv1_2":
		fallthrough
	case "tlsv1_3":
		*e = SslVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for SslVersion: %v", v)
	}
}

type Pgvector struct {
	// the database of the pgvector database
	Database *string `default:"kong-pgvector" json:"database"`
	// the host of the pgvector database
	Host *string `default:"127.0.0.1" json:"host"`
	// the password of the pgvector database
	Password *string `default:"null" json:"password"`
	// the port of the pgvector database
	Port *int64 `default:"5432" json:"port"`
	// whether to use ssl for the pgvector database
	Ssl *bool `default:"false" json:"ssl"`
	// the path of ssl cert to use for the pgvector database
	SslCert *string `default:"null" json:"ssl_cert"`
	// the path of ssl cert key to use for the pgvector database
	SslCertKey *string `default:"null" json:"ssl_cert_key"`
	// whether ssl is required for the pgvector database
	SslRequired *bool `default:"false" json:"ssl_required"`
	// whether to verify ssl for the pgvector database
	SslVerify *bool `default:"false" json:"ssl_verify"`
	// the ssl version to use for the pgvector database
	SslVersion *SslVersion `default:"tlsv1_2" json:"ssl_version"`
	// the timeout of the pgvector database
	Timeout *float64 `default:"5000" json:"timeout"`
	// the user of the pgvector database
	User *string `default:"postgres" json:"user"`
}

func (p Pgvector) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(p, "", false)
}

func (p *Pgvector) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &p, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (p *Pgvector) GetDatabase() *string {
	if p == nil {
		return nil
	}
	return p.Database
}

func (p *Pgvector) GetHost() *string {
	if p == nil {
		return nil
	}
	return p.Host
}

func (p *Pgvector) GetPassword() *string {
	if p == nil {
		return nil
	}
	return p.Password
}

func (p *Pgvector) GetPort() *int64 {
	if p == nil {
		return nil
	}
	return p.Port
}

func (p *Pgvector) GetSsl() *bool {
	if p == nil {
		return nil
	}
	return p.Ssl
}

func (p *Pgvector) GetSslCert() *string {
	if p == nil {
		return nil
	}
	return p.SslCert
}

func (p *Pgvector) GetSslCertKey() *string {
	if p == nil {
		return nil
	}
	return p.SslCertKey
}

func (p *Pgvector) GetSslRequired() *bool {
	if p == nil {
		return nil
	}
	return p.SslRequired
}

func (p *Pgvector) GetSslVerify() *bool {
	if p == nil {
		return nil
	}
	return p.SslVerify
}

func (p *Pgvector) GetSslVersion() *SslVersion {
	if p == nil {
		return nil
	}
	return p.SslVersion
}

func (p *Pgvector) GetTimeout() *float64 {
	if p == nil {
		return nil
	}
	return p.Timeout
}

func (p *Pgvector) GetUser() *string {
	if p == nil {
		return nil
	}
	return p.User
}

type AiProxyAdvancedPluginClusterNodes struct {
	// A string representing a host name, such as example.com.
	IP *string `default:"127.0.0.1" json:"ip"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port *int64 `default:"6379" json:"port"`
}

func (a AiProxyAdvancedPluginClusterNodes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginClusterNodes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginClusterNodes) GetIP() *string {
	if a == nil {
		return nil
	}
	return a.IP
}

func (a *AiProxyAdvancedPluginClusterNodes) GetPort() *int64 {
	if a == nil {
		return nil
	}
	return a.Port
}

type AiProxyAdvancedPluginSentinelNodes struct {
	// A string representing a host name, such as example.com.
	Host *string `default:"127.0.0.1" json:"host"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port *int64 `default:"6379" json:"port"`
}

func (a AiProxyAdvancedPluginSentinelNodes) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginSentinelNodes) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginSentinelNodes) GetHost() *string {
	if a == nil {
		return nil
	}
	return a.Host
}

func (a *AiProxyAdvancedPluginSentinelNodes) GetPort() *int64 {
	if a == nil {
		return nil
	}
	return a.Port
}

// AiProxyAdvancedPluginSentinelRole - Sentinel role to use for Redis connections when the `redis` strategy is defined. Defining this value implies using Redis Sentinel.
type AiProxyAdvancedPluginSentinelRole string

const (
	AiProxyAdvancedPluginSentinelRoleAny    AiProxyAdvancedPluginSentinelRole = "any"
	AiProxyAdvancedPluginSentinelRoleMaster AiProxyAdvancedPluginSentinelRole = "master"
	AiProxyAdvancedPluginSentinelRoleSlave  AiProxyAdvancedPluginSentinelRole = "slave"
)

func (e AiProxyAdvancedPluginSentinelRole) ToPointer() *AiProxyAdvancedPluginSentinelRole {
	return &e
}
func (e *AiProxyAdvancedPluginSentinelRole) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "any":
		fallthrough
	case "master":
		fallthrough
	case "slave":
		*e = AiProxyAdvancedPluginSentinelRole(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginSentinelRole: %v", v)
	}
}

type AiProxyAdvancedPluginRedis struct {
	// Maximum retry attempts for redirection.
	ClusterMaxRedirections *int64 `default:"5" json:"cluster_max_redirections"`
	// Cluster addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Cluster. The minimum length of the array is 1 element.
	ClusterNodes []AiProxyAdvancedPluginClusterNodes `json:"cluster_nodes"`
	// An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.
	ConnectTimeout *int64 `default:"2000" json:"connect_timeout"`
	// If the connection to Redis is proxied (e.g. Envoy), set it `true`. Set the `host` and `port` to point to the proxy address.
	ConnectionIsProxied *bool `default:"false" json:"connection_is_proxied"`
	// Database to use for the Redis connection when using the `redis` strategy
	Database *int64 `default:"0" json:"database"`
	// A string representing a host name, such as example.com.
	Host *string `default:"127.0.0.1" json:"host"`
	// Limits the total number of opened connections for a pool. If the connection pool is full, connection queues above the limit go into the backlog queue. If the backlog queue is full, subsequent connect operations fail and return `nil`. Queued operations (subject to set timeouts) resume once the number of connections in the pool is less than `keepalive_pool_size`. If latency is high or throughput is low, try increasing this value. Empirically, this value is larger than `keepalive_pool_size`.
	KeepaliveBacklog *int64 `default:"null" json:"keepalive_backlog"`
	// The size limit for every cosocket connection pool associated with every remote server, per worker process. If neither `keepalive_pool_size` nor `keepalive_backlog` is specified, no pool is created. If `keepalive_pool_size` isn't specified but `keepalive_backlog` is specified, then the pool uses the default value. Try to increase (e.g. 512) this value if latency is high or throughput is low.
	KeepalivePoolSize *int64 `default:"256" json:"keepalive_pool_size"`
	// Password to use for Redis connections. If undefined, no AUTH commands are sent to Redis.
	Password *string `default:"null" json:"password"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port *int64 `default:"6379" json:"port"`
	// An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.
	ReadTimeout *int64 `default:"2000" json:"read_timeout"`
	// An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2.
	SendTimeout *int64 `default:"2000" json:"send_timeout"`
	// Sentinel master to use for Redis connections. Defining this value implies using Redis Sentinel.
	SentinelMaster *string `default:"null" json:"sentinel_master"`
	// Sentinel node addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Sentinel. The minimum length of the array is 1 element.
	SentinelNodes []AiProxyAdvancedPluginSentinelNodes `json:"sentinel_nodes"`
	// Sentinel password to authenticate with a Redis Sentinel instance. If undefined, no AUTH commands are sent to Redis Sentinels.
	SentinelPassword *string `default:"null" json:"sentinel_password"`
	// Sentinel role to use for Redis connections when the `redis` strategy is defined. Defining this value implies using Redis Sentinel.
	SentinelRole *AiProxyAdvancedPluginSentinelRole `json:"sentinel_role,omitempty"`
	// Sentinel username to authenticate with a Redis Sentinel instance. If undefined, ACL authentication won't be performed. This requires Redis v6.2.0+.
	SentinelUsername *string `default:"null" json:"sentinel_username"`
	// A string representing an SNI (server name indication) value for TLS.
	ServerName *string `default:"null" json:"server_name"`
	// If set to true, uses SSL to connect to Redis.
	Ssl *bool `default:"false" json:"ssl"`
	// If set to true, verifies the validity of the server SSL certificate. If setting this parameter, also configure `lua_ssl_trusted_certificate` in `kong.conf` to specify the CA (or server) certificate used by your Redis server. You may also need to configure `lua_ssl_verify_depth` accordingly.
	SslVerify *bool `default:"false" json:"ssl_verify"`
	// Username to use for Redis connections. If undefined, ACL authentication won't be performed. This requires Redis v6.0.0+. To be compatible with Redis v5.x.y, you can set it to `default`.
	Username *string `default:"null" json:"username"`
}

func (a AiProxyAdvancedPluginRedis) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginRedis) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginRedis) GetClusterMaxRedirections() *int64 {
	if a == nil {
		return nil
	}
	return a.ClusterMaxRedirections
}

func (a *AiProxyAdvancedPluginRedis) GetClusterNodes() []AiProxyAdvancedPluginClusterNodes {
	if a == nil {
		return nil
	}
	return a.ClusterNodes
}

func (a *AiProxyAdvancedPluginRedis) GetConnectTimeout() *int64 {
	if a == nil {
		return nil
	}
	return a.ConnectTimeout
}

func (a *AiProxyAdvancedPluginRedis) GetConnectionIsProxied() *bool {
	if a == nil {
		return nil
	}
	return a.ConnectionIsProxied
}

func (a *AiProxyAdvancedPluginRedis) GetDatabase() *int64 {
	if a == nil {
		return nil
	}
	return a.Database
}

func (a *AiProxyAdvancedPluginRedis) GetHost() *string {
	if a == nil {
		return nil
	}
	return a.Host
}

func (a *AiProxyAdvancedPluginRedis) GetKeepaliveBacklog() *int64 {
	if a == nil {
		return nil
	}
	return a.KeepaliveBacklog
}

func (a *AiProxyAdvancedPluginRedis) GetKeepalivePoolSize() *int64 {
	if a == nil {
		return nil
	}
	return a.KeepalivePoolSize
}

func (a *AiProxyAdvancedPluginRedis) GetPassword() *string {
	if a == nil {
		return nil
	}
	return a.Password
}

func (a *AiProxyAdvancedPluginRedis) GetPort() *int64 {
	if a == nil {
		return nil
	}
	return a.Port
}

func (a *AiProxyAdvancedPluginRedis) GetReadTimeout() *int64 {
	if a == nil {
		return nil
	}
	return a.ReadTimeout
}

func (a *AiProxyAdvancedPluginRedis) GetSendTimeout() *int64 {
	if a == nil {
		return nil
	}
	return a.SendTimeout
}

func (a *AiProxyAdvancedPluginRedis) GetSentinelMaster() *string {
	if a == nil {
		return nil
	}
	return a.SentinelMaster
}

func (a *AiProxyAdvancedPluginRedis) GetSentinelNodes() []AiProxyAdvancedPluginSentinelNodes {
	if a == nil {
		return nil
	}
	return a.SentinelNodes
}

func (a *AiProxyAdvancedPluginRedis) GetSentinelPassword() *string {
	if a == nil {
		return nil
	}
	return a.SentinelPassword
}

func (a *AiProxyAdvancedPluginRedis) GetSentinelRole() *AiProxyAdvancedPluginSentinelRole {
	if a == nil {
		return nil
	}
	return a.SentinelRole
}

func (a *AiProxyAdvancedPluginRedis) GetSentinelUsername() *string {
	if a == nil {
		return nil
	}
	return a.SentinelUsername
}

func (a *AiProxyAdvancedPluginRedis) GetServerName() *string {
	if a == nil {
		return nil
	}
	return a.ServerName
}

func (a *AiProxyAdvancedPluginRedis) GetSsl() *bool {
	if a == nil {
		return nil
	}
	return a.Ssl
}

func (a *AiProxyAdvancedPluginRedis) GetSslVerify() *bool {
	if a == nil {
		return nil
	}
	return a.SslVerify
}

func (a *AiProxyAdvancedPluginRedis) GetUsername() *string {
	if a == nil {
		return nil
	}
	return a.Username
}

// AiProxyAdvancedPluginStrategy - which vector database driver to use
type AiProxyAdvancedPluginStrategy string

const (
	AiProxyAdvancedPluginStrategyPgvector AiProxyAdvancedPluginStrategy = "pgvector"
	AiProxyAdvancedPluginStrategyRedis    AiProxyAdvancedPluginStrategy = "redis"
)

func (e AiProxyAdvancedPluginStrategy) ToPointer() *AiProxyAdvancedPluginStrategy {
	return &e
}
func (e *AiProxyAdvancedPluginStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "pgvector":
		fallthrough
	case "redis":
		*e = AiProxyAdvancedPluginStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginStrategy: %v", v)
	}
}

type Vectordb struct {
	// the desired dimensionality for the vectors
	Dimensions int64 `json:"dimensions"`
	// the distance metric to use for vector searches
	DistanceMetric DistanceMetric              `json:"distance_metric"`
	Pgvector       *Pgvector                   `json:"pgvector"`
	Redis          *AiProxyAdvancedPluginRedis `json:"redis"`
	// which vector database driver to use
	Strategy AiProxyAdvancedPluginStrategy `json:"strategy"`
	// the default similarity threshold for accepting semantic search results (float)
	Threshold float64 `json:"threshold"`
}

func (v *Vectordb) GetDimensions() int64 {
	if v == nil {
		return 0
	}
	return v.Dimensions
}

func (v *Vectordb) GetDistanceMetric() DistanceMetric {
	if v == nil {
		return DistanceMetric("")
	}
	return v.DistanceMetric
}

func (v *Vectordb) GetPgvector() *Pgvector {
	if v == nil {
		return nil
	}
	return v.Pgvector
}

func (v *Vectordb) GetRedis() *AiProxyAdvancedPluginRedis {
	if v == nil {
		return nil
	}
	return v.Redis
}

func (v *Vectordb) GetStrategy() AiProxyAdvancedPluginStrategy {
	if v == nil {
		return AiProxyAdvancedPluginStrategy("")
	}
	return v.Strategy
}

func (v *Vectordb) GetThreshold() float64 {
	if v == nil {
		return 0.0
	}
	return v.Threshold
}

type AiProxyAdvancedPluginConfig struct {
	Balancer   *Balancer   `json:"balancer"`
	Embeddings *Embeddings `json:"embeddings"`
	// Generative AI category of the request
	GenaiCategory *AiProxyAdvancedPluginGenaiCategory `default:"text/generation" json:"genai_category"`
	// LLM input and output format and schema to use
	LlmFormat *AiProxyAdvancedPluginLlmFormat `default:"openai" json:"llm_format"`
	// max allowed body size allowed to be introspected. 0 means unlimited, but the size of this body will still be limited by Nginx's client_max_body_size.
	MaxRequestBodySize *int64 `default:"8192" json:"max_request_body_size"`
	// Display the model name selected in the X-Kong-LLM-Model response header
	ModelNameHeader *bool `default:"true" json:"model_name_header"`
	// Whether to 'optionally allow', 'deny', or 'always' (force) the streaming of answers via server sent events.
	ResponseStreaming *AiProxyAdvancedPluginResponseStreaming `default:"allow" json:"response_streaming"`
	Targets           []Targets                               `json:"targets"`
	Vectordb          *Vectordb                               `json:"vectordb"`
}

func (a AiProxyAdvancedPluginConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPluginConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"targets"}); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPluginConfig) GetBalancer() *Balancer {
	if a == nil {
		return nil
	}
	return a.Balancer
}

func (a *AiProxyAdvancedPluginConfig) GetEmbeddings() *Embeddings {
	if a == nil {
		return nil
	}
	return a.Embeddings
}

func (a *AiProxyAdvancedPluginConfig) GetGenaiCategory() *AiProxyAdvancedPluginGenaiCategory {
	if a == nil {
		return nil
	}
	return a.GenaiCategory
}

func (a *AiProxyAdvancedPluginConfig) GetLlmFormat() *AiProxyAdvancedPluginLlmFormat {
	if a == nil {
		return nil
	}
	return a.LlmFormat
}

func (a *AiProxyAdvancedPluginConfig) GetMaxRequestBodySize() *int64 {
	if a == nil {
		return nil
	}
	return a.MaxRequestBodySize
}

func (a *AiProxyAdvancedPluginConfig) GetModelNameHeader() *bool {
	if a == nil {
		return nil
	}
	return a.ModelNameHeader
}

func (a *AiProxyAdvancedPluginConfig) GetResponseStreaming() *AiProxyAdvancedPluginResponseStreaming {
	if a == nil {
		return nil
	}
	return a.ResponseStreaming
}

func (a *AiProxyAdvancedPluginConfig) GetTargets() []Targets {
	if a == nil {
		return []Targets{}
	}
	return a.Targets
}

func (a *AiProxyAdvancedPluginConfig) GetVectordb() *Vectordb {
	if a == nil {
		return nil
	}
	return a.Vectordb
}

// AiProxyAdvancedPluginConsumer - If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
type AiProxyAdvancedPluginConsumer struct {
	ID *string `json:"id,omitempty"`
}

func (a *AiProxyAdvancedPluginConsumer) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

// AiProxyAdvancedPluginConsumerGroup - If set, the plugin will activate only for requests where the specified consumer group has been authenticated. (Note that some plugins can not be restricted to consumers groups this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer Groups
type AiProxyAdvancedPluginConsumerGroup struct {
	ID *string `json:"id,omitempty"`
}

func (a *AiProxyAdvancedPluginConsumerGroup) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

type AiProxyAdvancedPluginProtocols string

const (
	AiProxyAdvancedPluginProtocolsGrpc  AiProxyAdvancedPluginProtocols = "grpc"
	AiProxyAdvancedPluginProtocolsGrpcs AiProxyAdvancedPluginProtocols = "grpcs"
	AiProxyAdvancedPluginProtocolsHTTP  AiProxyAdvancedPluginProtocols = "http"
	AiProxyAdvancedPluginProtocolsHTTPS AiProxyAdvancedPluginProtocols = "https"
	AiProxyAdvancedPluginProtocolsWs    AiProxyAdvancedPluginProtocols = "ws"
	AiProxyAdvancedPluginProtocolsWss   AiProxyAdvancedPluginProtocols = "wss"
)

func (e AiProxyAdvancedPluginProtocols) ToPointer() *AiProxyAdvancedPluginProtocols {
	return &e
}
func (e *AiProxyAdvancedPluginProtocols) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "grpcs":
		fallthrough
	case "http":
		fallthrough
	case "https":
		fallthrough
	case "ws":
		fallthrough
	case "wss":
		*e = AiProxyAdvancedPluginProtocols(v)
		return nil
	default:
		return fmt.Errorf("invalid value for AiProxyAdvancedPluginProtocols: %v", v)
	}
}

// AiProxyAdvancedPluginRoute - If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
type AiProxyAdvancedPluginRoute struct {
	ID *string `json:"id,omitempty"`
}

func (a *AiProxyAdvancedPluginRoute) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

// AiProxyAdvancedPluginService - If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
type AiProxyAdvancedPluginService struct {
	ID *string `json:"id,omitempty"`
}

func (a *AiProxyAdvancedPluginService) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

// AiProxyAdvancedPlugin - A Plugin entity represents a plugin configuration that will be executed during the HTTP request/response lifecycle. It is how you can add functionalities to Services that run behind Kong, like Authentication or Rate Limiting for example. You can find more information about how to install and what values each plugin takes by visiting the [Kong Hub](https://docs.konghq.com/hub/). When adding a Plugin Configuration to a Service, every request made by a client to that Service will run said Plugin. If a Plugin needs to be tuned to different values for some specific Consumers, you can do so by creating a separate plugin instance that specifies both the Service and the Consumer, through the `service` and `consumer` fields.
type AiProxyAdvancedPlugin struct {
	// Unix epoch when the resource was created.
	CreatedAt *int64 `json:"created_at,omitempty"`
	// Whether the plugin is applied.
	Enabled *bool `default:"true" json:"enabled"`
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	InstanceName *string                        `default:"null" json:"instance_name"`
	name         string                         `const:"ai-proxy-advanced" json:"name"`
	Ordering     *AiProxyAdvancedPluginOrdering `json:"ordering"`
	// A list of partials to be used by the plugin.
	Partials []AiProxyAdvancedPluginPartials `json:"partials"`
	// An optional set of strings associated with the Plugin for grouping and filtering.
	Tags []string `json:"tags"`
	// Unix epoch when the resource was last updated.
	UpdatedAt *int64                      `json:"updated_at,omitempty"`
	Config    AiProxyAdvancedPluginConfig `json:"config"`
	// If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
	Consumer *AiProxyAdvancedPluginConsumer `json:"consumer"`
	// If set, the plugin will activate only for requests where the specified consumer group has been authenticated. (Note that some plugins can not be restricted to consumers groups this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer Groups
	ConsumerGroup *AiProxyAdvancedPluginConsumerGroup `json:"consumer_group"`
	// A list of the request protocols that will trigger this plugin. The default value, as well as the possible values allowed on this field, may change depending on the plugin type. For example, plugins that only work in stream mode will only support tcp and tls.
	Protocols []AiProxyAdvancedPluginProtocols `json:"protocols"`
	// If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
	Route *AiProxyAdvancedPluginRoute `json:"route"`
	// If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
	Service *AiProxyAdvancedPluginService `json:"service"`
}

func (a AiProxyAdvancedPlugin) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(a, "", false)
}

func (a *AiProxyAdvancedPlugin) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &a, "", false, []string{"name", "config"}); err != nil {
		return err
	}
	return nil
}

func (a *AiProxyAdvancedPlugin) GetCreatedAt() *int64 {
	if a == nil {
		return nil
	}
	return a.CreatedAt
}

func (a *AiProxyAdvancedPlugin) GetEnabled() *bool {
	if a == nil {
		return nil
	}
	return a.Enabled
}

func (a *AiProxyAdvancedPlugin) GetID() *string {
	if a == nil {
		return nil
	}
	return a.ID
}

func (a *AiProxyAdvancedPlugin) GetInstanceName() *string {
	if a == nil {
		return nil
	}
	return a.InstanceName
}

func (a *AiProxyAdvancedPlugin) GetName() string {
	return "ai-proxy-advanced"
}

func (a *AiProxyAdvancedPlugin) GetOrdering() *AiProxyAdvancedPluginOrdering {
	if a == nil {
		return nil
	}
	return a.Ordering
}

func (a *AiProxyAdvancedPlugin) GetPartials() []AiProxyAdvancedPluginPartials {
	if a == nil {
		return nil
	}
	return a.Partials
}

func (a *AiProxyAdvancedPlugin) GetTags() []string {
	if a == nil {
		return nil
	}
	return a.Tags
}

func (a *AiProxyAdvancedPlugin) GetUpdatedAt() *int64 {
	if a == nil {
		return nil
	}
	return a.UpdatedAt
}

func (a *AiProxyAdvancedPlugin) GetConfig() AiProxyAdvancedPluginConfig {
	if a == nil {
		return AiProxyAdvancedPluginConfig{}
	}
	return a.Config
}

func (a *AiProxyAdvancedPlugin) GetConsumer() *AiProxyAdvancedPluginConsumer {
	if a == nil {
		return nil
	}
	return a.Consumer
}

func (a *AiProxyAdvancedPlugin) GetConsumerGroup() *AiProxyAdvancedPluginConsumerGroup {
	if a == nil {
		return nil
	}
	return a.ConsumerGroup
}

func (a *AiProxyAdvancedPlugin) GetProtocols() []AiProxyAdvancedPluginProtocols {
	if a == nil {
		return nil
	}
	return a.Protocols
}

func (a *AiProxyAdvancedPlugin) GetRoute() *AiProxyAdvancedPluginRoute {
	if a == nil {
		return nil
	}
	return a.Route
}

func (a *AiProxyAdvancedPlugin) GetService() *AiProxyAdvancedPluginService {
	if a == nil {
		return nil
	}
	return a.Service
}
