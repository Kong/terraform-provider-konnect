// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/kong/terraform-provider-konnect/internal/sdk/internal/utils"
	"github.com/kong/terraform-provider-konnect/internal/sdk/types"
)

// CreateKafkaUpstreamPluginMechanism - The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256`, or `SCRAM-SHA-512`.
type CreateKafkaUpstreamPluginMechanism string

const (
	CreateKafkaUpstreamPluginMechanismPlain       CreateKafkaUpstreamPluginMechanism = "PLAIN"
	CreateKafkaUpstreamPluginMechanismScramSha256 CreateKafkaUpstreamPluginMechanism = "SCRAM-SHA-256"
	CreateKafkaUpstreamPluginMechanismScramSha512 CreateKafkaUpstreamPluginMechanism = "SCRAM-SHA-512"
)

func (e CreateKafkaUpstreamPluginMechanism) ToPointer() *CreateKafkaUpstreamPluginMechanism {
	return &e
}
func (e *CreateKafkaUpstreamPluginMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PLAIN":
		fallthrough
	case "SCRAM-SHA-256":
		fallthrough
	case "SCRAM-SHA-512":
		*e = CreateKafkaUpstreamPluginMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateKafkaUpstreamPluginMechanism: %v", v)
	}
}

// CreateKafkaUpstreamPluginStrategy - The authentication strategy for the plugin, the only option for the value is `sasl`.
type CreateKafkaUpstreamPluginStrategy string

const (
	CreateKafkaUpstreamPluginStrategySasl CreateKafkaUpstreamPluginStrategy = "sasl"
)

func (e CreateKafkaUpstreamPluginStrategy) ToPointer() *CreateKafkaUpstreamPluginStrategy {
	return &e
}
func (e *CreateKafkaUpstreamPluginStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sasl":
		*e = CreateKafkaUpstreamPluginStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateKafkaUpstreamPluginStrategy: %v", v)
	}
}

type CreateKafkaUpstreamPluginAuthentication struct {
	// The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256`, or `SCRAM-SHA-512`.
	Mechanism *CreateKafkaUpstreamPluginMechanism `json:"mechanism,omitempty"`
	// Password for SASL authentication.
	Password *string `json:"password,omitempty"`
	// The authentication strategy for the plugin, the only option for the value is `sasl`.
	Strategy *CreateKafkaUpstreamPluginStrategy `json:"strategy,omitempty"`
	// Enable this to indicate `DelegationToken` authentication.
	Tokenauth *bool `json:"tokenauth,omitempty"`
	// Username for SASL authentication.
	User *string `json:"user,omitempty"`
}

func (o *CreateKafkaUpstreamPluginAuthentication) GetMechanism() *CreateKafkaUpstreamPluginMechanism {
	if o == nil {
		return nil
	}
	return o.Mechanism
}

func (o *CreateKafkaUpstreamPluginAuthentication) GetPassword() *string {
	if o == nil {
		return nil
	}
	return o.Password
}

func (o *CreateKafkaUpstreamPluginAuthentication) GetStrategy() *CreateKafkaUpstreamPluginStrategy {
	if o == nil {
		return nil
	}
	return o.Strategy
}

func (o *CreateKafkaUpstreamPluginAuthentication) GetTokenauth() *bool {
	if o == nil {
		return nil
	}
	return o.Tokenauth
}

func (o *CreateKafkaUpstreamPluginAuthentication) GetUser() *string {
	if o == nil {
		return nil
	}
	return o.User
}

type CreateKafkaUpstreamPluginBootstrapServers struct {
	// A string representing a host name, such as example.com.
	Host string `json:"host"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port int64 `json:"port"`
}

func (o *CreateKafkaUpstreamPluginBootstrapServers) GetHost() string {
	if o == nil {
		return ""
	}
	return o.Host
}

func (o *CreateKafkaUpstreamPluginBootstrapServers) GetPort() int64 {
	if o == nil {
		return 0
	}
	return o.Port
}

// CreateKafkaUpstreamPluginProducerRequestAcks - The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
type CreateKafkaUpstreamPluginProducerRequestAcks int64

const (
	CreateKafkaUpstreamPluginProducerRequestAcksMinus1 CreateKafkaUpstreamPluginProducerRequestAcks = -1
	CreateKafkaUpstreamPluginProducerRequestAcksZero   CreateKafkaUpstreamPluginProducerRequestAcks = 0
	CreateKafkaUpstreamPluginProducerRequestAcksOne    CreateKafkaUpstreamPluginProducerRequestAcks = 1
)

func (e CreateKafkaUpstreamPluginProducerRequestAcks) ToPointer() *CreateKafkaUpstreamPluginProducerRequestAcks {
	return &e
}
func (e *CreateKafkaUpstreamPluginProducerRequestAcks) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case -1:
		fallthrough
	case 0:
		fallthrough
	case 1:
		*e = CreateKafkaUpstreamPluginProducerRequestAcks(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateKafkaUpstreamPluginProducerRequestAcks: %v", v)
	}
}

type CreateKafkaUpstreamPluginSecurity struct {
	// UUID of certificate entity for mTLS authentication.
	CertificateID *string `json:"certificate_id,omitempty"`
	// Enables TLS.
	Ssl *bool `json:"ssl,omitempty"`
}

func (o *CreateKafkaUpstreamPluginSecurity) GetCertificateID() *string {
	if o == nil {
		return nil
	}
	return o.CertificateID
}

func (o *CreateKafkaUpstreamPluginSecurity) GetSsl() *bool {
	if o == nil {
		return nil
	}
	return o.Ssl
}

type CreateKafkaUpstreamPluginConfig struct {
	Authentication *CreateKafkaUpstreamPluginAuthentication `json:"authentication,omitempty"`
	// Set of bootstrap brokers in a `{host: host, port: port}` list format.
	BootstrapServers []CreateKafkaUpstreamPluginBootstrapServers `json:"bootstrap_servers,omitempty"`
	// An identifier for the Kafka cluster. By default, this field generates a random string. You can also set your own custom cluster identifier.  If more than one Kafka plugin is configured without a `cluster_name` (that is, if the default autogenerated value is removed), these plugins will use the same producer, and by extension, the same cluster. Logs will be sent to the leader of the cluster.
	ClusterName *string `json:"cluster_name,omitempty"`
	// Include the request body in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardBody *bool `json:"forward_body,omitempty"`
	// Include the request headers in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardHeaders *bool `json:"forward_headers,omitempty"`
	// Include the request method in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardMethod *bool `json:"forward_method,omitempty"`
	// Include the request URI and URI arguments (as in, query arguments) in the message. At least one of these must be true: `forward_method`, `forward_uri`, `forward_headers`, `forward_body`.
	ForwardURI *bool `json:"forward_uri,omitempty"`
	// Keepalive timeout in milliseconds.
	Keepalive        *int64 `json:"keepalive,omitempty"`
	KeepaliveEnabled *bool  `json:"keepalive_enabled,omitempty"`
	// Flag to enable asynchronous mode.
	ProducerAsync *bool `json:"producer_async,omitempty"`
	// Maximum number of messages that can be buffered in memory in asynchronous mode.
	ProducerAsyncBufferingLimitsMessagesInMemory *int64 `json:"producer_async_buffering_limits_messages_in_memory,omitempty"`
	// Maximum time interval in milliseconds between buffer flushes in asynchronous mode.
	ProducerAsyncFlushTimeout *int64 `json:"producer_async_flush_timeout,omitempty"`
	// The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
	ProducerRequestAcks *CreateKafkaUpstreamPluginProducerRequestAcks `json:"producer_request_acks,omitempty"`
	// Maximum size of a Produce request in bytes.
	ProducerRequestLimitsBytesPerRequest *int64 `json:"producer_request_limits_bytes_per_request,omitempty"`
	// Maximum number of messages to include into a single producer request.
	ProducerRequestLimitsMessagesPerRequest *int64 `json:"producer_request_limits_messages_per_request,omitempty"`
	// Backoff interval between retry attempts in milliseconds.
	ProducerRequestRetriesBackoffTimeout *int64 `json:"producer_request_retries_backoff_timeout,omitempty"`
	// Maximum number of retry attempts per single Produce request.
	ProducerRequestRetriesMaxAttempts *int64 `json:"producer_request_retries_max_attempts,omitempty"`
	// Time to wait for a Produce response in milliseconds.
	ProducerRequestTimeout *int64                             `json:"producer_request_timeout,omitempty"`
	Security               *CreateKafkaUpstreamPluginSecurity `json:"security,omitempty"`
	// Socket timeout in milliseconds.
	Timeout *int64 `json:"timeout,omitempty"`
	// The Kafka topic to publish to.
	Topic *string `json:"topic,omitempty"`
}

func (o *CreateKafkaUpstreamPluginConfig) GetAuthentication() *CreateKafkaUpstreamPluginAuthentication {
	if o == nil {
		return nil
	}
	return o.Authentication
}

func (o *CreateKafkaUpstreamPluginConfig) GetBootstrapServers() []CreateKafkaUpstreamPluginBootstrapServers {
	if o == nil {
		return nil
	}
	return o.BootstrapServers
}

func (o *CreateKafkaUpstreamPluginConfig) GetClusterName() *string {
	if o == nil {
		return nil
	}
	return o.ClusterName
}

func (o *CreateKafkaUpstreamPluginConfig) GetForwardBody() *bool {
	if o == nil {
		return nil
	}
	return o.ForwardBody
}

func (o *CreateKafkaUpstreamPluginConfig) GetForwardHeaders() *bool {
	if o == nil {
		return nil
	}
	return o.ForwardHeaders
}

func (o *CreateKafkaUpstreamPluginConfig) GetForwardMethod() *bool {
	if o == nil {
		return nil
	}
	return o.ForwardMethod
}

func (o *CreateKafkaUpstreamPluginConfig) GetForwardURI() *bool {
	if o == nil {
		return nil
	}
	return o.ForwardURI
}

func (o *CreateKafkaUpstreamPluginConfig) GetKeepalive() *int64 {
	if o == nil {
		return nil
	}
	return o.Keepalive
}

func (o *CreateKafkaUpstreamPluginConfig) GetKeepaliveEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.KeepaliveEnabled
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerAsync() *bool {
	if o == nil {
		return nil
	}
	return o.ProducerAsync
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerAsyncBufferingLimitsMessagesInMemory() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerAsyncBufferingLimitsMessagesInMemory
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerAsyncFlushTimeout() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerAsyncFlushTimeout
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestAcks() *CreateKafkaUpstreamPluginProducerRequestAcks {
	if o == nil {
		return nil
	}
	return o.ProducerRequestAcks
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestLimitsBytesPerRequest() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerRequestLimitsBytesPerRequest
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestLimitsMessagesPerRequest() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerRequestLimitsMessagesPerRequest
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestRetriesBackoffTimeout() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerRequestRetriesBackoffTimeout
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestRetriesMaxAttempts() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerRequestRetriesMaxAttempts
}

func (o *CreateKafkaUpstreamPluginConfig) GetProducerRequestTimeout() *int64 {
	if o == nil {
		return nil
	}
	return o.ProducerRequestTimeout
}

func (o *CreateKafkaUpstreamPluginConfig) GetSecurity() *CreateKafkaUpstreamPluginSecurity {
	if o == nil {
		return nil
	}
	return o.Security
}

func (o *CreateKafkaUpstreamPluginConfig) GetTimeout() *int64 {
	if o == nil {
		return nil
	}
	return o.Timeout
}

func (o *CreateKafkaUpstreamPluginConfig) GetTopic() *string {
	if o == nil {
		return nil
	}
	return o.Topic
}

type CreateKafkaUpstreamPluginAfter struct {
	Access []string `json:"access,omitempty"`
}

func (o *CreateKafkaUpstreamPluginAfter) GetAccess() []string {
	if o == nil {
		return nil
	}
	return o.Access
}

type CreateKafkaUpstreamPluginBefore struct {
	Access []string `json:"access,omitempty"`
}

func (o *CreateKafkaUpstreamPluginBefore) GetAccess() []string {
	if o == nil {
		return nil
	}
	return o.Access
}

type CreateKafkaUpstreamPluginOrdering struct {
	After  *CreateKafkaUpstreamPluginAfter  `json:"after,omitempty"`
	Before *CreateKafkaUpstreamPluginBefore `json:"before,omitempty"`
}

func (o *CreateKafkaUpstreamPluginOrdering) GetAfter() *CreateKafkaUpstreamPluginAfter {
	if o == nil {
		return nil
	}
	return o.After
}

func (o *CreateKafkaUpstreamPluginOrdering) GetBefore() *CreateKafkaUpstreamPluginBefore {
	if o == nil {
		return nil
	}
	return o.Before
}

type CreateKafkaUpstreamPluginProtocols string

const (
	CreateKafkaUpstreamPluginProtocolsGrpc           CreateKafkaUpstreamPluginProtocols = "grpc"
	CreateKafkaUpstreamPluginProtocolsGrpcs          CreateKafkaUpstreamPluginProtocols = "grpcs"
	CreateKafkaUpstreamPluginProtocolsHTTP           CreateKafkaUpstreamPluginProtocols = "http"
	CreateKafkaUpstreamPluginProtocolsHTTPS          CreateKafkaUpstreamPluginProtocols = "https"
	CreateKafkaUpstreamPluginProtocolsTCP            CreateKafkaUpstreamPluginProtocols = "tcp"
	CreateKafkaUpstreamPluginProtocolsTLS            CreateKafkaUpstreamPluginProtocols = "tls"
	CreateKafkaUpstreamPluginProtocolsTLSPassthrough CreateKafkaUpstreamPluginProtocols = "tls_passthrough"
	CreateKafkaUpstreamPluginProtocolsUDP            CreateKafkaUpstreamPluginProtocols = "udp"
	CreateKafkaUpstreamPluginProtocolsWs             CreateKafkaUpstreamPluginProtocols = "ws"
	CreateKafkaUpstreamPluginProtocolsWss            CreateKafkaUpstreamPluginProtocols = "wss"
)

func (e CreateKafkaUpstreamPluginProtocols) ToPointer() *CreateKafkaUpstreamPluginProtocols {
	return &e
}
func (e *CreateKafkaUpstreamPluginProtocols) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "grpcs":
		fallthrough
	case "http":
		fallthrough
	case "https":
		fallthrough
	case "tcp":
		fallthrough
	case "tls":
		fallthrough
	case "tls_passthrough":
		fallthrough
	case "udp":
		fallthrough
	case "ws":
		fallthrough
	case "wss":
		*e = CreateKafkaUpstreamPluginProtocols(v)
		return nil
	default:
		return fmt.Errorf("invalid value for CreateKafkaUpstreamPluginProtocols: %v", v)
	}
}

// CreateKafkaUpstreamPluginConsumer - If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
type CreateKafkaUpstreamPluginConsumer struct {
	ID *string `json:"id,omitempty"`
}

func (o *CreateKafkaUpstreamPluginConsumer) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

type CreateKafkaUpstreamPluginConsumerGroup struct {
	ID *string `json:"id,omitempty"`
}

func (o *CreateKafkaUpstreamPluginConsumerGroup) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

// CreateKafkaUpstreamPluginRoute - If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the Route being used.
type CreateKafkaUpstreamPluginRoute struct {
	ID *string `json:"id,omitempty"`
}

func (o *CreateKafkaUpstreamPluginRoute) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

// CreateKafkaUpstreamPluginService - If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
type CreateKafkaUpstreamPluginService struct {
	ID *string `json:"id,omitempty"`
}

func (o *CreateKafkaUpstreamPluginService) GetID() *string {
	if o == nil {
		return nil
	}
	return o.ID
}

type CreateKafkaUpstreamPlugin struct {
	Config *CreateKafkaUpstreamPluginConfig `json:"config,omitempty"`
	// Whether the plugin is applied.
	Enabled      *bool                              `json:"enabled,omitempty"`
	InstanceName *string                            `json:"instance_name,omitempty"`
	name         *string                            `const:"kafka-upstream" json:"name,omitempty"`
	Ordering     *CreateKafkaUpstreamPluginOrdering `json:"ordering,omitempty"`
	// A list of the request protocols that will trigger this plugin. The default value, as well as the possible values allowed on this field, may change depending on the plugin type. For example, plugins that only work in stream mode will only support `"tcp"` and `"tls"`.
	Protocols []CreateKafkaUpstreamPluginProtocols `json:"protocols,omitempty"`
	// An optional set of strings associated with the Plugin for grouping and filtering.
	Tags []string `json:"tags,omitempty"`
	// If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
	Consumer      *CreateKafkaUpstreamPluginConsumer      `json:"consumer,omitempty"`
	ConsumerGroup *CreateKafkaUpstreamPluginConsumerGroup `json:"consumer_group,omitempty"`
	// If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the Route being used.
	Route *CreateKafkaUpstreamPluginRoute `json:"route,omitempty"`
	// If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
	Service *CreateKafkaUpstreamPluginService `json:"service,omitempty"`
}

func (c CreateKafkaUpstreamPlugin) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(c, "", false)
}

func (c *CreateKafkaUpstreamPlugin) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &c, "", false, false); err != nil {
		return err
	}
	return nil
}

func (o *CreateKafkaUpstreamPlugin) GetConfig() *CreateKafkaUpstreamPluginConfig {
	if o == nil {
		return nil
	}
	return o.Config
}

func (o *CreateKafkaUpstreamPlugin) GetEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.Enabled
}

func (o *CreateKafkaUpstreamPlugin) GetInstanceName() *string {
	if o == nil {
		return nil
	}
	return o.InstanceName
}

func (o *CreateKafkaUpstreamPlugin) GetName() *string {
	return types.String("kafka-upstream")
}

func (o *CreateKafkaUpstreamPlugin) GetOrdering() *CreateKafkaUpstreamPluginOrdering {
	if o == nil {
		return nil
	}
	return o.Ordering
}

func (o *CreateKafkaUpstreamPlugin) GetProtocols() []CreateKafkaUpstreamPluginProtocols {
	if o == nil {
		return nil
	}
	return o.Protocols
}

func (o *CreateKafkaUpstreamPlugin) GetTags() []string {
	if o == nil {
		return nil
	}
	return o.Tags
}

func (o *CreateKafkaUpstreamPlugin) GetConsumer() *CreateKafkaUpstreamPluginConsumer {
	if o == nil {
		return nil
	}
	return o.Consumer
}

func (o *CreateKafkaUpstreamPlugin) GetConsumerGroup() *CreateKafkaUpstreamPluginConsumerGroup {
	if o == nil {
		return nil
	}
	return o.ConsumerGroup
}

func (o *CreateKafkaUpstreamPlugin) GetRoute() *CreateKafkaUpstreamPluginRoute {
	if o == nil {
		return nil
	}
	return o.Route
}

func (o *CreateKafkaUpstreamPlugin) GetService() *CreateKafkaUpstreamPluginService {
	if o == nil {
		return nil
	}
	return o.Service
}
