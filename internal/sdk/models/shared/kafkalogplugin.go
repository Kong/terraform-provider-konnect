// Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
	"github.com/kong/terraform-provider-konnect/v3/internal/sdk/internal/utils"
)

type KafkaLogPluginAfter struct {
	Access []string `json:"access,omitempty"`
}

func (k *KafkaLogPluginAfter) GetAccess() []string {
	if k == nil {
		return nil
	}
	return k.Access
}

type KafkaLogPluginBefore struct {
	Access []string `json:"access,omitempty"`
}

func (k *KafkaLogPluginBefore) GetAccess() []string {
	if k == nil {
		return nil
	}
	return k.Access
}

type KafkaLogPluginOrdering struct {
	After  *KafkaLogPluginAfter  `json:"after,omitempty"`
	Before *KafkaLogPluginBefore `json:"before,omitempty"`
}

func (k *KafkaLogPluginOrdering) GetAfter() *KafkaLogPluginAfter {
	if k == nil {
		return nil
	}
	return k.After
}

func (k *KafkaLogPluginOrdering) GetBefore() *KafkaLogPluginBefore {
	if k == nil {
		return nil
	}
	return k.Before
}

type KafkaLogPluginPartials struct {
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	Name *string `json:"name,omitempty"`
	Path *string `json:"path,omitempty"`
}

func (k *KafkaLogPluginPartials) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

func (k *KafkaLogPluginPartials) GetName() *string {
	if k == nil {
		return nil
	}
	return k.Name
}

func (k *KafkaLogPluginPartials) GetPath() *string {
	if k == nil {
		return nil
	}
	return k.Path
}

// KafkaLogPluginMechanism - The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256` or `SCRAM-SHA-512`.
type KafkaLogPluginMechanism string

const (
	KafkaLogPluginMechanismPlain       KafkaLogPluginMechanism = "PLAIN"
	KafkaLogPluginMechanismScramSha256 KafkaLogPluginMechanism = "SCRAM-SHA-256"
	KafkaLogPluginMechanismScramSha512 KafkaLogPluginMechanism = "SCRAM-SHA-512"
)

func (e KafkaLogPluginMechanism) ToPointer() *KafkaLogPluginMechanism {
	return &e
}
func (e *KafkaLogPluginMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PLAIN":
		fallthrough
	case "SCRAM-SHA-256":
		fallthrough
	case "SCRAM-SHA-512":
		*e = KafkaLogPluginMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginMechanism: %v", v)
	}
}

// KafkaLogPluginStrategy - The authentication strategy for the plugin, the only option for the value is `sasl`.
type KafkaLogPluginStrategy string

const (
	KafkaLogPluginStrategySasl KafkaLogPluginStrategy = "sasl"
)

func (e KafkaLogPluginStrategy) ToPointer() *KafkaLogPluginStrategy {
	return &e
}
func (e *KafkaLogPluginStrategy) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "sasl":
		*e = KafkaLogPluginStrategy(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginStrategy: %v", v)
	}
}

type KafkaLogPluginAuthentication struct {
	// The SASL authentication mechanism.  Supported options: `PLAIN`, `SCRAM-SHA-256` or `SCRAM-SHA-512`.
	Mechanism *KafkaLogPluginMechanism `json:"mechanism,omitempty"`
	// Password for SASL authentication.
	Password *string `default:"null" json:"password"`
	// The authentication strategy for the plugin, the only option for the value is `sasl`.
	Strategy *KafkaLogPluginStrategy `json:"strategy,omitempty"`
	// Enable this to indicate `DelegationToken` authentication
	Tokenauth *bool `default:"null" json:"tokenauth"`
	// Username for SASL authentication.
	User *string `default:"null" json:"user"`
}

func (k KafkaLogPluginAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginAuthentication) GetMechanism() *KafkaLogPluginMechanism {
	if k == nil {
		return nil
	}
	return k.Mechanism
}

func (k *KafkaLogPluginAuthentication) GetPassword() *string {
	if k == nil {
		return nil
	}
	return k.Password
}

func (k *KafkaLogPluginAuthentication) GetStrategy() *KafkaLogPluginStrategy {
	if k == nil {
		return nil
	}
	return k.Strategy
}

func (k *KafkaLogPluginAuthentication) GetTokenauth() *bool {
	if k == nil {
		return nil
	}
	return k.Tokenauth
}

func (k *KafkaLogPluginAuthentication) GetUser() *string {
	if k == nil {
		return nil
	}
	return k.User
}

type KafkaLogPluginBootstrapServers struct {
	// A string representing a host name, such as example.com.
	Host string `json:"host"`
	// An integer representing a port number between 0 and 65535, inclusive.
	Port int64 `json:"port"`
}

func (k *KafkaLogPluginBootstrapServers) GetHost() string {
	if k == nil {
		return ""
	}
	return k.Host
}

func (k *KafkaLogPluginBootstrapServers) GetPort() int64 {
	if k == nil {
		return 0
	}
	return k.Port
}

// KafkaLogPluginProducerRequestAcks - The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
type KafkaLogPluginProducerRequestAcks int64

const (
	KafkaLogPluginProducerRequestAcksMinus1 KafkaLogPluginProducerRequestAcks = -1
	KafkaLogPluginProducerRequestAcksZero   KafkaLogPluginProducerRequestAcks = 0
	KafkaLogPluginProducerRequestAcksOne    KafkaLogPluginProducerRequestAcks = 1
)

func (e KafkaLogPluginProducerRequestAcks) ToPointer() *KafkaLogPluginProducerRequestAcks {
	return &e
}
func (e *KafkaLogPluginProducerRequestAcks) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case -1:
		fallthrough
	case 0:
		fallthrough
	case 1:
		*e = KafkaLogPluginProducerRequestAcks(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginProducerRequestAcks: %v", v)
	}
}

type KafkaLogPluginBasic struct {
	Password string `json:"password"`
	Username string `json:"username"`
}

func (k *KafkaLogPluginBasic) GetPassword() string {
	if k == nil {
		return ""
	}
	return k.Password
}

func (k *KafkaLogPluginBasic) GetUsername() string {
	if k == nil {
		return ""
	}
	return k.Username
}

// KafkaLogPluginMode - Authentication mode to use with the schema registry.
type KafkaLogPluginMode string

const (
	KafkaLogPluginModeBasic  KafkaLogPluginMode = "basic"
	KafkaLogPluginModeNone   KafkaLogPluginMode = "none"
	KafkaLogPluginModeOauth2 KafkaLogPluginMode = "oauth2"
)

func (e KafkaLogPluginMode) ToPointer() *KafkaLogPluginMode {
	return &e
}
func (e *KafkaLogPluginMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "basic":
		fallthrough
	case "none":
		fallthrough
	case "oauth2":
		*e = KafkaLogPluginMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginMode: %v", v)
	}
}

// KafkaLogPluginGrantType - The OAuth grant type to be used.
type KafkaLogPluginGrantType string

const (
	KafkaLogPluginGrantTypeClientCredentials KafkaLogPluginGrantType = "client_credentials"
	KafkaLogPluginGrantTypePassword          KafkaLogPluginGrantType = "password"
)

func (e KafkaLogPluginGrantType) ToPointer() *KafkaLogPluginGrantType {
	return &e
}
func (e *KafkaLogPluginGrantType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "client_credentials":
		fallthrough
	case "password":
		*e = KafkaLogPluginGrantType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginGrantType: %v", v)
	}
}

type KafkaLogPluginOauth2 struct {
	// List of audiences passed to the IdP when obtaining a new token.
	Audience []string `json:"audience,omitempty"`
	// The client ID for the application registration in the IdP.
	ClientID *string `default:"null" json:"client_id"`
	// The client secret for the application registration in the IdP.
	ClientSecret *string `default:"null" json:"client_secret"`
	// The OAuth grant type to be used.
	GrantType *KafkaLogPluginGrantType `default:"client_credentials" json:"grant_type"`
	// The password to use if `config.oauth.grant_type` is set to `password`.
	Password *string `default:"null" json:"password"`
	// List of scopes to request from the IdP when obtaining a new token.
	Scopes []string `json:"scopes,omitempty"`
	// The token endpoint URI.
	TokenEndpoint string `json:"token_endpoint"`
	// Extra headers to be passed in the token endpoint request.
	TokenHeaders map[string]any `json:"token_headers,omitempty"`
	// Extra post arguments to be passed in the token endpoint request.
	TokenPostArgs map[string]any `json:"token_post_args,omitempty"`
	// The username to use if `config.oauth.grant_type` is set to `password`.
	Username *string `default:"null" json:"username"`
}

func (k KafkaLogPluginOauth2) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginOauth2) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, []string{"token_endpoint"}); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginOauth2) GetAudience() []string {
	if k == nil {
		return nil
	}
	return k.Audience
}

func (k *KafkaLogPluginOauth2) GetClientID() *string {
	if k == nil {
		return nil
	}
	return k.ClientID
}

func (k *KafkaLogPluginOauth2) GetClientSecret() *string {
	if k == nil {
		return nil
	}
	return k.ClientSecret
}

func (k *KafkaLogPluginOauth2) GetGrantType() *KafkaLogPluginGrantType {
	if k == nil {
		return nil
	}
	return k.GrantType
}

func (k *KafkaLogPluginOauth2) GetPassword() *string {
	if k == nil {
		return nil
	}
	return k.Password
}

func (k *KafkaLogPluginOauth2) GetScopes() []string {
	if k == nil {
		return nil
	}
	return k.Scopes
}

func (k *KafkaLogPluginOauth2) GetTokenEndpoint() string {
	if k == nil {
		return ""
	}
	return k.TokenEndpoint
}

func (k *KafkaLogPluginOauth2) GetTokenHeaders() map[string]any {
	if k == nil {
		return nil
	}
	return k.TokenHeaders
}

func (k *KafkaLogPluginOauth2) GetTokenPostArgs() map[string]any {
	if k == nil {
		return nil
	}
	return k.TokenPostArgs
}

func (k *KafkaLogPluginOauth2) GetUsername() *string {
	if k == nil {
		return nil
	}
	return k.Username
}

// KafkaLogPluginAuthMethod - The authentication method used in client requests to the IdP. Supported values are: `client_secret_basic` to send `client_id` and `client_secret` in the `Authorization: Basic` header, `client_secret_post` to send `client_id` and `client_secret` as part of the request body, or `client_secret_jwt` to send a JWT signed with the `client_secret` using the client assertion as part of the body.
type KafkaLogPluginAuthMethod string

const (
	KafkaLogPluginAuthMethodClientSecretBasic KafkaLogPluginAuthMethod = "client_secret_basic"
	KafkaLogPluginAuthMethodClientSecretJwt   KafkaLogPluginAuthMethod = "client_secret_jwt"
	KafkaLogPluginAuthMethodClientSecretPost  KafkaLogPluginAuthMethod = "client_secret_post"
	KafkaLogPluginAuthMethodNone              KafkaLogPluginAuthMethod = "none"
)

func (e KafkaLogPluginAuthMethod) ToPointer() *KafkaLogPluginAuthMethod {
	return &e
}
func (e *KafkaLogPluginAuthMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "client_secret_basic":
		fallthrough
	case "client_secret_jwt":
		fallthrough
	case "client_secret_post":
		fallthrough
	case "none":
		*e = KafkaLogPluginAuthMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginAuthMethod: %v", v)
	}
}

// KafkaLogPluginClientSecretJwtAlg - The algorithm to use with JWT when using `client_secret_jwt` authentication.
type KafkaLogPluginClientSecretJwtAlg string

const (
	KafkaLogPluginClientSecretJwtAlgHs256 KafkaLogPluginClientSecretJwtAlg = "HS256"
	KafkaLogPluginClientSecretJwtAlgHs512 KafkaLogPluginClientSecretJwtAlg = "HS512"
)

func (e KafkaLogPluginClientSecretJwtAlg) ToPointer() *KafkaLogPluginClientSecretJwtAlg {
	return &e
}
func (e *KafkaLogPluginClientSecretJwtAlg) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "HS256":
		fallthrough
	case "HS512":
		*e = KafkaLogPluginClientSecretJwtAlg(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginClientSecretJwtAlg: %v", v)
	}
}

type KafkaLogPluginOauth2Client struct {
	// The authentication method used in client requests to the IdP. Supported values are: `client_secret_basic` to send `client_id` and `client_secret` in the `Authorization: Basic` header, `client_secret_post` to send `client_id` and `client_secret` as part of the request body, or `client_secret_jwt` to send a JWT signed with the `client_secret` using the client assertion as part of the body.
	AuthMethod *KafkaLogPluginAuthMethod `default:"client_secret_post" json:"auth_method"`
	// The algorithm to use with JWT when using `client_secret_jwt` authentication.
	ClientSecretJwtAlg *KafkaLogPluginClientSecretJwtAlg `default:"HS512" json:"client_secret_jwt_alg"`
	// The proxy to use when making HTTP requests to the IdP.
	HTTPProxy *string `default:"null" json:"http_proxy"`
	// The `Proxy-Authorization` header value to be used with `http_proxy`.
	HTTPProxyAuthorization *string `default:"null" json:"http_proxy_authorization"`
	// The HTTP version used for requests made by this plugin. Supported values: `1.1` for HTTP 1.1 and `1.0` for HTTP 1.0.
	HTTPVersion *float64 `default:"1.1" json:"http_version"`
	// The proxy to use when making HTTPS requests to the IdP.
	HTTPSProxy *string `default:"null" json:"https_proxy"`
	// The `Proxy-Authorization` header value to be used with `https_proxy`.
	HTTPSProxyAuthorization *string `default:"null" json:"https_proxy_authorization"`
	// Whether to use keepalive connections to the IdP.
	KeepAlive *bool `default:"true" json:"keep_alive"`
	// A comma-separated list of hosts that should not be proxied.
	NoProxy *string `default:"null" json:"no_proxy"`
	// Whether to verify the certificate presented by the IdP when using HTTPS.
	SslVerify *bool `default:"false" json:"ssl_verify"`
	// Network I/O timeout for requests to the IdP in milliseconds.
	Timeout *int64 `default:"10000" json:"timeout"`
}

func (k KafkaLogPluginOauth2Client) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginOauth2Client) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginOauth2Client) GetAuthMethod() *KafkaLogPluginAuthMethod {
	if k == nil {
		return nil
	}
	return k.AuthMethod
}

func (k *KafkaLogPluginOauth2Client) GetClientSecretJwtAlg() *KafkaLogPluginClientSecretJwtAlg {
	if k == nil {
		return nil
	}
	return k.ClientSecretJwtAlg
}

func (k *KafkaLogPluginOauth2Client) GetHTTPProxy() *string {
	if k == nil {
		return nil
	}
	return k.HTTPProxy
}

func (k *KafkaLogPluginOauth2Client) GetHTTPProxyAuthorization() *string {
	if k == nil {
		return nil
	}
	return k.HTTPProxyAuthorization
}

func (k *KafkaLogPluginOauth2Client) GetHTTPVersion() *float64 {
	if k == nil {
		return nil
	}
	return k.HTTPVersion
}

func (k *KafkaLogPluginOauth2Client) GetHTTPSProxy() *string {
	if k == nil {
		return nil
	}
	return k.HTTPSProxy
}

func (k *KafkaLogPluginOauth2Client) GetHTTPSProxyAuthorization() *string {
	if k == nil {
		return nil
	}
	return k.HTTPSProxyAuthorization
}

func (k *KafkaLogPluginOauth2Client) GetKeepAlive() *bool {
	if k == nil {
		return nil
	}
	return k.KeepAlive
}

func (k *KafkaLogPluginOauth2Client) GetNoProxy() *string {
	if k == nil {
		return nil
	}
	return k.NoProxy
}

func (k *KafkaLogPluginOauth2Client) GetSslVerify() *bool {
	if k == nil {
		return nil
	}
	return k.SslVerify
}

func (k *KafkaLogPluginOauth2Client) GetTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.Timeout
}

type KafkaLogPluginConfigAuthentication struct {
	Basic *KafkaLogPluginBasic `json:"basic"`
	// Authentication mode to use with the schema registry.
	Mode         *KafkaLogPluginMode         `default:"none" json:"mode"`
	Oauth2       *KafkaLogPluginOauth2       `json:"oauth2"`
	Oauth2Client *KafkaLogPluginOauth2Client `json:"oauth2_client"`
}

func (k KafkaLogPluginConfigAuthentication) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginConfigAuthentication) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginConfigAuthentication) GetBasic() *KafkaLogPluginBasic {
	if k == nil {
		return nil
	}
	return k.Basic
}

func (k *KafkaLogPluginConfigAuthentication) GetMode() *KafkaLogPluginMode {
	if k == nil {
		return nil
	}
	return k.Mode
}

func (k *KafkaLogPluginConfigAuthentication) GetOauth2() *KafkaLogPluginOauth2 {
	if k == nil {
		return nil
	}
	return k.Oauth2
}

func (k *KafkaLogPluginConfigAuthentication) GetOauth2Client() *KafkaLogPluginOauth2Client {
	if k == nil {
		return nil
	}
	return k.Oauth2Client
}

type KafkaLogPluginKeySchema struct {
	// The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.
	SchemaVersion *string `default:"null" json:"schema_version"`
	// The name of the subject
	SubjectName *string `default:"null" json:"subject_name"`
}

func (k KafkaLogPluginKeySchema) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginKeySchema) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginKeySchema) GetSchemaVersion() *string {
	if k == nil {
		return nil
	}
	return k.SchemaVersion
}

func (k *KafkaLogPluginKeySchema) GetSubjectName() *string {
	if k == nil {
		return nil
	}
	return k.SubjectName
}

type KafkaLogPluginValueSchema struct {
	// The schema version to use for serialization/deserialization. Use 'latest' to always fetch the most recent version.
	SchemaVersion *string `default:"null" json:"schema_version"`
	// The name of the subject
	SubjectName *string `default:"null" json:"subject_name"`
}

func (k KafkaLogPluginValueSchema) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginValueSchema) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginValueSchema) GetSchemaVersion() *string {
	if k == nil {
		return nil
	}
	return k.SchemaVersion
}

func (k *KafkaLogPluginValueSchema) GetSubjectName() *string {
	if k == nil {
		return nil
	}
	return k.SubjectName
}

type KafkaLogPluginConfluent struct {
	Authentication *KafkaLogPluginConfigAuthentication `json:"authentication"`
	KeySchema      *KafkaLogPluginKeySchema            `json:"key_schema"`
	// Set to false to disable SSL certificate verification when connecting to the schema registry.
	SslVerify *bool `default:"true" json:"ssl_verify"`
	// The TTL in seconds for the schema registry cache.
	TTL *float64 `default:"null" json:"ttl"`
	// The URL of the schema registry.
	URL         *string                    `default:"null" json:"url"`
	ValueSchema *KafkaLogPluginValueSchema `json:"value_schema"`
}

func (k KafkaLogPluginConfluent) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginConfluent) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginConfluent) GetAuthentication() *KafkaLogPluginConfigAuthentication {
	if k == nil {
		return nil
	}
	return k.Authentication
}

func (k *KafkaLogPluginConfluent) GetKeySchema() *KafkaLogPluginKeySchema {
	if k == nil {
		return nil
	}
	return k.KeySchema
}

func (k *KafkaLogPluginConfluent) GetSslVerify() *bool {
	if k == nil {
		return nil
	}
	return k.SslVerify
}

func (k *KafkaLogPluginConfluent) GetTTL() *float64 {
	if k == nil {
		return nil
	}
	return k.TTL
}

func (k *KafkaLogPluginConfluent) GetURL() *string {
	if k == nil {
		return nil
	}
	return k.URL
}

func (k *KafkaLogPluginConfluent) GetValueSchema() *KafkaLogPluginValueSchema {
	if k == nil {
		return nil
	}
	return k.ValueSchema
}

// KafkaLogPluginSchemaRegistry - The plugin-global schema registry configuration. This can be overwritten by the topic configuration.
type KafkaLogPluginSchemaRegistry struct {
	Confluent *KafkaLogPluginConfluent `json:"confluent"`
}

func (k *KafkaLogPluginSchemaRegistry) GetConfluent() *KafkaLogPluginConfluent {
	if k == nil {
		return nil
	}
	return k.Confluent
}

type KafkaLogPluginSecurity struct {
	// UUID of certificate entity for mTLS authentication.
	CertificateID *string `default:"null" json:"certificate_id"`
	// Enables TLS.
	Ssl *bool `default:"null" json:"ssl"`
}

func (k KafkaLogPluginSecurity) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginSecurity) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, nil); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginSecurity) GetCertificateID() *string {
	if k == nil {
		return nil
	}
	return k.CertificateID
}

func (k *KafkaLogPluginSecurity) GetSsl() *bool {
	if k == nil {
		return nil
	}
	return k.Ssl
}

type KafkaLogPluginConfig struct {
	Authentication *KafkaLogPluginAuthentication `json:"authentication"`
	// Set of bootstrap brokers in a `{host: host, port: port}` list format.
	BootstrapServers []KafkaLogPluginBootstrapServers `json:"bootstrap_servers"`
	// An identifier for the Kafka cluster. By default, this field generates a random string. You can also set your own custom cluster identifier.  If more than one Kafka plugin is configured without a `cluster_name` (that is, if the default autogenerated value is removed), these plugins will use the same producer, and by extension, the same cluster. Logs will be sent to the leader of the cluster.
	ClusterName *string `default:"null" json:"cluster_name"`
	// Lua code as a key-value map
	CustomFieldsByLua map[string]string `json:"custom_fields_by_lua,omitempty"`
	Keepalive         *int64            `default:"60000" json:"keepalive"`
	KeepaliveEnabled  *bool             `default:"false" json:"keepalive_enabled"`
	// The request query parameter name that contains the Kafka message key. If specified, messages with the same key will be sent to the same Kafka partition, ensuring consistent ordering.
	KeyQueryArg *string `default:"null" json:"key_query_arg"`
	// Flag to enable asynchronous mode.
	ProducerAsync *bool `default:"true" json:"producer_async"`
	// Maximum number of messages that can be buffered in memory in asynchronous mode.
	ProducerAsyncBufferingLimitsMessagesInMemory *int64 `default:"50000" json:"producer_async_buffering_limits_messages_in_memory"`
	// Maximum time interval in milliseconds between buffer flushes in asynchronous mode.
	ProducerAsyncFlushTimeout *int64 `default:"1000" json:"producer_async_flush_timeout"`
	// The number of acknowledgments the producer requires the leader to have received before considering a request complete. Allowed values: 0 for no acknowledgments; 1 for only the leader; and -1 for the full ISR (In-Sync Replica set).
	ProducerRequestAcks *KafkaLogPluginProducerRequestAcks `default:"1" json:"producer_request_acks"`
	// Maximum size of a Produce request in bytes.
	ProducerRequestLimitsBytesPerRequest *int64 `default:"1048576" json:"producer_request_limits_bytes_per_request"`
	// Maximum number of messages to include into a single Produce request.
	ProducerRequestLimitsMessagesPerRequest *int64 `default:"200" json:"producer_request_limits_messages_per_request"`
	// Backoff interval between retry attempts in milliseconds.
	ProducerRequestRetriesBackoffTimeout *int64 `default:"100" json:"producer_request_retries_backoff_timeout"`
	// Maximum number of retry attempts per single Produce request.
	ProducerRequestRetriesMaxAttempts *int64 `default:"10" json:"producer_request_retries_max_attempts"`
	// Time to wait for a Produce response in milliseconds
	ProducerRequestTimeout *int64 `default:"2000" json:"producer_request_timeout"`
	// The plugin-global schema registry configuration. This can be overwritten by the topic configuration.
	SchemaRegistry *KafkaLogPluginSchemaRegistry `json:"schema_registry"`
	Security       *KafkaLogPluginSecurity       `json:"security"`
	// Socket timeout in milliseconds.
	Timeout *int64 `default:"10000" json:"timeout"`
	// The Kafka topic to publish to.
	Topic string `json:"topic"`
}

func (k KafkaLogPluginConfig) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPluginConfig) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, []string{"topic"}); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPluginConfig) GetAuthentication() *KafkaLogPluginAuthentication {
	if k == nil {
		return nil
	}
	return k.Authentication
}

func (k *KafkaLogPluginConfig) GetBootstrapServers() []KafkaLogPluginBootstrapServers {
	if k == nil {
		return nil
	}
	return k.BootstrapServers
}

func (k *KafkaLogPluginConfig) GetClusterName() *string {
	if k == nil {
		return nil
	}
	return k.ClusterName
}

func (k *KafkaLogPluginConfig) GetCustomFieldsByLua() map[string]string {
	if k == nil {
		return nil
	}
	return k.CustomFieldsByLua
}

func (k *KafkaLogPluginConfig) GetKeepalive() *int64 {
	if k == nil {
		return nil
	}
	return k.Keepalive
}

func (k *KafkaLogPluginConfig) GetKeepaliveEnabled() *bool {
	if k == nil {
		return nil
	}
	return k.KeepaliveEnabled
}

func (k *KafkaLogPluginConfig) GetKeyQueryArg() *string {
	if k == nil {
		return nil
	}
	return k.KeyQueryArg
}

func (k *KafkaLogPluginConfig) GetProducerAsync() *bool {
	if k == nil {
		return nil
	}
	return k.ProducerAsync
}

func (k *KafkaLogPluginConfig) GetProducerAsyncBufferingLimitsMessagesInMemory() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerAsyncBufferingLimitsMessagesInMemory
}

func (k *KafkaLogPluginConfig) GetProducerAsyncFlushTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerAsyncFlushTimeout
}

func (k *KafkaLogPluginConfig) GetProducerRequestAcks() *KafkaLogPluginProducerRequestAcks {
	if k == nil {
		return nil
	}
	return k.ProducerRequestAcks
}

func (k *KafkaLogPluginConfig) GetProducerRequestLimitsBytesPerRequest() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestLimitsBytesPerRequest
}

func (k *KafkaLogPluginConfig) GetProducerRequestLimitsMessagesPerRequest() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestLimitsMessagesPerRequest
}

func (k *KafkaLogPluginConfig) GetProducerRequestRetriesBackoffTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestRetriesBackoffTimeout
}

func (k *KafkaLogPluginConfig) GetProducerRequestRetriesMaxAttempts() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestRetriesMaxAttempts
}

func (k *KafkaLogPluginConfig) GetProducerRequestTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.ProducerRequestTimeout
}

func (k *KafkaLogPluginConfig) GetSchemaRegistry() *KafkaLogPluginSchemaRegistry {
	if k == nil {
		return nil
	}
	return k.SchemaRegistry
}

func (k *KafkaLogPluginConfig) GetSecurity() *KafkaLogPluginSecurity {
	if k == nil {
		return nil
	}
	return k.Security
}

func (k *KafkaLogPluginConfig) GetTimeout() *int64 {
	if k == nil {
		return nil
	}
	return k.Timeout
}

func (k *KafkaLogPluginConfig) GetTopic() string {
	if k == nil {
		return ""
	}
	return k.Topic
}

// KafkaLogPluginConsumer - If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
type KafkaLogPluginConsumer struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaLogPluginConsumer) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

type KafkaLogPluginProtocols string

const (
	KafkaLogPluginProtocolsGrpc  KafkaLogPluginProtocols = "grpc"
	KafkaLogPluginProtocolsGrpcs KafkaLogPluginProtocols = "grpcs"
	KafkaLogPluginProtocolsHTTP  KafkaLogPluginProtocols = "http"
	KafkaLogPluginProtocolsHTTPS KafkaLogPluginProtocols = "https"
	KafkaLogPluginProtocolsWs    KafkaLogPluginProtocols = "ws"
	KafkaLogPluginProtocolsWss   KafkaLogPluginProtocols = "wss"
)

func (e KafkaLogPluginProtocols) ToPointer() *KafkaLogPluginProtocols {
	return &e
}
func (e *KafkaLogPluginProtocols) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "grpc":
		fallthrough
	case "grpcs":
		fallthrough
	case "http":
		fallthrough
	case "https":
		fallthrough
	case "ws":
		fallthrough
	case "wss":
		*e = KafkaLogPluginProtocols(v)
		return nil
	default:
		return fmt.Errorf("invalid value for KafkaLogPluginProtocols: %v", v)
	}
}

// KafkaLogPluginRoute - If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
type KafkaLogPluginRoute struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaLogPluginRoute) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

// KafkaLogPluginService - If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
type KafkaLogPluginService struct {
	ID *string `json:"id,omitempty"`
}

func (k *KafkaLogPluginService) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

// KafkaLogPlugin - A Plugin entity represents a plugin configuration that will be executed during the HTTP request/response lifecycle. It is how you can add functionalities to Services that run behind Kong, like Authentication or Rate Limiting for example. You can find more information about how to install and what values each plugin takes by visiting the [Kong Hub](https://docs.konghq.com/hub/). When adding a Plugin Configuration to a Service, every request made by a client to that Service will run said Plugin. If a Plugin needs to be tuned to different values for some specific Consumers, you can do so by creating a separate plugin instance that specifies both the Service and the Consumer, through the `service` and `consumer` fields.
type KafkaLogPlugin struct {
	// Unix epoch when the resource was created.
	CreatedAt *int64 `json:"created_at,omitempty"`
	// Whether the plugin is applied.
	Enabled *bool `default:"true" json:"enabled"`
	// A string representing a UUID (universally unique identifier).
	ID *string `json:"id,omitempty"`
	// A unique string representing a UTF-8 encoded name.
	InstanceName *string                 `default:"null" json:"instance_name"`
	name         string                  `const:"kafka-log" json:"name"`
	Ordering     *KafkaLogPluginOrdering `json:"ordering"`
	// A list of partials to be used by the plugin.
	Partials []KafkaLogPluginPartials `json:"partials"`
	// An optional set of strings associated with the Plugin for grouping and filtering.
	Tags []string `json:"tags"`
	// Unix epoch when the resource was last updated.
	UpdatedAt *int64               `json:"updated_at,omitempty"`
	Config    KafkaLogPluginConfig `json:"config"`
	// If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer.
	Consumer *KafkaLogPluginConsumer `json:"consumer"`
	// A list of the request protocols that will trigger this plugin. The default value, as well as the possible values allowed on this field, may change depending on the plugin type. For example, plugins that only work in stream mode will only support tcp and tls.
	Protocols []KafkaLogPluginProtocols `json:"protocols"`
	// If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used.
	Route *KafkaLogPluginRoute `json:"route"`
	// If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched.
	Service *KafkaLogPluginService `json:"service"`
}

func (k KafkaLogPlugin) MarshalJSON() ([]byte, error) {
	return utils.MarshalJSON(k, "", false)
}

func (k *KafkaLogPlugin) UnmarshalJSON(data []byte) error {
	if err := utils.UnmarshalJSON(data, &k, "", false, []string{"name", "config"}); err != nil {
		return err
	}
	return nil
}

func (k *KafkaLogPlugin) GetCreatedAt() *int64 {
	if k == nil {
		return nil
	}
	return k.CreatedAt
}

func (k *KafkaLogPlugin) GetEnabled() *bool {
	if k == nil {
		return nil
	}
	return k.Enabled
}

func (k *KafkaLogPlugin) GetID() *string {
	if k == nil {
		return nil
	}
	return k.ID
}

func (k *KafkaLogPlugin) GetInstanceName() *string {
	if k == nil {
		return nil
	}
	return k.InstanceName
}

func (k *KafkaLogPlugin) GetName() string {
	return "kafka-log"
}

func (k *KafkaLogPlugin) GetOrdering() *KafkaLogPluginOrdering {
	if k == nil {
		return nil
	}
	return k.Ordering
}

func (k *KafkaLogPlugin) GetPartials() []KafkaLogPluginPartials {
	if k == nil {
		return nil
	}
	return k.Partials
}

func (k *KafkaLogPlugin) GetTags() []string {
	if k == nil {
		return nil
	}
	return k.Tags
}

func (k *KafkaLogPlugin) GetUpdatedAt() *int64 {
	if k == nil {
		return nil
	}
	return k.UpdatedAt
}

func (k *KafkaLogPlugin) GetConfig() KafkaLogPluginConfig {
	if k == nil {
		return KafkaLogPluginConfig{}
	}
	return k.Config
}

func (k *KafkaLogPlugin) GetConsumer() *KafkaLogPluginConsumer {
	if k == nil {
		return nil
	}
	return k.Consumer
}

func (k *KafkaLogPlugin) GetProtocols() []KafkaLogPluginProtocols {
	if k == nil {
		return nil
	}
	return k.Protocols
}

func (k *KafkaLogPlugin) GetRoute() *KafkaLogPluginRoute {
	if k == nil {
		return nil
	}
	return k.Route
}

func (k *KafkaLogPlugin) GetService() *KafkaLogPluginService {
	if k == nil {
		return nil
	}
	return k.Service
}
