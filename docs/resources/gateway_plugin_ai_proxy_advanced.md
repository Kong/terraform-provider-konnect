---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "konnect_gateway_plugin_ai_proxy_advanced Resource - terraform-provider-konnect"
subcategory: ""
description: |-
  GatewayPluginAiProxyAdvanced Resource
---

# konnect_gateway_plugin_ai_proxy_advanced (Resource)

GatewayPluginAiProxyAdvanced Resource

## Example Usage

```terraform
resource "konnect_gateway_plugin_ai_proxy_advanced" "my_gatewaypluginaiproxyadvanced" {
  config = {
    balancer = {
      algorithm       = "lowest-latency"
      connect_timeout = 1069677678
      fail_timeout    = 251767862
      failover_criteria = [
        "http_403"
      ]
      hash_on_header        = "...my_hash_on_header..."
      latency_strategy      = "e2e"
      max_fails             = 32489
      read_timeout          = 1128540479
      retries               = 14809
      slots                 = 27573
      tokens_count_strategy = "prompt-tokens"
      write_timeout         = 1475900303
    }
    embeddings = {
      auth = {
        allow_override             = true
        aws_access_key_id          = "...my_aws_access_key_id..."
        aws_secret_access_key      = "...my_aws_secret_access_key..."
        azure_client_id            = "...my_azure_client_id..."
        azure_client_secret        = "...my_azure_client_secret..."
        azure_tenant_id            = "...my_azure_tenant_id..."
        azure_use_managed_identity = false
        gcp_service_account_json   = "...my_gcp_service_account_json..."
        gcp_use_service_account    = false
        header_name                = "...my_header_name..."
        header_value               = "...my_header_value..."
        param_location             = "body"
        param_name                 = "...my_param_name..."
        param_value                = "...my_param_value..."
      }
      model = {
        name = "...my_name..."
        options = {
          azure = {
            api_version   = "...my_api_version..."
            deployment_id = "...my_deployment_id..."
            instance      = "...my_instance..."
          }
          bedrock = {
            aws_assume_role_arn        = "...my_aws_assume_role_arn..."
            aws_region                 = "...my_aws_region..."
            aws_role_session_name      = "...my_aws_role_session_name..."
            aws_sts_endpoint_url       = "...my_aws_sts_endpoint_url..."
            embeddings_normalize       = true
            performance_config_latency = "...my_performance_config_latency..."
            video_output_s3_uri        = "...my_video_output_s3_uri..."
          }
          gemini = {
            api_endpoint = "...my_api_endpoint..."
            location_id  = "...my_location_id..."
            project_id   = "...my_project_id..."
          }
          huggingface = {
            use_cache      = false
            wait_for_model = false
          }
          upstream_url = "...my_upstream_url..."
        }
        provider = "gemini"
      }
    }
    genai_category        = "image/generation"
    llm_format            = "huggingface"
    max_request_body_size = 5
    model_name_header     = true
    response_streaming    = "allow"
    targets = [
      {
        auth = {
          allow_override             = true
          aws_access_key_id          = "...my_aws_access_key_id..."
          aws_secret_access_key      = "...my_aws_secret_access_key..."
          azure_client_id            = "...my_azure_client_id..."
          azure_client_secret        = "...my_azure_client_secret..."
          azure_tenant_id            = "...my_azure_tenant_id..."
          azure_use_managed_identity = true
          gcp_service_account_json   = "...my_gcp_service_account_json..."
          gcp_use_service_account    = false
          header_name                = "...my_header_name..."
          header_value               = "...my_header_value..."
          param_location             = "query"
          param_name                 = "...my_param_name..."
          param_value                = "...my_param_value..."
        }
        description = "...my_description..."
        logging = {
          log_payloads   = true
          log_statistics = true
        }
        metadata = {
          key = jsonencode("value")
        }
        model = {
          name = "...my_name..."
          options = {
            anthropic_version   = "...my_anthropic_version..."
            azure_api_version   = "...my_azure_api_version..."
            azure_deployment_id = "...my_azure_deployment_id..."
            azure_instance      = "...my_azure_instance..."
            bedrock = {
              aws_assume_role_arn        = "...my_aws_assume_role_arn..."
              aws_region                 = "...my_aws_region..."
              aws_role_session_name      = "...my_aws_role_session_name..."
              aws_sts_endpoint_url       = "...my_aws_sts_endpoint_url..."
              embeddings_normalize       = true
              performance_config_latency = "...my_performance_config_latency..."
              video_output_s3_uri        = "...my_video_output_s3_uri..."
            }
            cohere = {
              embedding_input_type = "classification"
              wait_for_model       = true
            }
            dashscope = {
              international = true
            }
            embeddings_dimensions = 6
            gemini = {
              api_endpoint = "...my_api_endpoint..."
              endpoint_id  = "...my_endpoint_id..."
              location_id  = "...my_location_id..."
              project_id   = "...my_project_id..."
            }
            huggingface = {
              use_cache      = true
              wait_for_model = false
            }
            input_cost     = 2.57
            llama2_format  = "openai"
            max_tokens     = 2
            mistral_format = "openai"
            output_cost    = 7.34
            temperature    = 3.51
            top_k          = 204
            top_p          = 0.37
            upstream_path  = "...my_upstream_path..."
            upstream_url   = "...my_upstream_url..."
          }
          provider = "cerebras"
        }
        route_type = "llm/v1/assistants"
        weight     = 58189
      }
    ]
    vectordb = {
      dimensions      = 3
      distance_metric = "euclidean"
      pgvector = {
        database     = "...my_database..."
        host         = "...my_host..."
        password     = "...my_password..."
        port         = 5
        ssl          = true
        ssl_cert     = "...my_ssl_cert..."
        ssl_cert_key = "...my_ssl_cert_key..."
        ssl_required = true
        ssl_verify   = true
        ssl_version  = "any"
        timeout      = 3.81
        user         = "...my_user..."
      }
      redis = {
        cloud_authentication = {
          auth_provider            = "azure"
          aws_access_key_id        = "...my_aws_access_key_id..."
          aws_assume_role_arn      = "...my_aws_assume_role_arn..."
          aws_cache_name           = "...my_aws_cache_name..."
          aws_is_serverless        = false
          aws_region               = "...my_aws_region..."
          aws_role_session_name    = "...my_aws_role_session_name..."
          aws_secret_access_key    = "...my_aws_secret_access_key..."
          azure_client_id          = "...my_azure_client_id..."
          azure_client_secret      = "...my_azure_client_secret..."
          azure_tenant_id          = "...my_azure_tenant_id..."
          gcp_service_account_json = "...my_gcp_service_account_json..."
        }
        cluster_max_redirections = 4
        cluster_nodes = [
          {
            ip   = "...my_ip..."
            port = 50944
          }
        ]
        connect_timeout       = 656443886
        connection_is_proxied = false
        database              = 10
        host                  = "...my_host..."
        keepalive_backlog     = 251172057
        keepalive_pool_size   = 1127137192
        password              = "...my_password..."
        port                  = 31201
        read_timeout          = 1222450418
        send_timeout          = 1541453227
        sentinel_master       = "...my_sentinel_master..."
        sentinel_nodes = [
          {
            host = "...my_host..."
            port = 61553
          }
        ]
        sentinel_password = "...my_sentinel_password..."
        sentinel_role     = "master"
        sentinel_username = "...my_sentinel_username..."
        server_name       = "...my_server_name..."
        ssl               = true
        ssl_verify        = false
        username          = "...my_username..."
      }
      strategy  = "pgvector"
      threshold = 6.56
    }
  }
  consumer = {
    id = "...my_id..."
  }
  consumer_group = {
    id = "...my_id..."
  }
  control_plane_id = "9524ec7d-36d9-465d-a8c5-83a3c9390458"
  created_at       = 3
  enabled          = true
  id               = "...my_id..."
  instance_name    = "...my_instance_name..."
  ordering = {
    after = {
      access = [
        "..."
      ]
    }
    before = {
      access = [
        "..."
      ]
    }
  }
  partials = [
    {
      id   = "...my_id..."
      name = "...my_name..."
      path = "...my_path..."
    }
  ]
  protocols = [
    "ws"
  ]
  route = {
    id = "...my_id..."
  }
  service = {
    id = "...my_id..."
  }
  tags = [
    "..."
  ]
  updated_at = 8
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `config` (Attributes) (see [below for nested schema](#nestedatt--config))
- `control_plane_id` (String) The UUID of your control plane. This variable is available in the Konnect manager. Requires replacement if changed.

### Optional

- `consumer` (Attributes) If set, the plugin will activate only for requests where the specified has been authenticated. (Note that some plugins can not be restricted to consumers this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer. (see [below for nested schema](#nestedatt--consumer))
- `consumer_group` (Attributes) If set, the plugin will activate only for requests where the specified consumer group has been authenticated. (Note that some plugins can not be restricted to consumers groups this way.). Leave unset for the plugin to activate regardless of the authenticated Consumer Groups (see [below for nested schema](#nestedatt--consumer_group))
- `created_at` (Number) Unix epoch when the resource was created.
- `enabled` (Boolean) Whether the plugin is applied. Default: true
- `id` (String) A string representing a UUID (universally unique identifier).
- `instance_name` (String) A unique string representing a UTF-8 encoded name.
- `ordering` (Attributes) (see [below for nested schema](#nestedatt--ordering))
- `partials` (Attributes List) A list of partials to be used by the plugin. (see [below for nested schema](#nestedatt--partials))
- `protocols` (Set of String) A list of the request protocols that will trigger this plugin. The default value, as well as the possible values allowed on this field, may change depending on the plugin type. For example, plugins that only work in stream mode will only support tcp and tls. Default: ["grpc","grpcs","http","https","ws","wss"]
- `route` (Attributes) If set, the plugin will only activate when receiving requests via the specified route. Leave unset for the plugin to activate regardless of the route being used. (see [below for nested schema](#nestedatt--route))
- `service` (Attributes) If set, the plugin will only activate when receiving requests via one of the routes belonging to the specified Service. Leave unset for the plugin to activate regardless of the Service being matched. (see [below for nested schema](#nestedatt--service))
- `tags` (List of String) An optional set of strings associated with the Plugin for grouping and filtering.
- `updated_at` (Number) Unix epoch when the resource was last updated.

<a id="nestedatt--config"></a>
### Nested Schema for `config`

Required:

- `targets` (Attributes List) (see [below for nested schema](#nestedatt--config--targets))

Optional:

- `balancer` (Attributes) (see [below for nested schema](#nestedatt--config--balancer))
- `embeddings` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings))
- `genai_category` (String) Generative AI category of the request. Default: "text/generation"; must be one of ["audio/speech", "audio/transcription", "image/generation", "realtime/generation", "text/embeddings", "text/generation"]
- `llm_format` (String) LLM input and output format and schema to use. Default: "openai"; must be one of ["anthropic", "bedrock", "cohere", "gemini", "huggingface", "openai"]
- `max_request_body_size` (Number) max allowed body size allowed to be introspected. 0 means unlimited, but the size of this body will still be limited by Nginx's client_max_body_size. Default: 1048576
- `model_name_header` (Boolean) Display the model name selected in the X-Kong-LLM-Model response header. Default: true
- `response_streaming` (String) Whether to 'optionally allow', 'deny', or 'always' (force) the streaming of answers via server sent events. Default: "allow"; must be one of ["allow", "always", "deny"]
- `vectordb` (Attributes) (see [below for nested schema](#nestedatt--config--vectordb))

<a id="nestedatt--config--targets"></a>
### Nested Schema for `config.targets`

Optional:

- `auth` (Attributes) (see [below for nested schema](#nestedatt--config--targets--auth))
- `description` (String) The semantic description of the target, required if using semantic load balancing. Specially, setting this to 'CATCHALL' will indicate such target to be used when no other targets match the semantic threshold. Only used by ai-proxy-advanced.
- `logging` (Attributes) (see [below for nested schema](#nestedatt--config--targets--logging))
- `metadata` (Map of String) For internal use only.
- `model` (Attributes) Not Null (see [below for nested schema](#nestedatt--config--targets--model))
- `route_type` (String) The model's operation implementation, for this provider. Not Null; must be one of ["audio/v1/audio/speech", "audio/v1/audio/transcriptions", "audio/v1/audio/translations", "image/v1/images/edits", "image/v1/images/generations", "llm/v1/assistants", "llm/v1/batches", "llm/v1/chat", "llm/v1/completions", "llm/v1/embeddings", "llm/v1/files", "llm/v1/responses", "preserve", "realtime/v1/realtime", "video/v1/videos/generations"]
- `weight` (Number) The weight this target gets within the upstream loadbalancer (1-65535). Only used by ai-proxy-advanced. Default: 100

<a id="nestedatt--config--targets--auth"></a>
### Nested Schema for `config.targets.auth`

Optional:

- `allow_override` (Boolean) If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin. Default: false
- `aws_access_key_id` (String) Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.
- `aws_secret_access_key` (String) Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.
- `azure_client_id` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.
- `azure_client_secret` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.
- `azure_tenant_id` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.
- `azure_use_managed_identity` (Boolean) Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models. Default: false
- `gcp_service_account_json` (String) Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.
- `gcp_use_service_account` (Boolean) Use service account auth for GCP-based providers and models. Default: false
- `header_name` (String) If AI model requires authentication via Authorization or API key header, specify its name here.
- `header_value` (String) Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.
- `param_location` (String) Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body. must be one of ["body", "query"]
- `param_name` (String) If AI model requires authentication via query parameter, specify its name here.
- `param_value` (String) Specify the full parameter value for 'param_name'.


<a id="nestedatt--config--targets--logging"></a>
### Nested Schema for `config.targets.logging`

Optional:

- `log_payloads` (Boolean) If enabled, will log the request and response body into the Kong log plugin(s) output.Furthermore if Opentelemetry instrumentation is enabled the traces will contain this data as well. Default: false
- `log_statistics` (Boolean) If enabled and supported by the driver, will add model usage and token metrics into the Kong log plugin(s) output. Default: false


<a id="nestedatt--config--targets--model"></a>
### Nested Schema for `config.targets.model`

Optional:

- `name` (String) Model name to execute.
- `options` (Attributes) Key/value settings for the model (see [below for nested schema](#nestedatt--config--targets--model--options))
- `provider` (String) AI provider request format - Kong translates requests to and from the specified backend compatible formats. Not Null; must be one of ["anthropic", "azure", "bedrock", "cerebras", "cohere", "dashscope", "gemini", "huggingface", "llama2", "mistral", "openai", "xai"]

<a id="nestedatt--config--targets--model--options"></a>
### Nested Schema for `config.targets.model.options`

Optional:

- `anthropic_version` (String) Defines the schema/API version, if using Anthropic provider.
- `azure_api_version` (String) 'api-version' for Azure OpenAI instances. Default: "2023-05-15"
- `azure_deployment_id` (String) Deployment ID for Azure OpenAI instances.
- `azure_instance` (String) Instance name for Azure OpenAI hosted models.
- `bedrock` (Attributes) (see [below for nested schema](#nestedatt--config--targets--model--options--bedrock))
- `cohere` (Attributes) (see [below for nested schema](#nestedatt--config--targets--model--options--cohere))
- `dashscope` (Attributes) (see [below for nested schema](#nestedatt--config--targets--model--options--dashscope))
- `embeddings_dimensions` (Number) If using embeddings models, set the number of dimensions to generate.
- `gemini` (Attributes) (see [below for nested schema](#nestedatt--config--targets--model--options--gemini))
- `huggingface` (Attributes) (see [below for nested schema](#nestedatt--config--targets--model--options--huggingface))
- `input_cost` (Number) Defines the cost per 1M tokens in your prompt.
- `llama2_format` (String) If using llama2 provider, select the upstream message format. must be one of ["ollama", "openai", "raw"]
- `max_tokens` (Number) Defines the max_tokens, if using chat or completion models.
- `mistral_format` (String) If using mistral provider, select the upstream message format. must be one of ["ollama", "openai"]
- `output_cost` (Number) Defines the cost per 1M tokens in the output of the AI.
- `temperature` (Number) Defines the matching temperature, if using chat or completion models.
- `top_k` (Number) Defines the top-k most likely tokens, if supported.
- `top_p` (Number) Defines the top-p probability mass, if supported.
- `upstream_path` (String) Manually specify or override the AI operation path, used when e.g. using the 'preserve' route_type.
- `upstream_url` (String) Manually specify or override the full URL to the AI operation endpoints, when calling (self-)hosted models, or for running via a private endpoint.

<a id="nestedatt--config--targets--model--options--bedrock"></a>
### Nested Schema for `config.targets.model.options.bedrock`

Optional:

- `aws_assume_role_arn` (String) If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.
- `aws_region` (String) If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.
- `aws_role_session_name` (String) If using AWS providers (Bedrock), set the identifier of the assumed role session.
- `aws_sts_endpoint_url` (String) If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.
- `embeddings_normalize` (Boolean) If using AWS providers (Bedrock), set to true to normalize the embeddings. Default: false
- `performance_config_latency` (String) Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.
- `video_output_s3_uri` (String) S3 URI (s3://bucket/prefix) where Bedrock will store generated video files. Required for video generation.


<a id="nestedatt--config--targets--model--options--cohere"></a>
### Nested Schema for `config.targets.model.options.cohere`

Optional:

- `embedding_input_type` (String) The purpose of the input text to calculate embedding vectors. Default: "classification"; must be one of ["classification", "clustering", "image", "search_document", "search_query"]
- `wait_for_model` (Boolean) Wait for the model if it is not ready


<a id="nestedatt--config--targets--model--options--dashscope"></a>
### Nested Schema for `config.targets.model.options.dashscope`

Optional:

- `international` (Boolean) Two Dashscope endpoints are available, and the international endpoint will be used when this is set to `true`.
It is recommended to set this to `true` when using international version of dashscope.
Default: true


<a id="nestedatt--config--targets--model--options--gemini"></a>
### Nested Schema for `config.targets.model.options.gemini`

Optional:

- `api_endpoint` (String) If running Gemini on Vertex, specify the regional API endpoint (hostname only).
- `endpoint_id` (String) If running Gemini on Vertex Model Garden, specify the endpoint ID.
- `location_id` (String) If running Gemini on Vertex, specify the location ID.
- `project_id` (String) If running Gemini on Vertex, specify the project ID.


<a id="nestedatt--config--targets--model--options--huggingface"></a>
### Nested Schema for `config.targets.model.options.huggingface`

Optional:

- `use_cache` (Boolean) Use the cache layer on the inference API
- `wait_for_model` (Boolean) Wait for the model if it is not ready





<a id="nestedatt--config--balancer"></a>
### Nested Schema for `config.balancer`

Optional:

- `algorithm` (String) Which load balancing algorithm to use. Default: "round-robin"; must be one of ["consistent-hashing", "least-connections", "lowest-latency", "lowest-usage", "priority", "round-robin", "semantic"]
- `connect_timeout` (Number) Default: 60000
- `fail_timeout` (Number) The period of time (in milliseconds) the target will be considered unavailable after the number of unsuccessful attempts reaches `max_fails`. Default: 10000
- `failover_criteria` (List of String) Specifies in which cases an upstream response should be failover to the next target. Each option in the array is equivalent to the function of http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream. Default: ["error","timeout"]
- `hash_on_header` (String) The header to use for consistent-hashing. Default: "X-Kong-LLM-Request-ID"
- `latency_strategy` (String) What metrics to use for latency. Available values are: `tpot` (time-per-output-token) and `e2e`. Default: "tpot"; must be one of ["e2e", "tpot"]
- `max_fails` (Number) Number of unsuccessful attempts to communicate with a target that should occur in the duration defined by `fail_timeout` before the target is considered unavailable. The zero value disables the circuit breaker. What is considered an unsuccessful attempt is defined by `failover_criteria`. Note the cases of `error`, `timeout` and `invalid_header` are always considered unsuccessful attempts, while the cases of `http_403` and `http_404` are never considered unsuccessful attempts. Default: 0
- `read_timeout` (Number) Default: 60000
- `retries` (Number) The number of retries to execute upon failure to proxy. Default: 5
- `slots` (Number) The number of slots in the load balancer algorithm. Default: 10000
- `tokens_count_strategy` (String) What tokens to use for usage calculation. Available values are: `total_tokens` `prompt_tokens`, `completion_tokens` and `cost`. Default: "total-tokens"; must be one of ["completion-tokens", "cost", "llm-accuracy", "prompt-tokens", "total-tokens"]
- `write_timeout` (Number) Default: 60000


<a id="nestedatt--config--embeddings"></a>
### Nested Schema for `config.embeddings`

Required:

- `model` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--model))

Optional:

- `auth` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--auth))

<a id="nestedatt--config--embeddings--model"></a>
### Nested Schema for `config.embeddings.model`

Required:

- `name` (String) Model name to execute.
- `provider` (String) AI provider format to use for embeddings API. must be one of ["azure", "bedrock", "gemini", "huggingface", "mistral", "openai"]

Optional:

- `options` (Attributes) Key/value settings for the model (see [below for nested schema](#nestedatt--config--embeddings--model--options))

<a id="nestedatt--config--embeddings--model--options"></a>
### Nested Schema for `config.embeddings.model.options`

Optional:

- `azure` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--model--options--azure))
- `bedrock` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--model--options--bedrock))
- `gemini` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--model--options--gemini))
- `huggingface` (Attributes) (see [below for nested schema](#nestedatt--config--embeddings--model--options--huggingface))
- `upstream_url` (String) upstream url for the embeddings

<a id="nestedatt--config--embeddings--model--options--azure"></a>
### Nested Schema for `config.embeddings.model.options.azure`

Optional:

- `api_version` (String) 'api-version' for Azure OpenAI instances. Default: "2023-05-15"
- `deployment_id` (String) Deployment ID for Azure OpenAI instances.
- `instance` (String) Instance name for Azure OpenAI hosted models.


<a id="nestedatt--config--embeddings--model--options--bedrock"></a>
### Nested Schema for `config.embeddings.model.options.bedrock`

Optional:

- `aws_assume_role_arn` (String) If using AWS providers (Bedrock) you can assume a different role after authentication with the current IAM context is successful.
- `aws_region` (String) If using AWS providers (Bedrock) you can override the `AWS_REGION` environment variable by setting this option.
- `aws_role_session_name` (String) If using AWS providers (Bedrock), set the identifier of the assumed role session.
- `aws_sts_endpoint_url` (String) If using AWS providers (Bedrock), override the STS endpoint URL when assuming a different role.
- `embeddings_normalize` (Boolean) If using AWS providers (Bedrock), set to true to normalize the embeddings. Default: false
- `performance_config_latency` (String) Force the client's performance configuration 'latency' for all requests. Leave empty to let the consumer select the performance configuration.
- `video_output_s3_uri` (String) S3 URI (s3://bucket/prefix) where Bedrock will store generated video files. Required for video generation.


<a id="nestedatt--config--embeddings--model--options--gemini"></a>
### Nested Schema for `config.embeddings.model.options.gemini`

Optional:

- `api_endpoint` (String) If running Gemini on Vertex, specify the regional API endpoint (hostname only).
- `location_id` (String) If running Gemini on Vertex, specify the location ID.
- `project_id` (String) If running Gemini on Vertex, specify the project ID.


<a id="nestedatt--config--embeddings--model--options--huggingface"></a>
### Nested Schema for `config.embeddings.model.options.huggingface`

Optional:

- `use_cache` (Boolean) Use the cache layer on the inference API
- `wait_for_model` (Boolean) Wait for the model if it is not ready




<a id="nestedatt--config--embeddings--auth"></a>
### Nested Schema for `config.embeddings.auth`

Optional:

- `allow_override` (Boolean) If enabled, the authorization header or parameter can be overridden in the request by the value configured in the plugin. Default: false
- `aws_access_key_id` (String) Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_ACCESS_KEY_ID environment variable for this plugin instance.
- `aws_secret_access_key` (String) Set this if you are using an AWS provider (Bedrock) and you are authenticating using static IAM User credentials. Setting this will override the AWS_SECRET_ACCESS_KEY environment variable for this plugin instance.
- `azure_client_id` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client ID.
- `azure_client_secret` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the client secret.
- `azure_tenant_id` (String) If azure_use_managed_identity is set to true, and you need to use a different user-assigned identity for this LLM instance, set the tenant ID.
- `azure_use_managed_identity` (Boolean) Set true to use the Azure Cloud Managed Identity (or user-assigned identity) to authenticate with Azure-provider models. Default: false
- `gcp_service_account_json` (String) Set this field to the full JSON of the GCP service account to authenticate, if required. If null (and gcp_use_service_account is true), Kong will attempt to read from environment variable `GCP_SERVICE_ACCOUNT`.
- `gcp_use_service_account` (Boolean) Use service account auth for GCP-based providers and models. Default: false
- `header_name` (String) If AI model requires authentication via Authorization or API key header, specify its name here.
- `header_value` (String) Specify the full auth header value for 'header_name', for example 'Bearer key' or just 'key'.
- `param_location` (String) Specify whether the 'param_name' and 'param_value' options go in a query string, or the POST form/JSON body. must be one of ["body", "query"]
- `param_name` (String) If AI model requires authentication via query parameter, specify its name here.
- `param_value` (String) Specify the full parameter value for 'param_name'.



<a id="nestedatt--config--vectordb"></a>
### Nested Schema for `config.vectordb`

Required:

- `dimensions` (Number) the desired dimensionality for the vectors
- `distance_metric` (String) the distance metric to use for vector searches. must be one of ["cosine", "euclidean"]
- `strategy` (String) which vector database driver to use. must be one of ["pgvector", "redis"]

Optional:

- `pgvector` (Attributes) (see [below for nested schema](#nestedatt--config--vectordb--pgvector))
- `redis` (Attributes) (see [below for nested schema](#nestedatt--config--vectordb--redis))
- `threshold` (Number) the default similarity threshold for accepting semantic search results (float)

<a id="nestedatt--config--vectordb--pgvector"></a>
### Nested Schema for `config.vectordb.pgvector`

Optional:

- `database` (String) the database of the pgvector database. Default: "kong-pgvector"
- `host` (String) the host of the pgvector database. Default: "127.0.0.1"
- `password` (String) the password of the pgvector database
- `port` (Number) the port of the pgvector database. Default: 5432
- `ssl` (Boolean) whether to use ssl for the pgvector database. Default: false
- `ssl_cert` (String) the path of ssl cert to use for the pgvector database
- `ssl_cert_key` (String) the path of ssl cert key to use for the pgvector database
- `ssl_required` (Boolean) whether ssl is required for the pgvector database. Default: false
- `ssl_verify` (Boolean) whether to verify ssl for the pgvector database. Default: false
- `ssl_version` (String) the ssl version to use for the pgvector database. Default: "tlsv1_2"; must be one of ["any", "tlsv1_2", "tlsv1_3"]
- `timeout` (Number) the timeout of the pgvector database. Default: 5000
- `user` (String) the user of the pgvector database. Default: "postgres"


<a id="nestedatt--config--vectordb--redis"></a>
### Nested Schema for `config.vectordb.redis`

Optional:

- `cloud_authentication` (Attributes) Cloud auth related configs for connecting to a Cloud Provider's Redis instance. (see [below for nested schema](#nestedatt--config--vectordb--redis--cloud_authentication))
- `cluster_max_redirections` (Number) Maximum retry attempts for redirection. Default: 5
- `cluster_nodes` (Attributes List) Cluster addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Cluster. The minimum length of the array is 1 element. (see [below for nested schema](#nestedatt--config--vectordb--redis--cluster_nodes))
- `connect_timeout` (Number) An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2. Default: 2000
- `connection_is_proxied` (Boolean) If the connection to Redis is proxied (e.g. Envoy), set it `true`. Set the `host` and `port` to point to the proxy address. Default: false
- `database` (Number) Database to use for the Redis connection when using the `redis` strategy. Default: 0
- `host` (String) A string representing a host name, such as example.com. Default: "127.0.0.1"
- `keepalive_backlog` (Number) Limits the total number of opened connections for a pool. If the connection pool is full, connection queues above the limit go into the backlog queue. If the backlog queue is full, subsequent connect operations fail and return `nil`. Queued operations (subject to set timeouts) resume once the number of connections in the pool is less than `keepalive_pool_size`. If latency is high or throughput is low, try increasing this value. Empirically, this value is larger than `keepalive_pool_size`.
- `keepalive_pool_size` (Number) The size limit for every cosocket connection pool associated with every remote server, per worker process. If neither `keepalive_pool_size` nor `keepalive_backlog` is specified, no pool is created. If `keepalive_pool_size` isn't specified but `keepalive_backlog` is specified, then the pool uses the default value. Try to increase (e.g. 512) this value if latency is high or throughput is low. Default: 256
- `password` (String) Password to use for Redis connections. If undefined, no AUTH commands are sent to Redis.
- `port` (Number) An integer representing a port number between 0 and 65535, inclusive. Default: 6379
- `read_timeout` (Number) An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2. Default: 2000
- `send_timeout` (Number) An integer representing a timeout in milliseconds. Must be between 0 and 2^31-2. Default: 2000
- `sentinel_master` (String) Sentinel master to use for Redis connections. Defining this value implies using Redis Sentinel.
- `sentinel_nodes` (Attributes List) Sentinel node addresses to use for Redis connections when the `redis` strategy is defined. Defining this field implies using a Redis Sentinel. The minimum length of the array is 1 element. (see [below for nested schema](#nestedatt--config--vectordb--redis--sentinel_nodes))
- `sentinel_password` (String) Sentinel password to authenticate with a Redis Sentinel instance. If undefined, no AUTH commands are sent to Redis Sentinels.
- `sentinel_role` (String) Sentinel role to use for Redis connections when the `redis` strategy is defined. Defining this value implies using Redis Sentinel. must be one of ["any", "master", "slave"]
- `sentinel_username` (String) Sentinel username to authenticate with a Redis Sentinel instance. If undefined, ACL authentication won't be performed. This requires Redis v6.2.0+.
- `server_name` (String) A string representing an SNI (server name indication) value for TLS.
- `ssl` (Boolean) If set to true, uses SSL to connect to Redis. Default: false
- `ssl_verify` (Boolean) If set to true, verifies the validity of the server SSL certificate. If setting this parameter, also configure `lua_ssl_trusted_certificate` in `kong.conf` to specify the CA (or server) certificate used by your Redis server. You may also need to configure `lua_ssl_verify_depth` accordingly. Default: false
- `username` (String) Username to use for Redis connections. If undefined, ACL authentication won't be performed. This requires Redis v6.0.0+. To be compatible with Redis v5.x.y, you can set it to `default`.

<a id="nestedatt--config--vectordb--redis--cloud_authentication"></a>
### Nested Schema for `config.vectordb.redis.cloud_authentication`

Optional:

- `auth_provider` (String) Auth providers to be used to authenticate to a Cloud Provider's Redis instance. must be one of ["aws", "azure", "gcp"]
- `aws_access_key_id` (String) AWS Access Key ID to be used for authentication when `auth_provider` is set to `aws`.
- `aws_assume_role_arn` (String) The ARN of the IAM role to assume for generating ElastiCache IAM authentication tokens.
- `aws_cache_name` (String) The name of the AWS Elasticache cluster when `auth_provider` is set to `aws`.
- `aws_is_serverless` (Boolean) This flag specifies whether the cluster is serverless when auth_provider is set to `aws`. Default: true
- `aws_region` (String) The region of the AWS ElastiCache cluster when `auth_provider` is set to `aws`.
- `aws_role_session_name` (String) The session name for the temporary credentials when assuming the IAM role.
- `aws_secret_access_key` (String) AWS Secret Access Key to be used for authentication when `auth_provider` is set to `aws`.
- `azure_client_id` (String) Azure Client ID to be used for authentication when `auth_provider` is set to `azure`.
- `azure_client_secret` (String) Azure Client Secret to be used for authentication when `auth_provider` is set to `azure`.
- `azure_tenant_id` (String) Azure Tenant ID to be used for authentication when `auth_provider` is set to `azure`.
- `gcp_service_account_json` (String) GCP Service Account JSON to be used for authentication when `auth_provider` is set to `gcp`.


<a id="nestedatt--config--vectordb--redis--cluster_nodes"></a>
### Nested Schema for `config.vectordb.redis.cluster_nodes`

Optional:

- `ip` (String) A string representing a host name, such as example.com. Default: "127.0.0.1"
- `port` (Number) An integer representing a port number between 0 and 65535, inclusive. Default: 6379


<a id="nestedatt--config--vectordb--redis--sentinel_nodes"></a>
### Nested Schema for `config.vectordb.redis.sentinel_nodes`

Optional:

- `host` (String) A string representing a host name, such as example.com. Default: "127.0.0.1"
- `port` (Number) An integer representing a port number between 0 and 65535, inclusive. Default: 6379





<a id="nestedatt--consumer"></a>
### Nested Schema for `consumer`

Optional:

- `id` (String)


<a id="nestedatt--consumer_group"></a>
### Nested Schema for `consumer_group`

Optional:

- `id` (String)


<a id="nestedatt--ordering"></a>
### Nested Schema for `ordering`

Optional:

- `after` (Attributes) (see [below for nested schema](#nestedatt--ordering--after))
- `before` (Attributes) (see [below for nested schema](#nestedatt--ordering--before))

<a id="nestedatt--ordering--after"></a>
### Nested Schema for `ordering.after`

Optional:

- `access` (List of String)


<a id="nestedatt--ordering--before"></a>
### Nested Schema for `ordering.before`

Optional:

- `access` (List of String)



<a id="nestedatt--partials"></a>
### Nested Schema for `partials`

Optional:

- `id` (String) A string representing a UUID (universally unique identifier).
- `name` (String) A unique string representing a UTF-8 encoded name.
- `path` (String)


<a id="nestedatt--route"></a>
### Nested Schema for `route`

Optional:

- `id` (String)


<a id="nestedatt--service"></a>
### Nested Schema for `service`

Optional:

- `id` (String)

## Import

Import is supported using the following syntax:

In Terraform v1.5.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `id` attribute, for example:

```terraform
import {
  to = konnect_gateway_plugin_ai_proxy_advanced.my_konnect_gateway_plugin_ai_proxy_advanced
  id = jsonencode({
    control_plane_id = "9524ec7d-36d9-465d-a8c5-83a3c9390458"
    id = "3473c251-5b6c-4f45-b1ff-7ede735a366d"
  })
}
```

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import konnect_gateway_plugin_ai_proxy_advanced.my_konnect_gateway_plugin_ai_proxy_advanced '{"control_plane_id": "9524ec7d-36d9-465d-a8c5-83a3c9390458", "id": "3473c251-5b6c-4f45-b1ff-7ede735a366d"}'
```
